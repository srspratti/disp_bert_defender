{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"bert_defender_modified.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GFjvtMt8wsST","executionInfo":{"status":"ok","timestamp":1617239789525,"user_tz":240,"elapsed":748,"user":{"displayName":"sriram sanjeev pratti","photoUrl":"https://lh3.googleusercontent.com/-x9kOW5PtcK0/AAAAAAAAAAI/AAAAAAAARGg/gGBrVWqYABU/s64/photo.jpg","userId":"07241238899528141574"}},"outputId":"b4aad280-499b-40ea-c7dc-41e3180beda6"},"source":["!pwd"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lBNAxf8JxchI","executionInfo":{"status":"ok","timestamp":1617239814641,"user_tz":240,"elapsed":23591,"user":{"displayName":"sriram sanjeev pratti","photoUrl":"https://lh3.googleusercontent.com/-x9kOW5PtcK0/AAAAAAAAAAI/AAAAAAAARGg/gGBrVWqYABU/s64/photo.jpg","userId":"07241238899528141574"}},"outputId":"0fe8f260-33ac-44e5-ec29-94146ddada4f"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CyPapm2sg1YK","outputId":"41c5b849-323d-42b9-cc2e-b32c617b5c3e"},"source":["cd bert_defender_master_vastai_new_instance"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: 'bert_defender_master_vastai_new_instance'\n","/root/bert_defender_master_vastai_new_instance\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U8Yckm3vhnSq","executionInfo":{"status":"ok","timestamp":1617239818963,"user_tz":240,"elapsed":1418,"user":{"displayName":"sriram sanjeev pratti","photoUrl":"https://lh3.googleusercontent.com/-x9kOW5PtcK0/AAAAAAAAAAI/AAAAAAAARGg/gGBrVWqYABU/s64/photo.jpg","userId":"07241238899528141574"}},"outputId":"58c6f52b-8106-4e32-d01e-6061c583420f"},"source":["cd /content/drive/MyDrive/UdeM/GT_ML/bert-defender-master/Bert_Defender_ts/disp_bert_defender/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/UdeM/GT_ML/bert-defender-master/Bert_Defender_ts/disp_bert_defender\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haOwVP_qyA1D","executionInfo":{"status":"ok","timestamp":1617231816316,"user_tz":240,"elapsed":259,"user":{"displayName":"sriram sanjeev pratti","photoUrl":"https://lh3.googleusercontent.com/-x9kOW5PtcK0/AAAAAAAAAAI/AAAAAAAARGg/gGBrVWqYABU/s64/photo.jpg","userId":"07241238899528141574"}},"outputId":"b350c673-bd83-4ce7-cfaa-dbbe387b61b2"},"source":["ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":["bert_classifier.py            bert_model.py           \u001b[0m\u001b[01;34mmodels\u001b[0m/\n","bert_config.json              bert_random_attacks.py  optimization.py\n","bert_defender_modified.ipynb  bert_utils.py           \u001b[01;34m__pycache__\u001b[0m/\n","bert_discriminator.py         \u001b[01;34mdata\u001b[0m/                   README.md\n","bert_eval_epoches.py          \u001b[01;34memb\u001b[0m/                    sample\n","bert_eval.py                  enumerate_attacks.py    \u001b[01;34mtmp\u001b[0m/\n","bert_generator.py             file_utils.py           tokenization.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bhj4N3zezAIk","outputId":"2ab9ace5-3c89-4bbe-d7f0-08fb3f9d866d"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Thu Mar 25 13:46:12 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  GeForce RTX 3090    Off  | 00000000:46:00.0 Off |                  N/A |\n","| 30%   37C    P8     9W / 350W |      6MiB / 24268MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","|   1  GeForce RTX 3090    Off  | 00000000:C2:00.0 Off |                  N/A |\n","|  0%   32C    P8    12W / 350W |      6MiB / 24268MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9NH4l-Ig1YL","executionInfo":{"status":"ok","timestamp":1617231823848,"user_tz":240,"elapsed":3938,"user":{"displayName":"sriram sanjeev pratti","photoUrl":"https://lh3.googleusercontent.com/-x9kOW5PtcK0/AAAAAAAAAAI/AAAAAAAARGg/gGBrVWqYABU/s64/photo.jpg","userId":"07241238899528141574"}},"outputId":"b458e77a-934a-48c1-9bb6-e1dd82b253d2"},"source":["!pip install torch"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N-uziBBezoQ0","executionInfo":{"status":"ok","timestamp":1617231825633,"user_tz":240,"elapsed":4543,"user":{"displayName":"sriram sanjeev pratti","photoUrl":"https://lh3.googleusercontent.com/-x9kOW5PtcK0/AAAAAAAAAAI/AAAAAAAARGg/gGBrVWqYABU/s64/photo.jpg","userId":"07241238899528141574"}},"outputId":"4ab9def8-9b09-4ff7-e7a4-b33282aef144"},"source":["import torch\n","torch.cuda.is_available()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9LVvTU180CDC","executionInfo":{"status":"ok","timestamp":1617231827431,"user_tz":240,"elapsed":5152,"user":{"displayName":"sriram sanjeev pratti","photoUrl":"https://lh3.googleusercontent.com/-x9kOW5PtcK0/AAAAAAAAAAI/AAAAAAAARGg/gGBrVWqYABU/s64/photo.jpg","userId":"07241238899528141574"}},"outputId":"1d4ec9b5-31f8-4f5d-d984-9d93969e8378"},"source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["''"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K7L8NN5P16fx","outputId":"b6c369e8-dc26-4665-83dd-04625135d455"},"source":["!which python"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/Users/sreeramasanjeevpratti/.conda/envs/disp_bert_defender/bin/python\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jWou01Hj-c1Z","executionInfo":{"status":"ok","timestamp":1617239850152,"user_tz":240,"elapsed":6857,"user":{"displayName":"sriram sanjeev pratti","photoUrl":"https://lh3.googleusercontent.com/-x9kOW5PtcK0/AAAAAAAAAAI/AAAAAAAARGg/gGBrVWqYABU/s64/photo.jpg","userId":"07241238899528141574"}},"outputId":"dacf77f6-d4b8-4589-95a9-77371b462e69"},"source":["!pip install boto3"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/d6/b16f09ce6fc7888e554cf289be0872456e9cab68d9944e4b8e25d3b6af93/boto3-1.17.42-py2.py3-none-any.whl (131kB)\n","\r\u001b[K     |██▌                             | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 30.6MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 30kB 28.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 20.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 51kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 61kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 71kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 81kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 92kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 102kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 112kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 122kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 16.9MB/s \n","\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/14/0b4be62b65c52d6d1c442f24e02d2a9889a73d3c352002e14c70f84a679f/s3transfer-0.3.6-py2.py3-none-any.whl (73kB)\n","\r\u001b[K     |████▌                           | 10kB 27.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20kB 35.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 30kB 39.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 40kB 41.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 51kB 42.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 61kB 32.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 71kB 33.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 10.6MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Collecting botocore<1.21.0,>=1.20.42\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/bc/53cbcc88c72f014f199bc2b8a12af1d5c234eee6a372b2765a7e4086a752/botocore-1.20.42-py2.py3-none-any.whl (7.4MB)\n","\u001b[K     |████████████████████████████████| 7.4MB 22.1MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.42->boto3) (2.8.1)\n","Collecting urllib3<1.27,>=1.25.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/c6/d3e3abe5b4f4f16cf0dfc9240ab7ce10c2baa0e268989a4e3ec19e90c84e/urllib3-1.26.4-py2.py3-none-any.whl (153kB)\n","\u001b[K     |████████████████████████████████| 153kB 58.4MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.42->boto3) (1.15.0)\n","\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.4 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n","  Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed boto3-1.17.42 botocore-1.20.42 jmespath-0.10.0 s3transfer-0.3.6 urllib3-1.26.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9MHA27HN-tKP","executionInfo":{"status":"ok","timestamp":1617239875683,"user_tz":240,"elapsed":30020,"user":{"displayName":"sriram sanjeev pratti","photoUrl":"https://lh3.googleusercontent.com/-x9kOW5PtcK0/AAAAAAAAAAI/AAAAAAAARGg/gGBrVWqYABU/s64/photo.jpg","userId":"07241238899528141574"}},"outputId":"66ee7f84-cb44-4ac5-bc09-18afaafdebbd"},"source":["!pip install hnswlib==0.5.1"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting hnswlib==0.5.1\n","  Downloading https://files.pythonhosted.org/packages/03/8c/3e0e608278b740f2a78ba76ba406dbecc8b7d3ce8cfb858580f13ea04930/hnswlib-0.5.1.tar.gz\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hnswlib==0.5.1) (1.19.5)\n","Building wheels for collected packages: hnswlib\n","  Building wheel for hnswlib (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hnswlib: filename=hnswlib-0.5.1-cp37-cp37m-linux_x86_64.whl size=1303035 sha256=3060106baebb21d7fc357c35b84ce4c009de0e79ce3ff55beee5225d4cbca6fd\n","  Stored in directory: /root/.cache/pip/wheels/46/7b/98/44c3a8a284506a54993f0b321e4a32a0c9e69215bbb72feff5\n","Successfully built hnswlib\n","Installing collected packages: hnswlib\n","Successfully installed hnswlib-0.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qV064Cit_kxn","executionInfo":{"status":"ok","timestamp":1617239879608,"user_tz":240,"elapsed":31674,"user":{"displayName":"sriram sanjeev pratti","photoUrl":"https://lh3.googleusercontent.com/-x9kOW5PtcK0/AAAAAAAAAAI/AAAAAAAARGg/gGBrVWqYABU/s64/photo.jpg","userId":"07241238899528141574"}},"outputId":"cc305c99-c356-43e7-f642-70e7599c7588"},"source":["!pip install nltk\n","import nltk\n","nltk.download('punkt')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i8ZNBbA6g1YN","executionInfo":{"status":"ok","timestamp":1617239882050,"user_tz":240,"elapsed":32811,"user":{"displayName":"sriram sanjeev pratti","photoUrl":"https://lh3.googleusercontent.com/-x9kOW5PtcK0/AAAAAAAAAAI/AAAAAAAARGg/gGBrVWqYABU/s64/photo.jpg","userId":"07241238899528141574"}},"outputId":"c6c132c0-3973-4ad2-c582-faacede0bd5a"},"source":["!pip install sklearn"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9029NhXg1YN","executionInfo":{"status":"ok","timestamp":1617239884378,"user_tz":240,"elapsed":32936,"user":{"displayName":"sriram sanjeev pratti","photoUrl":"https://lh3.googleusercontent.com/-x9kOW5PtcK0/AAAAAAAAAAI/AAAAAAAARGg/gGBrVWqYABU/s64/photo.jpg","userId":"07241238899528141574"}},"outputId":"38e09050-4005-49be-a3df-8be8bf279a65"},"source":["!pip install pandas"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"tags":[],"id":"05crN1MNg1YN","outputId":"fbd98ecc-4a4e-4259-a453-e1e94a47ab10"},"source":["!nvidia-smi -q"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","==============NVSMI LOG==============\n","\n","Timestamp                                 : Mon Mar 22 19:25:35 2021\n","Driver Version                            : 460.39\n","CUDA Version                              : 11.2\n","\n","Attached GPUs                             : 2\n","GPU 00000000:46:00.0\n","    Product Name                          : GeForce RTX 3090\n","    Product Brand                         : GeForce\n","    Display Mode                          : Disabled\n","    Display Active                        : Disabled\n","    Persistence Mode                      : Enabled\n","    MIG Mode\n","        Current                           : N/A\n","        Pending                           : N/A\n","    Accounting Mode                       : Disabled\n","    Accounting Mode Buffer Size           : 4000\n","    Driver Model\n","        Current                           : N/A\n","        Pending                           : N/A\n","    Serial Number                         : 1324020038945\n","    GPU UUID                              : GPU-8ad6666a-677c-9f0e-3b58-90220b309ddc\n","    Minor Number                          : 3\n","    VBIOS Version                         : 94.02.27.00.0A\n","    MultiGPU Board                        : No\n","    Board ID                              : 0x4600\n","    GPU Part Number                       : 900-1G136-2510-000\n","    Inforom Version\n","        Image Version                     : G001.0000.03.03\n","        OEM Object                        : 2.0\n","        ECC Object                        : N/A\n","        Power Management Object           : N/A\n","    GPU Operation Mode\n","        Current                           : N/A\n","        Pending                           : N/A\n","    GPU Virtualization Mode\n","        Virtualization Mode               : None\n","        Host VGPU Mode                    : N/A\n","    IBMNPU\n","        Relaxed Ordering Mode             : N/A\n","    PCI\n","        Bus                               : 0x46\n","        Device                            : 0x00\n","        Domain                            : 0x0000\n","        Device Id                         : 0x220410DE\n","        Bus Id                            : 00000000:46:00.0\n","        Sub System Id                     : 0x147D10DE\n","        GPU Link Info\n","            PCIe Generation\n","                Max                       : 3\n","                Current                   : 1\n","            Link Width\n","                Max                       : 16x\n","                Current                   : 16x\n","        Bridge Chip\n","            Type                          : N/A\n","            Firmware                      : N/A\n","        Replays Since Reset               : 0\n","        Replay Number Rollovers           : 0\n","        Tx Throughput                     : 0 KB/s\n","        Rx Throughput                     : 0 KB/s\n","    Fan Speed                             : 0 %\n","    Performance State                     : P8\n","    Clocks Throttle Reasons\n","        Idle                              : Active\n","        Applications Clocks Setting       : Not Active\n","        SW Power Cap                      : Not Active\n","        HW Slowdown                       : Not Active\n","            HW Thermal Slowdown           : Not Active\n","            HW Power Brake Slowdown       : Not Active\n","        Sync Boost                        : Not Active\n","        SW Thermal Slowdown               : Not Active\n","        Display Clock Setting             : Not Active\n","    FB Memory Usage\n","        Total                             : 24268 MiB\n","        Used                              : 414 MiB\n","        Free                              : 23854 MiB\n","    BAR1 Memory Usage\n","        Total                             : 256 MiB\n","        Used                              : 11 MiB\n","        Free                              : 245 MiB\n","    Compute Mode                          : Default\n","    Utilization\n","        Gpu                               : 0 %\n","        Memory                            : 0 %\n","        Encoder                           : 0 %\n","        Decoder                           : 0 %\n","    Encoder Stats\n","        Active Sessions                   : 0\n","        Average FPS                       : 0\n","        Average Latency                   : 0\n","    FBC Stats\n","        Active Sessions                   : 0\n","        Average FPS                       : 0\n","        Average Latency                   : 0\n","    Ecc Mode\n","        Current                           : N/A\n","        Pending                           : N/A\n","    ECC Errors\n","        Volatile\n","            SRAM Correctable              : N/A\n","            SRAM Uncorrectable            : N/A\n","            DRAM Correctable              : N/A\n","            DRAM Uncorrectable            : N/A\n","        Aggregate\n","            SRAM Correctable              : N/A\n","            SRAM Uncorrectable            : N/A\n","            DRAM Correctable              : N/A\n","            DRAM Uncorrectable            : N/A\n","    Retired Pages\n","        Single Bit ECC                    : N/A\n","        Double Bit ECC                    : N/A\n","        Pending Page Blacklist            : N/A\n","    Remapped Rows                         : N/A\n","    Temperature\n","        GPU Current Temp                  : 22 C\n","        GPU Shutdown Temp                 : 98 C\n","        GPU Slowdown Temp                 : 95 C\n","        GPU Max Operating Temp            : 93 C\n","        GPU Target Temperature            : 75 C\n","        Memory Current Temp               : N/A\n","        Memory Max Operating Temp         : N/A\n","    Power Readings\n","        Power Management                  : Supported\n","        Power Draw                        : 16.14 W\n","        Power Limit                       : 375.00 W\n","        Default Power Limit               : 350.00 W\n","        Enforced Power Limit              : 375.00 W\n","        Min Power Limit                   : 100.00 W\n","        Max Power Limit                   : 400.00 W\n","    Clocks\n","        Graphics                          : 0 MHz\n","        SM                                : 0 MHz\n","        Memory                            : 405 MHz\n","        Video                             : 555 MHz\n","    Applications Clocks\n","        Graphics                          : N/A\n","        Memory                            : N/A\n","    Default Applications Clocks\n","        Graphics                          : N/A\n","        Memory                            : N/A\n","    Max Clocks\n","        Graphics                          : 2100 MHz\n","        SM                                : 2100 MHz\n","        Memory                            : 9751 MHz\n","        Video                             : 1950 MHz\n","    Max Customer Boost Clocks\n","        Graphics                          : N/A\n","    Clock Policy\n","        Auto Boost                        : N/A\n","        Auto Boost Default                : N/A\n","    Processes                             : None\n","\n","GPU 00000000:81:00.0\n","    Product Name                          : GeForce RTX 3090\n","    Product Brand                         : GeForce\n","    Display Mode                          : Disabled\n","    Display Active                        : Disabled\n","    Persistence Mode                      : Enabled\n","    MIG Mode\n","        Current                           : N/A\n","        Pending                           : N/A\n","    Accounting Mode                       : Disabled\n","    Accounting Mode Buffer Size           : 4000\n","    Driver Model\n","        Current                           : N/A\n","        Pending                           : N/A\n","    Serial Number                         : 1323920020675\n","    GPU UUID                              : GPU-d45bf8ec-5a88-7fa3-7baa-c0196ebd87c8\n","    Minor Number                          : 2\n","    VBIOS Version                         : 94.02.27.00.0A\n","    MultiGPU Board                        : No\n","    Board ID                              : 0x8100\n","    GPU Part Number                       : 900-1G136-2510-000\n","    Inforom Version\n","        Image Version                     : G001.0000.03.03\n","        OEM Object                        : 2.0\n","        ECC Object                        : N/A\n","        Power Management Object           : N/A\n","    GPU Operation Mode\n","        Current                           : N/A\n","        Pending                           : N/A\n","    GPU Virtualization Mode\n","        Virtualization Mode               : None\n","        Host VGPU Mode                    : N/A\n","    IBMNPU\n","        Relaxed Ordering Mode             : N/A\n","    PCI\n","        Bus                               : 0x81\n","        Device                            : 0x00\n","        Domain                            : 0x0000\n","        Device Id                         : 0x220410DE\n","        Bus Id                            : 00000000:81:00.0\n","        Sub System Id                     : 0x147D10DE\n","        GPU Link Info\n","            PCIe Generation\n","                Max                       : 3\n","                Current                   : 1\n","            Link Width\n","                Max                       : 16x\n","                Current                   : 16x\n","        Bridge Chip\n","            Type                          : N/A\n","            Firmware                      : N/A\n","        Replays Since Reset               : 0\n","        Replay Number Rollovers           : 0\n","        Tx Throughput                     : 0 KB/s\n","        Rx Throughput                     : 0 KB/s\n","    Fan Speed                             : 0 %\n","    Performance State                     : P8\n","    Clocks Throttle Reasons\n","        Idle                              : Active\n","        Applications Clocks Setting       : Not Active\n","        SW Power Cap                      : Not Active\n","        HW Slowdown                       : Not Active\n","            HW Thermal Slowdown           : Not Active\n","            HW Power Brake Slowdown       : Not Active\n","        Sync Boost                        : Not Active\n","        SW Thermal Slowdown               : Not Active\n","        Display Clock Setting             : Not Active\n","    FB Memory Usage\n","        Total                             : 24268 MiB\n","        Used                              : 414 MiB\n","        Free                              : 23854 MiB\n","    BAR1 Memory Usage\n","        Total                             : 256 MiB\n","        Used                              : 7 MiB\n","        Free                              : 249 MiB\n","    Compute Mode                          : Default\n","    Utilization\n","        Gpu                               : 0 %\n","        Memory                            : 0 %\n","        Encoder                           : 0 %\n","        Decoder                           : 0 %\n","    Encoder Stats\n","        Active Sessions                   : 0\n","        Average FPS                       : 0\n","        Average Latency                   : 0\n","    FBC Stats\n","        Active Sessions                   : 0\n","        Average FPS                       : 0\n","        Average Latency                   : 0\n","    Ecc Mode\n","        Current                           : N/A\n","        Pending                           : N/A\n","    ECC Errors\n","        Volatile\n","            SRAM Correctable              : N/A\n","            SRAM Uncorrectable            : N/A\n","            DRAM Correctable              : N/A\n","            DRAM Uncorrectable            : N/A\n","        Aggregate\n","            SRAM Correctable              : N/A\n","            SRAM Uncorrectable            : N/A\n","            DRAM Correctable              : N/A\n","            DRAM Uncorrectable            : N/A\n","    Retired Pages\n","        Single Bit ECC                    : N/A\n","        Double Bit ECC                    : N/A\n","        Pending Page Blacklist            : N/A\n","    Remapped Rows                         : N/A\n","    Temperature\n","        GPU Current Temp                  : 24 C\n","        GPU Shutdown Temp                 : 98 C\n","        GPU Slowdown Temp                 : 95 C\n","        GPU Max Operating Temp            : 93 C\n","        GPU Target Temperature            : 75 C\n","        Memory Current Temp               : N/A\n","        Memory Max Operating Temp         : N/A\n","    Power Readings\n","        Power Management                  : Supported\n","        Power Draw                        : 13.63 W\n","        Power Limit                       : 375.00 W\n","        Default Power Limit               : 350.00 W\n","        Enforced Power Limit              : 375.00 W\n","        Min Power Limit                   : 100.00 W\n","        Max Power Limit                   : 400.00 W\n","    Clocks\n","        Graphics                          : 0 MHz\n","        SM                                : 0 MHz\n","        Memory                            : 405 MHz\n","        Video                             : 555 MHz\n","    Applications Clocks\n","        Graphics                          : N/A\n","        Memory                            : N/A\n","    Default Applications Clocks\n","        Graphics                          : N/A\n","        Memory                            : N/A\n","    Max Clocks\n","        Graphics                          : 2100 MHz\n","        SM                                : 2100 MHz\n","        Memory                            : 9751 MHz\n","        Video                             : 1950 MHz\n","    Max Customer Boost Clocks\n","        Graphics                          : N/A\n","    Clock Policy\n","        Auto Boost                        : N/A\n","        Auto Boost Default                : N/A\n","    Processes                             : None\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"egkWwkwzg1YO"},"source":["Training"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"FIO5U77A1QcJ","jupyter":{"outputs_hidden":true},"tags":[],"outputId":"3653c367-8f1e-49ac-cbb9-bcbdd2ef4d30"},"source":["# Discriminator train \n","!python bert_discriminator.py \\\n","--task_name sst-2\\\n","--do_train\\\n","--do_lower_case\\\n","--data_dir data/sst-2/\\\n","--bert_model bert-base-uncased\\\n","--max_seq_length 128\\\n","--train_batch_size 8\\\n","--learning_rate 2e-5\\\n","--num_train_epochs 25\\\n","--output_dir ./tmp/disc/\n","#--no_cuda"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","03/28/2021 18:10:33 - INFO - bert_utils -   device: cpu , distributed training: False, 16-bits training: False\n","03/28/2021 18:10:34 - INFO - tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","03/28/2021 18:10:34 - INFO - bert_utils -   *** Example ***\n","03/28/2021 18:10:34 - INFO - bert_utils -   tokens: that loves its characters and communicates something rather beautiful about human nature\n","03/28/2021 18:10:34 - INFO - bert_utils -   token_ids: 1 2 3 4 5 6 7 8 9 10 11 12 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/28/2021 18:10:34 - INFO - bert_utils -   *** Example ***\n","03/28/2021 18:10:34 - INFO - bert_utils -   tokens: remains utterly satisfied to remain the same throughout\n","03/28/2021 18:10:34 - INFO - bert_utils -   token_ids: 13 14 15 16 17 18 19 20 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/28/2021 18:10:34 - INFO - bert_utils -   ***** Running training *****\n","03/28/2021 18:10:34 - INFO - bert_utils -     Num examples = 5\n","03/28/2021 18:10:34 - INFO - bert_utils -     Num token vocab = 59\n","03/28/2021 18:10:34 - INFO - bert_utils -     Batch size = 8\n","03/28/2021 18:10:34 - INFO - bert_utils -     Num steps = 0\n","03/28/2021 18:10:34 - INFO - bert_utils -   Loading word embeddings ... \n","03/28/2021 18:10:45 - INFO - bert_utils -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/28/2021 18:10:45 - INFO - bert_utils -   extracting archive file /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp8sz0b55q\n","03/28/2021 18:10:48 - INFO - bert_utils -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/28/2021 18:10:51 - INFO - bert_utils -   Weights of BertForDiscriminator not initialized from pretrained model: ['discriminator.weight', 'discriminator.bias']\n","03/28/2021 18:10:51 - INFO - bert_utils -   Weights from pretrained model not used in BertForDiscriminator: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0437, -0.0144, -0.1032, -0.0202, -0.0252, 0.019, 0.0131, -0.0011, -0.0168, -0.0128, -0.0008, 0.0121, -0.0426, 0.0192, 0.0158, -0.1123, 0.0189, 0.0492, 0.1644, -0.0394, -0.0248, 0.0215, -0.0129, -0.0496, 0.005, 0.0421, -0.0329, -0.0741, -0.1048, -0.0552, 0.0227, -0.0345, -0.0368, -0.0959, -0.0059, 0.0261, -0.0136, 0.0411, -0.0187, 0.0081, -0.0292, -0.0747, -0.0101, -0.0148, 0.0238, 0.0097, -0.0126, 0.0149, -0.0238, -0.0384, 0.0375, 0.071, -0.5428, -0.0469, 0.0233, 0.0216, 0.0095, 0.0793, -0.043, 0.0157, 0.0183, -0.0651, -0.0323, -0.0266, 0.0534, -0.0686, 0.0119, -0.0291, -0.0892, -0.0047, 0.0317, 0.0145, 0.024, -0.0603, -0.0286, 0.0417, -0.0266, -0.0207, -0.0179, 0.0923, -0.0155, -0.0167, 0.0018, -0.167, -0.0138, -0.0397, 0.004, 0.069, 0.2466, 0.0105, -0.029, -0.0633, 0.0889, -0.0542, -0.0125, 0.0102, -0.0743, -0.0065, -0.0179, 0.0513, -0.0914, -0.0053, -0.0592, 0.0338, -0.1552, 0.002, -0.0752, 0.0243, -0.0747, -0.0947, -0.071, -0.1083, -0.0362, 0.0888, -0.007, -0.0735, 0.0336, -0.0083, 0.0342, -0.3091, -0.0721, -0.0342, -0.0242, -0.2222, -0.0489, 0.137, -0.0865, 0.0516, 0.03, -0.0035, 0.0154, -0.0025, -0.0195, -0.0189, -0.0473, -0.1336, -0.001, -0.0033, -0.0832, 0.0505, -0.0475, -0.0468, 0.0717, 0.1783, 0.0927, 0.0197, 0.0592, -0.0596, 0.0006, 0.0368, 0.0973, 0.0478, -0.021, -0.0317, -0.0101, 0.0674, 0.0452, 0.0379, -0.0198, -0.0358, -0.0723, -0.0105, -0.0479, 0.0109, -0.1331, -0.0287, 0.0535, -0.0281, -0.0316, -0.0065, -0.0265, 0.0235, 0.0284, 0.0521, 0.0836, -0.1519, 0.1407, -0.2958, 0.0723, -0.0243, 0.0768, -0.0225, 0.0749, 0.0447, 0.0244, 0.1271, -0.0649, 0.0196, 0.4245, 0.0026, 0.0269, 0.0098, -0.0427, 0.0266, 0.0082, -0.0294, -0.0156, -0.0197, 0.2449, -0.0039, 0.0266, -0.2229, -0.0209, -0.0469, 0.0384, 0.0065, 0.0036, 0.0006, -0.0314, 0.0044, 0.0778, 0.0198, -0.0378, -0.0136, 0.0212, -0.0012, 0.0102, 0.0594, 0.0661, -0.0734, 0.0559, 0.0097, 0.0514, 0.019, 0.025, -0.0928, 0.045, 0.005, -0.0685, -0.114, 0.1314, 0.0066, 0.2853, -0.0352, 0.0347, -0.365, -0.0628, 0.1728, -0.2572, 0.0756, -0.0777, 0.027, 0.0623, -0.0096, 0.0195, -0.0214, 0.0187, -0.0461, -0.0247, 0.3452, 0.0195, -0.0091, -0.0981, 0.0356, -0.0193, 0.0092, -0.0804, -0.0073, 0.0464, 0.0069, 0.0712, -0.0265, 0.0014, -0.0015, -0.3931, -0.0186, -0.0188, -0.009, -0.0198, -0.031, -0.051, -0.0472, 0.0292, 0.0231, -0.035, -0.005, 0.0204, 0.0888, -0.0003, 0.0259, 0.036, -0.2131, 0.0651, -0.0641, -0.0229, 0.0442, -0.0742, 0.0325, -0.0619, 0.0497, 0.0603, 0.0174, -0.0593, 0.0226, -0.0546, 0.013, 0.0049, 0.0448, -0.0326, -0.013]\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  37\n","tok_id :  37\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.052, -0.0294, 0.0662, -0.0196, 0.0562, -0.0476, -0.0404, -0.1003, -0.0313, 0.0058, -0.0193, 0.008, -0.0415, 0.1196, 0.0555, -0.0765, 0.0005, 0.0354, -0.1444, -0.0218, 0.077, -0.1535, 0.0877, 0.162, 0.0346, 0.0851, 0.001, 0.0243, 0.0587, -0.04, -0.0109, -0.029, 0.0163, 0.0215, 0.0047, -0.1097, 0.0595, -0.1733, -0.0144, -0.0021, 0.1223, -0.0542, 0.0603, -0.0935, 0.0581, -0.1618, -0.0367, 0.0942, 0.0466, -0.034, -0.104, -0.0293, -0.5887, 0.0164, -0.0315, -0.0253, -0.039, 0.0221, -0.1189, 0.1224, 0.0414, 0.0568, 0.0248, -0.004, -0.1998, -0.1871, 0.0959, -0.1397, -0.136, -0.0227, -0.1149, 0.005, 0.0852, -0.0841, -0.1255, 0.0172, 0.0228, -0.0628, -0.0599, 0.1372, 0.0186, -0.0327, 0.0482, -0.2448, 0.0334, 0.0841, -0.0758, 0.0206, -0.4397, -0.025, -0.054, -0.0346, -0.0057, 0.0891, -0.0616, -0.0016, -0.0335, -0.0542, -0.0714, -0.0707, -0.2133, 0.0412, -0.0672, 0.0981, -0.3939, -0.085, -0.1221, -0.0232, 0.1097, -0.1054, -0.0446, -0.2737, 0.0793, -0.0647, 0.153, -0.1979, 0.0088, -0.0935, 0.0276, -0.3312, 0.0648, -0.0808, 0.054, -0.0313, -0.1577, 0.2038, 0.0053, -0.1417, 0.1395, 0.0545, 0.2468, -0.1229, -0.1038, -0.0565, -0.027, 0.2695, 0.104, 0.2153, -0.1012, -0.0243, -0.028, -0.0283, -0.1783, 0.3281, -0.0311, -0.1017, 0.1204, 0.0994, 0.0132, 0.1076, 0.1126, -0.1037, -0.0332, -0.0535, 0.0519, 0.0318, -0.0137, 0.0347, 0.0317, -0.0868, -0.0686, 0.0359, -0.0939, 0.2033, 0.0513, 0.0057, 0.0493, -0.0229, -0.0925, -0.0906, -0.1301, 0.0273, 0.1754, -0.1269, 0.189, -0.2194, 0.2082, 0.1058, -0.1408, -0.0965, 0.0585, 0.0207, 0.0668, -0.0127, -0.0278, 0.074, 0.0081, -0.0431, 0.8819, -0.0017, 0.0222, -0.0824, -0.1692, 0.0367, -0.0723, -0.014, -0.0677, 0.0994, 0.1914, -0.1304, -0.0475, 0.035, 0.0831, -0.0874, 0.0876, -0.0784, 0.006, -0.0642, 0.0893, 0.0028, 0.1467, -0.1508, 0.0415, 0.0912, -0.0696, -0.0012, 0.0188, 0.1286, -0.0516, 0.096, -0.1434, 0.0708, -0.0041, 0.0725, -0.0137, -0.0933, 0.1138, 0.0651, -0.0779, -0.238, 0.1244, 0.1053, 0.2864, 0.1014, 0.1074, 0.0836, 0.1157, 0.106, -0.2746, -0.0583, 0.0355, -0.0039, 0.0105, 0.116, 0.0939, 0.1633, -0.0605, 0.0444, 0.1468, 0.3065, -0.0717, 0.1178, -0.0014, 0.0606, -0.2838, -0.054, -0.0281, 0.0148, -0.0554, 0.0352, 0.0071, -0.047, -0.0562, -0.0249, -0.1897, 0.0359, 0.0688, -0.0628, -0.0416, 0.0313, -0.0206, 0.1185, -0.0501, 0.0159, -0.0199, -0.0524, 0.1503, -0.0864, -0.1211, -0.02, 0.0191, -0.1345, -0.0777, 0.1295, 0.0247, 0.018, 0.0964, 0.1789, -0.062, -0.0767, -0.0568, 0.0522, -0.0159, -0.0909, -0.1266, 0.0103, -0.1333, 0.153, 0.0375, 0.2267]\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","/root/bert_defender_master_vastai_new_instance/optimization.py:132: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.36s/it]\u001b[A\n","03/28/2021 18:10:55 - INFO - bert_utils -     flaw_f1 = 0.05309734513274336\n","03/28/2021 18:10:55 - INFO - bert_utils -     flaw_precision = 0.027573529411764705\n","03/28/2021 18:10:55 - INFO - bert_utils -     flaw_recall = 0.7142857142857143\n","03/28/2021 18:10:55 - INFO - bert_utils -     loss = 0.8163223266601562\n","Epoch:   4%|█▍                                   | 1/25 [00:05<02:00,  5.04s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0897, 0.016, -0.0571, 0.0405, -0.0696, -0.1237, 0.0301, 0.0248, -0.0303, 0.0174, 0.0063, 0.0184, 0.0217, -0.0257, 0.035, -0.0242, 0.0029, 0.0188, -0.057, 0.0252, -0.021, -0.0008, 0.036, -0.0729, -0.0665, 0.0989, 0.0676, 0.0852, -0.0089, 0.0313, -0.0069, -0.0032, -0.0462, 0.0497, 0.0261, 0.0268, -0.031, -0.1361, -0.0062, 0.0375, -0.032, -0.0106, 0.0534, -0.0187, 0.0638, 0.0094, 0.0047, -0.053, 0.0093, -0.0087, 0.0004, 0.0493, -0.6296, 0.0222, 0.019, 0.0268, -0.0426, 0.0057, -0.1683, 0.0244, -0.0213, -0.0181, 0.0421, -0.0309, -0.0089, 0.0032, 0.0108, -0.0049, 0.0258, 0.0278, -0.0163, 0.02, 0.0164, -0.0954, -0.0032, 0.0043, 0.0104, -0.0088, 0.0007, 0.035, -0.0206, -0.0083, -0.0114, -0.1869, 0.0258, 0.001, 0.0085, 0.0151, 0.2125, 0.0071, 0.0319, -0.0482, 0.0621, 0.0626, 0.0159, -0.0013, 0.0087, 0.0686, -0.0034, 0.0238, -0.0452, -0.0198, 0.0112, 0.0109, -0.1022, -0.0272, 0.2337, -0.0465, 0.1592, -0.0407, -0.1029, -0.0487, -0.0676, 0.0676, -0.0328, 0.0323, 0.0077, 0.019, 0.0017, -0.2974, 0.0011, -0.0356, 0.0693, -0.048, -0.0821, -0.0644, -0.0284, -0.0191, -0.0233, 0.0353, -0.0463, 0.0656, 0.0019, -0.0212, -0.0309, -0.3534, -0.0309, 0.0076, -0.0419, 0.0457, -0.0306, 0.0357, 0.0667, 0.3659, 0.0149, -0.0443, 0.0068, -0.0378, 0.0146, 0.0215, 0.1081, 0.0124, -0.0437, -0.043, 0.0258, 0.0213, -0.0309, -0.0018, -0.0067, 0.0172, 0.0089, -0.0171, 0.0275, -0.0518, -0.184, -0.013, -0.0241, 0.0526, -0.028, 0.0051, 0.0163, -0.0165, 0.0161, 0.1237, 0.0804, -0.0789, 0.0386, -0.3892, 0.0157, -0.0246, 0.0477, -0.0045, -0.0214, 0.0173, -0.0191, -0.1382, -0.0111, 0.0712, 0.1514, 0.0291, 0.0555, -0.0039, 0.0028, -0.0277, -0.0275, -0.0177, -0.0338, -0.0372, 0.2071, 0.046, -0.0294, 0.0435, -0.0169, -0.0121, 0.0253, 0.0198, 0.0918, 0.0193, 0.0668, 0.0288, 0.004, -0.0439, -0.0302, 0.0064, 0.0364, 0.0543, -0.0338, 0.0159, 0.0617, -0.0941, -0.0086, -0.0092, 0.03, -0.0241, -0.035, -0.0621, 0.0175, 0.0374, 0.0034, 0.0344, 0.1286, -0.0267, 0.1861, 0.0489, -0.0032, 0.018, -0.0228, 0.2414, -0.0935, 0.0612, -0.0209, 0.0136, 0.0392, -0.0135, -0.0253, 0.0335, 0.0095, 0.0419, 0.0076, 0.4522, -0.0188, 0.0233, -0.0474, 0.0159, -0.009, 0.0265, 0.0336, 0.0221, 0.0472, 0.0048, 0.0962, 0.0344, -0.0515, -0.0087, -0.098, -0.0288, 0.0377, 0.0202, -0.2979, -0.0387, -0.0198, -0.0161, -0.0045, 0.0087, -0.0387, 0.0421, 0.0383, 0.0258, 0.0069, -0.0298, -0.0198, -0.0152, 0.0033, 0.0075, 0.0358, -0.0155, -0.0111, 0.076, -0.0452, 0.0697, 0.0299, -0.0029, -0.0348, -0.027, 0.0351, 0.0559, 0.0591, 0.1559, -0.0254, -0.0259]\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.30s/it]\u001b[A\n","03/28/2021 18:11:00 - INFO - bert_utils -     flaw_f1 = 0.0\n","03/28/2021 18:11:00 - INFO - bert_utils -     flaw_precision = 0.0\n","03/28/2021 18:11:00 - INFO - bert_utils -     flaw_recall = 0.0\n","03/28/2021 18:11:00 - INFO - bert_utils -     loss = 0.44367465376853943\n","Epoch:   8%|██▉                                  | 2/25 [00:10<01:54,  4.99s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0369, -0.0747, -0.0469, 0.0361, -0.0919, -0.0009, -0.0225, -0.0086, 0.0385, 0.0186, 0.0531, -0.0053, 0.0438, 0.0318, 0.0474, -0.0007, 0.041, 0.0475, -0.1702, -0.0859, 0.0242, 0.0221, 0.0487, -0.0435, -0.064, -0.3495, 0.0443, -0.0841, -0.0702, -0.1877, 0.0284, 0.064, -0.1133, -0.0202, 0.002, 0.0423, -0.0616, -0.1389, -0.0825, 0.0436, 0.0003, -0.0068, -0.1889, 0.0691, 0.2175, -0.057, -0.0354, -0.0194, -0.0878, 0.0954, -0.036, 0.193, -0.6756, -0.0179, -0.1067, -0.0159, -0.0191, -0.0452, 0.1099, -0.0407, -0.0379, 0.0292, -0.0908, -0.0199, -0.0426, 0.0648, -0.018, 0.0435, -0.01, -0.0118, 0.0286, 0.0318, -0.0296, 0.0815, 0.0263, 0.0283, -0.0327, -0.1023, -0.0261, -0.0393, 0.0171, -0.0652, 0.0306, -0.2258, 0.0422, -0.0264, -0.0298, 0.0358, 0.0322, -0.0455, -0.0502, 0.0434, 0.0162, -0.0809, -0.12, -0.0164, -0.0162, -0.0172, -0.0128, -0.0066, -0.1001, -0.011, 0.0629, 0.0164, -0.1474, 0.0805, 0.2876, 0.0508, 0.1542, 0.0635, 0.0978, 0.1995, -0.0425, 0.009, 0.0627, 0.0527, -0.0341, 0.1002, 0.0001, -0.3458, -0.0683, 0.0053, 0.0336, 0.0839, 0.165, 0.1572, 0.0059, 0.1544, -0.1236, 0.0389, 0.0085, -0.0136, -0.1793, 0.0274, -0.0333, -0.2917, 0.0114, -0.1436, 0.1732, -0.0428, -0.0056, 0.0282, 0.0279, 0.2743, -0.0107, -0.0348, 0.0237, 0.136, -0.0467, 0.0389, 0.0732, -0.0709, 0.0007, -0.0509, 0.0266, 0.0308, -0.0009, -0.0623, -0.0245, 0.0403, -0.0138, -0.0155, 0.0327, -0.0914, -0.2653, 0.0259, 0.0943, 0.1989, 0.0456, -0.0408, 0.1517, 0.0092, -0.0148, 0.1394, 0.1615, -0.1643, 0.1515, -0.0187, 0.0064, -0.0194, 0.0148, 0.0217, 0.0553, 0.0124, 0.1067, -0.3425, -0.0749, -0.1354, 0.0049, 0.0316, 0.0313, -0.015, 0.0393, -0.0033, 0.0031, 0.0138, -0.0337, -0.0591, 0.1925, -0.0098, -0.0113, 0.0, -0.0543, 0.0013, 0.0086, 0.0152, -0.0175, -0.0826, -0.0609, 0.0307, 0.0502, -0.0115, -0.0115, -0.0416, 0.0216, -0.0092, -0.2547, 0.0468, -0.0902, 0.0619, 0.0911, 0.0074, 0.0039, 0.088, -0.0067, -0.1804, 0.0322, -0.0157, -0.0377, 0.1205, -0.1194, -0.0555, 0.2795, -0.0318, -0.0034, 0.1598, -0.0423, -0.0498, -0.2052, -0.0395, -0.0274, -0.0264, -0.024, -0.0693, 0.0042, 0.1378, 0.0812, 0.052, -0.0359, 0.2623, 0.0796, 0.2137, 0.0467, 0.0616, -0.0922, 0.0232, 0.0758, 0.033, 0.0098, 0.06, -0.0736, 0.0035, 0.0342, 0.0351, -0.049, -0.0351, 0.2016, -0.0154, 0.0575, 0.0059, 0.0248, 0.0083, -0.064, -0.0317, -0.0728, -0.004, -0.1209, 0.0036, -0.0315, -0.0304, -0.1957, 0.0333, 0.0718, -0.1432, -0.0835, -0.0423, 0.0635, 0.0478, -0.0796, 0.0728, 0.0468, -0.0089, 0.0349, 0.0238, 0.0034, -0.0854, 0.0075, 0.2231, 0.0352, 0.0672]\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.018, 0.0137, 0.0563, 0.0203, -0.0224, -0.0579, 0.0017, -0.0083, -0.0074, 0.0621, 0.0457, -0.0904, 0.0844, 0.013, -0.1144, 0.0202, -0.0783, -0.0346, -0.0351, 0.0287, -0.0507, -0.0797, 0.0259, 0.0543, 0.0421, -0.1147, -0.0449, -0.0618, -0.0264, 0.0732, 0.0393, -0.0798, -0.0383, -0.0212, 0.0242, -0.0619, 0.0028, -0.0545, -0.1246, 0.0882, -0.0696, 0.0284, -0.1216, 0.0243, 0.0088, 0.0228, -0.0419, 0.0312, 0.0095, -0.0116, -0.0563, -0.0754, -0.6494, -0.0508, 0.0136, -0.0307, -0.0149, -0.052, 0.0104, 0.0411, 0.0321, -0.0849, 0.0666, -0.0499, -0.0406, -0.0305, 0.0453, 0.0657, -0.0713, 0.0026, -0.0071, -0.0073, -0.012, -0.0021, 0.0152, 0.0728, -0.0177, 0.0067, 0.0472, 0.2579, 0.0086, 0.0526, -0.0531, -0.2221, -0.005, -0.0434, 0.0486, 0.0129, -0.0179, 0.0281, -0.0121, 0.0198, 0.0175, -0.026, -0.0251, -0.0165, 0.0305, 0.0568, 0.0422, -0.0578, -0.1283, -0.0809, -0.0824, 0.0095, 0.0213, 0.0042, 0.1039, 0.2486, 0.0316, 0.0603, 0.0895, 0.0652, 0.0716, 0.0304, -0.2216, -0.0121, 0.0162, -0.0474, -0.0523, -0.3365, -0.0059, -0.0389, -0.0493, 0.054, 0.0473, 0.1572, -0.0403, 0.2288, -0.1701, 0.0341, 0.1491, -0.042, 0.0274, -0.0687, 0.0232, -0.2326, -0.0087, -0.0353, 0.0201, -0.0392, -0.0263, -0.0005, 0.0106, 0.3222, 0.1188, -0.0025, 0.1381, -0.0301, -0.1146, 0.0012, -0.0458, 0.0793, 0.0299, -0.0276, 0.0263, -0.0017, -0.0616, -0.0363, 0.0757, -0.0887, -0.0505, 0.0739, 0.0222, 0.0485, -0.1574, 0.0128, 0.115, -0.0137, 0.0246, 0.0834, 0.062, 0.0275, -0.0376, -0.0543, 0.242, 0.0166, 0.1765, -0.1171, 0.0097, 0.0407, 0.0245, 0.0482, 0.0543, 0.0164, 0.0306, 0.0662, -0.0758, -0.0842, -0.1406, 0.0708, -0.0021, -0.032, 0.0435, 0.0469, -0.0045, 0.0869, 0.0144, 0.0109, 0.1798, -0.0279, 0.0251, -0.0165, -0.0496, -0.0203, 0.0504, 0.0375, 0.055, -0.0736, -0.1372, 0.0084, 0.0426, -0.001, -0.0611, -0.003, 0.0637, -0.0185, 0.0292, 0.022, -0.0052, 0.0605, 0.1659, -0.0197, -0.073, 0.0347, 0.0514, -0.0462, -0.033, 0.1258, -0.0531, -0.1589, -0.0904, -0.0152, 0.3261, -0.1132, -0.0136, 0.0702, -0.02, 0.0705, -0.1598, 0.0617, -0.0651, 0.0309, 0.0323, -0.0752, -0.0333, 0.0489, -0.0132, 0.0433, 0.0011, 0.3065, 0.0577, 0.1041, 0.0583, -0.0108, -0.1463, -0.0195, -0.0661, 0.0006, -0.0628, 0.0766, -0.1766, -0.1066, -0.0112, -0.0637, -0.3468, -0.0268, -0.0201, -0.0342, 0.05, 0.047, -0.0543, 0.0142, -0.102, -0.0296, -0.0426, 0.0159, 0.0272, -0.065, -0.0514, -0.0284, 0.0657, -0.0163, 0.0494, -0.0867, 0.022, 0.0482, 0.0015, 0.0358, 0.0483, 0.0545, -0.0117, -0.0571, 0.014, -0.047, 0.0189, -0.0918, -0.0813, 0.2471, 0.0845, -0.0592]\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.46s/it]\u001b[A\n","03/28/2021 18:11:05 - INFO - bert_utils -     flaw_f1 = 0.0\n","03/28/2021 18:11:05 - INFO - bert_utils -     flaw_precision = 0.0\n","03/28/2021 18:11:05 - INFO - bert_utils -     flaw_recall = 0.0\n","03/28/2021 18:11:05 - INFO - bert_utils -     loss = 0.2200097143650055\n","Epoch:  12%|████▍                                | 3/25 [00:15<01:50,  5.04s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.41s/it]\u001b[A\n","03/28/2021 18:11:10 - INFO - bert_utils -     flaw_f1 = 0.0\n","03/28/2021 18:11:10 - INFO - bert_utils -     flaw_precision = 0.0\n","03/28/2021 18:11:10 - INFO - bert_utils -     flaw_recall = 0.0\n","03/28/2021 18:11:10 - INFO - bert_utils -     loss = 0.15955662727355957\n","Epoch:  16%|█████▉                               | 4/25 [00:20<01:45,  5.04s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.01, -0.1164, -0.1155, 0.0128, 0.0066, 0.1118, 0.0019, 0.1206, 0.0421, -0.101, -0.004, -0.0397, -0.0289, 0.0068, -0.0612, 0.0406, 0.0486, 0.0586, 0.1727, -0.0766, 0.0337, -0.0184, -0.0366, 0.2488, 0.0496, -0.0027, -0.0022, -0.0953, 0.0506, -0.1002, 0.0485, 0.0158, -0.0052, 0.0754, 0.1312, 0.0125, -0.0013, 0.1345, 0.1304, -0.0553, 0.0419, -0.0352, -0.0879, 0.011, 0.1502, 0.077, 0.0504, -0.0595, 0.0213, 0.0447, -0.0306, 0.1326, -0.6322, -0.0197, 0.0337, -0.0027, -0.1529, -0.1602, -0.0631, -0.0668, -0.0243, 0.0625, -0.1633, -0.0073, -0.0559, -0.1796, -0.0004, -0.0384, 0.0424, -0.0468, 0.0202, -0.0719, -0.0158, 0.0609, -0.0076, -0.0106, 0.2165, 0.0046, 0.0026, 0.1756, 0.018, 0.0555, 0.0287, -0.2628, 0.0122, 0.1043, 0.109, -0.0115, -0.2083, -0.0649, 0.0975, 0.007, -0.001, -0.124, 0.03, 0.0333, -0.0295, 0.0596, 0.0244, -0.0265, -0.1616, -0.0581, 0.0439, 0.0733, -0.0714, -0.0393, 0.2064, 0.1114, -0.0533, 0.119, -0.0603, 0.0178, -0.0118, 0.0112, 0.1174, -0.0652, 0.0505, -0.1118, 0.0196, -0.3306, 0.0246, -0.0156, -0.0363, 0.0558, -0.0872, 0.1793, -0.0551, 0.2096, -0.3445, 0.0282, -0.0852, 0.0196, -0.1081, -0.0563, 0.138, -0.1404, 0.0364, -0.0088, 0.1013, 0.0078, 0.0305, -0.0422, -0.0317, 0.3136, -0.01, 0.0061, 0.1233, -0.1092, 0.0066, -0.0221, 0.1111, 0.0233, 0.0763, 0.0268, -0.0634, 0.0247, -0.0976, 0.112, 0.0448, 0.0234, 0.2722, -0.0352, -0.0033, -0.039, -0.1779, -0.0273, 0.1093, 0.0029, -0.0524, 0.0917, -0.0883, 0.0905, 0.0899, 0.0649, -0.0216, 0.0238, 0.232, -0.1989, -0.0122, 0.0077, -0.0079, -0.1072, -0.0594, -0.0178, -0.0088, 0.1284, 0.0422, -0.0185, 0.0461, 0.0493, 0.1004, 0.0176, -0.0153, -0.0245, -0.0135, 0.0783, 0.0164, -0.0252, 0.295, -0.0319, 0.1103, 0.01, -0.0029, -0.1097, -0.0587, -0.0045, -0.0928, -0.306, 0.0651, -0.0328, 0.0264, -0.1218, -0.0211, 0.0559, -0.0267, 0.0574, -0.2908, 0.06, 0.1002, -0.251, 0.0734, -0.2104, 0.0144, 0.0174, 0.0529, -0.0086, 0.0128, 0.0311, -0.1217, 0.0557, 0.0154, 0.0036, 0.2933, 0.1089, 0.0268, 0.248, 0.0073, 0.0447, -0.2185, 0.071, -0.0075, -0.0175, -0.0303, -0.0635, 0.0388, 0.1332, 0.1139, -0.0396, 0.0176, 0.3505, -0.0208, -0.0023, 0.0646, 0.0537, -0.0967, 0.0124, -0.0847, 0.0001, 0.0942, 0.0022, 0.0561, 0.0588, -0.0494, 0.0042, -0.2125, -0.047, 0.0718, 0.0505, -0.045, 0.0896, 0.0691, -0.0113, -0.0217, -0.0209, -0.0119, 0.0106, 0.0667, 0.0265, 0.0548, -0.0067, 0.0107, -0.0307, 0.0228, 0.0027, 0.0046, 0.0296, -0.1323, 0.1093, -0.4649, 0.0183, 0.087, -0.0078, -0.1624, 0.0289, 0.0533, -0.0682, -0.0692, 0.104, 0.0964, 0.0392]\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0004, 0.0032, -0.0204, 0.0479, -0.045, -0.1165, 0.0142, 0.0068, -0.0334, -0.0504, 0.0224, -0.0029, -0.0258, 0.0265, 0.0059, -0.0459, 0.0753, 0.0422, 0.0269, -0.0283, -0.1013, 0.0992, -0.0114, 0.0583, -0.1547, -0.1972, -0.0282, -0.1391, -0.0288, -0.0283, 0.0273, 0.0189, 0.0275, -0.054, 0.0458, 0.0306, -0.0158, 0.2338, 0.0206, -0.0081, -0.018, -0.0059, 0.1045, 0.0409, 0.0352, -0.0038, 0.0403, -0.0129, -0.0074, 0.0003, -0.0484, 0.0412, -0.5999, 0.0224, -0.0153, 0.0296, 0.0011, 0.064, -0.1061, 0.0009, -0.0038, -0.0197, 0.0198, -0.0056, -0.0287, 0.0157, -0.0262, -0.0003, -0.0033, -0.0007, -0.0421, 0.0367, -0.024, -0.0519, -0.0098, 0.0297, 0.0251, -0.011, -0.0059, -0.0042, 0.0191, 0.0912, 0.0142, -0.0469, 0.0047, -0.0461, -0.0007, -0.0242, -0.1023, 0.0221, -0.0055, -0.0246, 0.0235, 0.1175, 0.0527, -0.0013, 0.0069, 0.0075, 0.0653, 0.0739, -0.0852, -0.017, -0.0102, -0.0225, -0.3273, -0.004, -0.0259, 0.0374, -0.1285, -0.026, 0.0512, 0.0295, -0.0648, 0.008, 0.01, -0.0888, 0.0268, 0.0209, 0.0172, -0.2961, 0.0117, -0.1024, -0.0671, -0.1541, 0.0014, 0.0895, -0.009, -0.0117, 0.0023, 0.0197, 0.0513, 0.0514, -0.0087, -0.0016, -0.0187, -0.1328, -0.0309, 0.0093, -0.016, -0.0328, 0.0123, -0.0135, 0.0707, -0.4418, -0.0293, 0.0321, 0.0725, -0.015, -0.0241, -0.0308, 0.1423, 0.0205, -0.0443, -0.0164, -0.004, 0.041, 0.0311, 0.0291, -0.0144, 0.0029, 0.1101, 0.0305, 0.0559, -0.1322, -0.2437, -0.0496, 0.1666, -0.0371, -0.0255, -0.0138, -0.2298, -0.006, 0.0206, 0.0459, -0.1113, -0.0365, -0.0248, -0.3067, 0.0166, 0.0334, 0.0021, -0.0163, 0.0237, -0.025, 0.0108, -0.1783, 0.0301, -0.0656, 0.1937, 0.0227, 0.0142, -0.0309, -0.0313, 0.0592, 0.0157, -0.0146, 0.0691, -0.0355, 0.2422, 0.0033, 0.0094, 0.0925, -0.028, -0.0084, 0.1211, 0.0053, -0.0082, 0.0111, -0.0628, -0.0273, 0.0068, 0.0178, -0.0397, 0.0079, 0.013, -0.0139, -0.1617, -0.035, -0.059, -0.0596, 0.0098, 0.0481, 0.0207, -0.0105, 0.0466, 0.2175, 0.0148, 0.0207, -0.0174, -0.1542, 0.0322, -0.0149, 0.6264, 0.0136, -0.0067, 0.243, -0.0644, -0.1055, -0.189, -0.0042, -0.0424, -0.0319, 0.0419, 0.0078, -0.0486, -0.0519, -0.0194, 0.032, 0.0181, 0.0615, -0.0305, -0.0008, -0.0281, 0.0642, 0.0569, 0.0512, -0.0689, -0.01, 0.0339, -0.001, -0.0024, 0.0837, 0.0032, -0.0312, -0.1129, 0.0081, -0.032, 0.0065, 0.0968, -0.0263, -0.0471, -0.0256, -0.0003, 0.0188, -0.0397, 0.0475, -0.0811, -0.043, -0.0117, 0.0414, -0.0028, 0.0524, 0.0216, 0.082, 0.0114, -0.0173, -0.0362, -0.0067, -0.0118, 0.0435, 0.0637, 0.0022, -0.0096, -0.036, -0.1679, 0.0304, 0.029, 0.207, 0.0689, -0.0467]\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.36s/it]\u001b[A\n","03/28/2021 18:11:15 - INFO - bert_utils -     flaw_f1 = 0.0\n","03/28/2021 18:11:15 - INFO - bert_utils -     flaw_precision = 0.0\n","03/28/2021 18:11:15 - INFO - bert_utils -     flaw_recall = 0.0\n","03/28/2021 18:11:15 - INFO - bert_utils -     loss = 0.10847373306751251\n","Epoch:  20%|███████▍                             | 5/25 [00:25<01:41,  5.07s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.35s/it]\u001b[A\n","03/28/2021 18:11:20 - INFO - bert_utils -     flaw_f1 = 0.05714285714285715\n","03/28/2021 18:11:20 - INFO - bert_utils -     flaw_precision = 1.0\n","03/28/2021 18:11:20 - INFO - bert_utils -     flaw_recall = 0.029411764705882353\n","03/28/2021 18:11:20 - INFO - bert_utils -     loss = 0.11955753713846207\n","Epoch:  24%|████████▉                            | 6/25 [00:30<01:34,  5.00s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0897, 0.016, -0.0571, 0.0405, -0.0696, -0.1237, 0.0301, 0.0248, -0.0303, 0.0174, 0.0063, 0.0184, 0.0217, -0.0257, 0.035, -0.0242, 0.0029, 0.0188, -0.057, 0.0252, -0.021, -0.0008, 0.036, -0.0729, -0.0665, 0.0989, 0.0676, 0.0852, -0.0089, 0.0313, -0.0069, -0.0032, -0.0462, 0.0497, 0.0261, 0.0268, -0.031, -0.1361, -0.0062, 0.0375, -0.032, -0.0106, 0.0534, -0.0187, 0.0638, 0.0094, 0.0047, -0.053, 0.0093, -0.0087, 0.0004, 0.0493, -0.6296, 0.0222, 0.019, 0.0268, -0.0426, 0.0057, -0.1683, 0.0244, -0.0213, -0.0181, 0.0421, -0.0309, -0.0089, 0.0032, 0.0108, -0.0049, 0.0258, 0.0278, -0.0163, 0.02, 0.0164, -0.0954, -0.0032, 0.0043, 0.0104, -0.0088, 0.0007, 0.035, -0.0206, -0.0083, -0.0114, -0.1869, 0.0258, 0.001, 0.0085, 0.0151, 0.2125, 0.0071, 0.0319, -0.0482, 0.0621, 0.0626, 0.0159, -0.0013, 0.0087, 0.0686, -0.0034, 0.0238, -0.0452, -0.0198, 0.0112, 0.0109, -0.1022, -0.0272, 0.2337, -0.0465, 0.1592, -0.0407, -0.1029, -0.0487, -0.0676, 0.0676, -0.0328, 0.0323, 0.0077, 0.019, 0.0017, -0.2974, 0.0011, -0.0356, 0.0693, -0.048, -0.0821, -0.0644, -0.0284, -0.0191, -0.0233, 0.0353, -0.0463, 0.0656, 0.0019, -0.0212, -0.0309, -0.3534, -0.0309, 0.0076, -0.0419, 0.0457, -0.0306, 0.0357, 0.0667, 0.3659, 0.0149, -0.0443, 0.0068, -0.0378, 0.0146, 0.0215, 0.1081, 0.0124, -0.0437, -0.043, 0.0258, 0.0213, -0.0309, -0.0018, -0.0067, 0.0172, 0.0089, -0.0171, 0.0275, -0.0518, -0.184, -0.013, -0.0241, 0.0526, -0.028, 0.0051, 0.0163, -0.0165, 0.0161, 0.1237, 0.0804, -0.0789, 0.0386, -0.3892, 0.0157, -0.0246, 0.0477, -0.0045, -0.0214, 0.0173, -0.0191, -0.1382, -0.0111, 0.0712, 0.1514, 0.0291, 0.0555, -0.0039, 0.0028, -0.0277, -0.0275, -0.0177, -0.0338, -0.0372, 0.2071, 0.046, -0.0294, 0.0435, -0.0169, -0.0121, 0.0253, 0.0198, 0.0918, 0.0193, 0.0668, 0.0288, 0.004, -0.0439, -0.0302, 0.0064, 0.0364, 0.0543, -0.0338, 0.0159, 0.0617, -0.0941, -0.0086, -0.0092, 0.03, -0.0241, -0.035, -0.0621, 0.0175, 0.0374, 0.0034, 0.0344, 0.1286, -0.0267, 0.1861, 0.0489, -0.0032, 0.018, -0.0228, 0.2414, -0.0935, 0.0612, -0.0209, 0.0136, 0.0392, -0.0135, -0.0253, 0.0335, 0.0095, 0.0419, 0.0076, 0.4522, -0.0188, 0.0233, -0.0474, 0.0159, -0.009, 0.0265, 0.0336, 0.0221, 0.0472, 0.0048, 0.0962, 0.0344, -0.0515, -0.0087, -0.098, -0.0288, 0.0377, 0.0202, -0.2979, -0.0387, -0.0198, -0.0161, -0.0045, 0.0087, -0.0387, 0.0421, 0.0383, 0.0258, 0.0069, -0.0298, -0.0198, -0.0152, 0.0033, 0.0075, 0.0358, -0.0155, -0.0111, 0.076, -0.0452, 0.0697, 0.0299, -0.0029, -0.0348, -0.027, 0.0351, 0.0559, 0.0591, 0.1559, -0.0254, -0.0259]\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.35s/it]\u001b[A\n","03/28/2021 18:11:25 - INFO - bert_utils -     flaw_f1 = 0.46616541353383456\n","03/28/2021 18:11:25 - INFO - bert_utils -     flaw_precision = 0.30392156862745096\n","03/28/2021 18:11:25 - INFO - bert_utils -     flaw_recall = 1.0\n","03/28/2021 18:11:25 - INFO - bert_utils -     loss = 0.23758944869041443\n","Epoch:  28%|██████████▎                          | 7/25 [00:35<01:29,  4.97s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.41s/it]\u001b[A\n","03/28/2021 18:11:30 - INFO - bert_utils -     flaw_f1 = 0.0\n","03/28/2021 18:11:30 - INFO - bert_utils -     flaw_precision = 0.0\n","03/28/2021 18:11:30 - INFO - bert_utils -     flaw_recall = 0.0\n","03/28/2021 18:11:30 - INFO - bert_utils -     loss = 0.07304968684911728\n","Epoch:  32%|███████████▊                         | 8/25 [00:40<01:24,  4.99s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.1208, 0.0144, -0.0927, -0.0181, 0.1125, 0.0495, -0.0467, -0.0193, 0.0746, -0.0119, 0.0817, 0.0189, 0.0596, 0.0681, -0.0196, 0.1208, -0.0401, -0.0571, -0.1717, 0.1402, -0.0256, 0.0317, 0.0454, 0.1437, -0.0175, 0.0, 0.0317, 0.201, 0.0216, -0.0175, 0.0565, -0.0301, 0.0244, -0.045, 0.0697, -0.031, 0.0226, -0.1532, -0.0043, -0.0578, 0.0305, -0.0136, 0.0062, -0.0937, -0.0747, 0.0217, -0.0568, 0.0469, 0.0378, -0.0502, -0.1851, 0.1019, -0.5416, -0.0081, 0.0269, 0.0144, 0.0698, -0.1973, -0.1727, 0.0096, 0.0363, 0.0037, -0.0497, 0.0526, -0.0885, -0.0309, 0.0668, -0.0395, 0.0433, -0.0078, -0.0366, 0.0286, -0.0301, 0.0023, 0.0284, -0.0965, -0.0228, -0.0075, -0.0968, 0.2231, 0.0464, -0.0177, -0.0262, -0.2496, -0.0343, 0.0082, -0.087, -0.0224, -0.5577, 0.0062, 0.0702, 0.0396, -0.0915, 0.0162, -0.0607, 0.0235, 0.0355, -0.1029, -0.0998, -0.0685, -0.271, 0.0459, 0.0225, 0.0368, 0.0759, -0.0153, -0.3556, 0.1072, 0.1017, -0.048, 0.0321, 0.0134, 0.0368, 0.0471, -0.2595, 0.0088, 0.0406, 0.0368, -0.0217, -0.2414, -0.0309, -0.0005, -0.0251, 0.0478, 0.1212, 0.2134, 0.0031, 0.2574, 0.0242, 0.0058, 0.0395, 0.027, -0.1224, -0.0122, 0.0541, -0.256, -0.0568, 0.0002, 0.0708, -0.0554, -0.0341, -0.0603, -0.0489, 0.4024, -0.0091, -0.0236, 0.1828, -0.0233, 0.0515, -0.108, -0.0503, -0.0573, 0.1002, -0.0205, 0.0517, 0.0068, -0.068, 0.0079, 0.0352, 0.0006, 0.0082, 0.0527, -0.0963, -0.0826, 0.1342, 0.0436, 0.1095, 0.0198, -0.0052, 0.0599, -0.1023, 0.0427, 0.08, -0.0834, 0.1454, 0.1132, 0.2139, -0.6224, -0.0544, -0.0541, 0.0465, 0.036, 0.0616, 0.0823, 0.0118, -0.3318, 0.0023, -0.0795, 0.6474, 0.0441, -0.0659, -0.0212, -0.0356, 0.0759, 0.0593, 0.0551, 0.0249, 0.0295, 0.279, -0.0214, -0.0544, -0.0026, 0.0026, -0.0114, 0.0507, 0.023, -0.0792, -0.0548, -0.0457, 0.0767, -0.1153, 0.0243, 0.034, 0.0527, -0.0762, 0.0999, -0.045, -0.0452, 0.0266, -0.0179, -0.0063, -0.0617, 0.0071, 0.0549, 0.1069, -0.0226, -0.0059, -0.0535, -0.0097, -0.0183, 0.2572, -0.0157, 0.1969, 0.0353, -0.1263, -0.4035, 0.0456, -0.1514, -0.2378, 0.124, 0.0007, 0.0017, 0.0054, 0.0166, -0.0424, 0.033, 0.0231, -0.0127, 0.0388, 0.3186, 0.0278, -0.0014, -0.0062, 0.0322, 0.3341, 0.003, -0.1596, 0.0029, -0.0605, -0.0301, -0.1263, -0.0143, -0.0255, 0.0705, -0.8316, -0.0347, 0.0973, 0.0364, -0.019, -0.018, 0.0257, 0.0578, -0.0185, 0.0114, -0.0141, 0.0957, 0.1123, -0.0257, 0.0211, -0.0602, 0.1877, -0.0612, 0.0284, -0.0978, -0.0529, -0.0266, -0.0446, -0.0117, -0.1348, -0.0104, 0.0987, -0.0837, 0.1619, 0.05, -0.0111, 0.0056, -0.1176, 0.2829, 0.0629, 0.0723]\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0312, -0.0133, -0.0627, -0.0361, 0.0148, 0.0319, 0.0276, 0.0409, -0.0129, -0.0438, 0.0246, -0.087, -0.0367, -0.0649, -0.124, -0.0144, 0.0648, 0.0107, 0.1197, -0.0742, -0.0414, 0.0702, -0.094, -0.0256, -0.0283, -0.06, -0.1258, -0.0883, -0.0243, -0.1137, 0.0832, -0.0581, 0.1514, 0.0574, 0.0183, 0.0585, 0.0279, 0.0626, -0.0219, 0.0182, -0.0218, 0.031, -0.06, -0.0169, -0.0235, 0.0086, 0.0327, -0.0764, 0.0083, -0.002, -0.0496, -0.117, -0.6124, -0.009, 0.0031, -0.0017, -0.0477, -0.0916, -0.0452, -0.087, 0.0233, 0.0115, -0.0832, -0.0693, -0.0229, 0.1129, 0.0037, 0.0396, -0.0102, -0.0518, 0.052, -0.0792, -0.0331, -0.0026, 0.012, 0.0248, 0.0572, 0.0273, 0.109, 0.1978, -0.0371, -0.073, 0.0189, -0.2491, -0.007, 0.035, -0.0297, -0.043, -0.141, 0.0299, 0.1118, 0.0242, 0.0185, 0.0143, 0.0662, 0.0149, -0.0218, -0.0294, 0.0472, -0.0472, -0.133, -0.0284, -0.0129, 0.0475, -0.0595, -0.0138, 0.087, 0.0678, 0.0049, 0.0161, 0.0955, -0.1739, 0.0335, 0.1083, -0.0178, 0.0103, 0.0859, -0.0761, 0.0037, -0.3074, -0.0399, -0.0065, -0.0188, 0.0208, -0.1801, 0.1801, -0.0101, 0.1407, -0.1353, -0.0314, -0.029, 0.0156, -0.0953, -0.0124, 0.0264, -0.167, 0.0313, -0.1026, 0.0345, 0.0018, 0.0197, -0.0375, 0.0248, 0.3195, -0.0365, 0.0152, 0.1094, -0.026, -0.0107, -0.0482, 0.0186, -0.0329, 0.0716, 0.0384, 0.0098, 0.0439, -0.0697, 0.0827, 0.0656, 0.0292, 0.042, -0.0535, 0.0484, 0.0079, -0.1818, -0.0666, 0.1992, -0.0962, -0.0236, 0.0963, -0.0563, 0.009, 0.0392, 0.0302, 0.0433, -0.0182, 0.1542, -0.1861, 0.0033, 0.0275, -0.0038, -0.0268, -0.0119, 0.0041, 0.0624, 0.179, -0.0033, -0.1647, 0.0734, 0.0999, 0.0103, -0.0102, 0.0046, 0.0222, 0.0389, 0.0567, -0.0187, 0.0296, 0.3547, 0.0149, 0.0383, 0.0586, -0.0006, -0.0506, -0.0019, 0.0274, -0.0577, -0.0971, -0.0288, -0.0018, 0.1553, -0.0006, -0.0519, 0.0523, 0.0322, 0.0971, -0.2139, -0.0007, -0.0589, -0.0342, 0.1299, -0.0024, 0.0472, -0.0086, 0.0416, -0.1646, -0.0201, -0.0121, 0.0873, -0.0313, -0.0525, -0.0498, 0.3044, -0.0349, -0.1103, 0.1482, -0.0257, -0.1129, -0.2016, 0.0639, 0.0723, -0.0193, -0.0216, -0.0315, -0.0082, -0.0027, -0.0274, -0.0552, -0.0741, 0.2908, 0.0462, 0.0082, 0.0626, 0.0313, 0.0459, -0.0516, -0.1157, 0.0854, 0.0207, 0.0754, 0.0232, -0.0468, 0.0433, 0.0039, -0.1978, -0.0108, -0.0164, 0.0037, -0.0748, -0.0055, 0.1568, 0.0083, 0.0083, 0.0333, 0.0282, 0.0223, 0.005, -0.012, 0.0558, 0.0323, 0.0078, 0.013, 0.0351, -0.1201, -0.0071, -0.0138, -0.0476, 0.0112, -0.1684, 0.0376, -0.0111, -0.0568, -0.0641, 0.0521, 0.0665, -0.0576, -0.0074, 0.2201, 0.0738, -0.0633]\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0009, -0.0881, 0.1765, -0.0176, -0.1541, 0.0409, 0.0307, -0.0144, -0.0246, 0.105, 0.027, 0.0544, -0.0062, -0.0447, 0.0202, -0.058, 0.164, -0.0453, -0.024, -0.0168, -0.1362, -0.0312, -0.0716, 0.1757, -0.1112, 0.0055, -0.0377, -0.1418, -0.1168, 0.1707, 0.017, -0.068, -0.1887, 0.0019, 0.0381, 0.0233, 0.0031, -0.0202, -0.0539, -0.036, -0.1265, 0.0073, 0.1233, -0.0215, -0.1209, -0.0334, 0.1118, 0.1577, 0.0902, 0.0078, -0.0016, 0.0598, -0.661, -0.0722, -0.1674, 0.1576, 0.1408, 0.0291, -0.0688, 0.0597, -0.0933, -0.0038, -0.045, 0.0151, -0.1437, -0.0867, 0.0815, -0.1201, -0.0307, 0.0743, -0.1026, -0.0983, 0.0382, -0.0869, 0.0487, -0.0953, 0.1129, -0.1147, 0.1359, 0.1193, 0.0537, 0.0182, 0.0141, -0.2045, 0.0028, 0.0297, -0.0625, -0.0117, 0.2854, -0.0367, 0.0642, 0.0183, 0.0189, -0.0093, -0.0304, 0.0167, 0.1154, -0.0762, 0.1511, 0.0994, -0.1831, 0.0124, -0.0153, -0.0587, -0.0917, -0.0008, -0.0941, -0.0359, 0.0014, -0.0287, -0.0127, 0.0417, -0.0886, -0.0065, 0.1682, -0.0144, -0.0772, -0.0103, -0.0385, -0.2877, -0.0109, 0.0506, -0.0174, 0.1893, -0.0117, 0.2806, 0.0132, 0.0948, 0.0031, 0.0773, -0.0818, -0.0596, -0.0435, -0.1742, -0.1914, 0.0599, 0.0749, 0.058, 0.0998, -0.0271, -0.0564, -0.1195, 0.0616, 0.1958, -0.0821, 0.0322, -0.0055, 0.0017, 0.065, 0.051, 0.0739, 0.0013, -0.0018, -0.1519, 0.01, 0.0759, -0.1445, 0.0589, -0.0538, -0.1143, 0.0199, -0.0943, 0.0982, -0.1638, -0.0821, -0.0061, 0.1112, -0.0863, 0.013, -0.2725, -0.0053, -0.1254, 0.0097, 0.03, 0.0313, 0.1254, 0.2384, -0.4316, 0.0763, 0.0028, -0.0084, 0.0688, -0.0141, 0.0091, -0.055, -0.0366, -0.1464, -0.1668, -0.1206, -0.2776, -0.072, 0.1359, -0.0936, -0.0924, -0.0496, 0.0898, 0.0531, -0.059, 0.2331, -0.0631, -0.045, -0.0764, 0.0475, -0.0309, 0.1361, -0.0188, 0.0453, -0.0273, 0.0273, -0.0647, -0.0586, -0.0932, -0.2062, 0.1993, -0.0598, -0.0007, 0.007, 0.0067, -0.1401, -0.1123, -0.1363, -0.0536, 0.087, 0.0379, 0.1337, -0.1219, 0.1295, 0.0334, -0.0151, -0.1794, -0.1829, -0.0777, 0.3214, -0.0099, -0.0804, -0.0891, -0.1079, -0.0647, -0.2523, -0.2306, 0.0633, 0.0056, -0.1124, 0.004, -0.0387, -0.0482, 0.154, 0.1341, 0.0859, 0.3972, -0.0013, -0.1454, -0.1012, -0.1137, -0.0307, -0.0036, 0.1134, -0.0087, 0.1112, -0.0305, -0.0272, -0.0568, -0.0435, 0.0541, -0.3689, -0.0552, -0.1175, 0.0657, -0.1042, 0.043, 0.1862, -0.0658, 0.0141, 0.0465, -0.0112, 0.0364, 0.0719, -0.0872, -0.0338, 0.1012, -0.1876, 0.0278, -0.1171, -0.1303, 0.1601, 0.1416, -0.1077, 0.0635, 0.0294, 0.0996, -0.0902, -0.0323, 0.045, 0.1077, -0.0811, 0.1731, -0.0808, 0.1723, 0.009, 0.1053]\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0897, 0.016, -0.0571, 0.0405, -0.0696, -0.1237, 0.0301, 0.0248, -0.0303, 0.0174, 0.0063, 0.0184, 0.0217, -0.0257, 0.035, -0.0242, 0.0029, 0.0188, -0.057, 0.0252, -0.021, -0.0008, 0.036, -0.0729, -0.0665, 0.0989, 0.0676, 0.0852, -0.0089, 0.0313, -0.0069, -0.0032, -0.0462, 0.0497, 0.0261, 0.0268, -0.031, -0.1361, -0.0062, 0.0375, -0.032, -0.0106, 0.0534, -0.0187, 0.0638, 0.0094, 0.0047, -0.053, 0.0093, -0.0087, 0.0004, 0.0493, -0.6296, 0.0222, 0.019, 0.0268, -0.0426, 0.0057, -0.1683, 0.0244, -0.0213, -0.0181, 0.0421, -0.0309, -0.0089, 0.0032, 0.0108, -0.0049, 0.0258, 0.0278, -0.0163, 0.02, 0.0164, -0.0954, -0.0032, 0.0043, 0.0104, -0.0088, 0.0007, 0.035, -0.0206, -0.0083, -0.0114, -0.1869, 0.0258, 0.001, 0.0085, 0.0151, 0.2125, 0.0071, 0.0319, -0.0482, 0.0621, 0.0626, 0.0159, -0.0013, 0.0087, 0.0686, -0.0034, 0.0238, -0.0452, -0.0198, 0.0112, 0.0109, -0.1022, -0.0272, 0.2337, -0.0465, 0.1592, -0.0407, -0.1029, -0.0487, -0.0676, 0.0676, -0.0328, 0.0323, 0.0077, 0.019, 0.0017, -0.2974, 0.0011, -0.0356, 0.0693, -0.048, -0.0821, -0.0644, -0.0284, -0.0191, -0.0233, 0.0353, -0.0463, 0.0656, 0.0019, -0.0212, -0.0309, -0.3534, -0.0309, 0.0076, -0.0419, 0.0457, -0.0306, 0.0357, 0.0667, 0.3659, 0.0149, -0.0443, 0.0068, -0.0378, 0.0146, 0.0215, 0.1081, 0.0124, -0.0437, -0.043, 0.0258, 0.0213, -0.0309, -0.0018, -0.0067, 0.0172, 0.0089, -0.0171, 0.0275, -0.0518, -0.184, -0.013, -0.0241, 0.0526, -0.028, 0.0051, 0.0163, -0.0165, 0.0161, 0.1237, 0.0804, -0.0789, 0.0386, -0.3892, 0.0157, -0.0246, 0.0477, -0.0045, -0.0214, 0.0173, -0.0191, -0.1382, -0.0111, 0.0712, 0.1514, 0.0291, 0.0555, -0.0039, 0.0028, -0.0277, -0.0275, -0.0177, -0.0338, -0.0372, 0.2071, 0.046, -0.0294, 0.0435, -0.0169, -0.0121, 0.0253, 0.0198, 0.0918, 0.0193, 0.0668, 0.0288, 0.004, -0.0439, -0.0302, 0.0064, 0.0364, 0.0543, -0.0338, 0.0159, 0.0617, -0.0941, -0.0086, -0.0092, 0.03, -0.0241, -0.035, -0.0621, 0.0175, 0.0374, 0.0034, 0.0344, 0.1286, -0.0267, 0.1861, 0.0489, -0.0032, 0.018, -0.0228, 0.2414, -0.0935, 0.0612, -0.0209, 0.0136, 0.0392, -0.0135, -0.0253, 0.0335, 0.0095, 0.0419, 0.0076, 0.4522, -0.0188, 0.0233, -0.0474, 0.0159, -0.009, 0.0265, 0.0336, 0.0221, 0.0472, 0.0048, 0.0962, 0.0344, -0.0515, -0.0087, -0.098, -0.0288, 0.0377, 0.0202, -0.2979, -0.0387, -0.0198, -0.0161, -0.0045, 0.0087, -0.0387, 0.0421, 0.0383, 0.0258, 0.0069, -0.0298, -0.0198, -0.0152, 0.0033, 0.0075, 0.0358, -0.0155, -0.0111, 0.076, -0.0452, 0.0697, 0.0299, -0.0029, -0.0348, -0.027, 0.0351, 0.0559, 0.0591, 0.1559, -0.0254, -0.0259]\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.46s/it]\u001b[A\n","03/28/2021 18:11:35 - INFO - bert_utils -     flaw_f1 = 0.0\n","03/28/2021 18:11:35 - INFO - bert_utils -     flaw_precision = 0.0\n","03/28/2021 18:11:35 - INFO - bert_utils -     flaw_recall = 0.0\n","03/28/2021 18:11:35 - INFO - bert_utils -     loss = 0.07746419310569763\n","Epoch:  36%|█████████████▎                       | 9/25 [00:45<01:20,  5.01s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.01, -0.1164, -0.1155, 0.0128, 0.0066, 0.1118, 0.0019, 0.1206, 0.0421, -0.101, -0.004, -0.0397, -0.0289, 0.0068, -0.0612, 0.0406, 0.0486, 0.0586, 0.1727, -0.0766, 0.0337, -0.0184, -0.0366, 0.2488, 0.0496, -0.0027, -0.0022, -0.0953, 0.0506, -0.1002, 0.0485, 0.0158, -0.0052, 0.0754, 0.1312, 0.0125, -0.0013, 0.1345, 0.1304, -0.0553, 0.0419, -0.0352, -0.0879, 0.011, 0.1502, 0.077, 0.0504, -0.0595, 0.0213, 0.0447, -0.0306, 0.1326, -0.6322, -0.0197, 0.0337, -0.0027, -0.1529, -0.1602, -0.0631, -0.0668, -0.0243, 0.0625, -0.1633, -0.0073, -0.0559, -0.1796, -0.0004, -0.0384, 0.0424, -0.0468, 0.0202, -0.0719, -0.0158, 0.0609, -0.0076, -0.0106, 0.2165, 0.0046, 0.0026, 0.1756, 0.018, 0.0555, 0.0287, -0.2628, 0.0122, 0.1043, 0.109, -0.0115, -0.2083, -0.0649, 0.0975, 0.007, -0.001, -0.124, 0.03, 0.0333, -0.0295, 0.0596, 0.0244, -0.0265, -0.1616, -0.0581, 0.0439, 0.0733, -0.0714, -0.0393, 0.2064, 0.1114, -0.0533, 0.119, -0.0603, 0.0178, -0.0118, 0.0112, 0.1174, -0.0652, 0.0505, -0.1118, 0.0196, -0.3306, 0.0246, -0.0156, -0.0363, 0.0558, -0.0872, 0.1793, -0.0551, 0.2096, -0.3445, 0.0282, -0.0852, 0.0196, -0.1081, -0.0563, 0.138, -0.1404, 0.0364, -0.0088, 0.1013, 0.0078, 0.0305, -0.0422, -0.0317, 0.3136, -0.01, 0.0061, 0.1233, -0.1092, 0.0066, -0.0221, 0.1111, 0.0233, 0.0763, 0.0268, -0.0634, 0.0247, -0.0976, 0.112, 0.0448, 0.0234, 0.2722, -0.0352, -0.0033, -0.039, -0.1779, -0.0273, 0.1093, 0.0029, -0.0524, 0.0917, -0.0883, 0.0905, 0.0899, 0.0649, -0.0216, 0.0238, 0.232, -0.1989, -0.0122, 0.0077, -0.0079, -0.1072, -0.0594, -0.0178, -0.0088, 0.1284, 0.0422, -0.0185, 0.0461, 0.0493, 0.1004, 0.0176, -0.0153, -0.0245, -0.0135, 0.0783, 0.0164, -0.0252, 0.295, -0.0319, 0.1103, 0.01, -0.0029, -0.1097, -0.0587, -0.0045, -0.0928, -0.306, 0.0651, -0.0328, 0.0264, -0.1218, -0.0211, 0.0559, -0.0267, 0.0574, -0.2908, 0.06, 0.1002, -0.251, 0.0734, -0.2104, 0.0144, 0.0174, 0.0529, -0.0086, 0.0128, 0.0311, -0.1217, 0.0557, 0.0154, 0.0036, 0.2933, 0.1089, 0.0268, 0.248, 0.0073, 0.0447, -0.2185, 0.071, -0.0075, -0.0175, -0.0303, -0.0635, 0.0388, 0.1332, 0.1139, -0.0396, 0.0176, 0.3505, -0.0208, -0.0023, 0.0646, 0.0537, -0.0967, 0.0124, -0.0847, 0.0001, 0.0942, 0.0022, 0.0561, 0.0588, -0.0494, 0.0042, -0.2125, -0.047, 0.0718, 0.0505, -0.045, 0.0896, 0.0691, -0.0113, -0.0217, -0.0209, -0.0119, 0.0106, 0.0667, 0.0265, 0.0548, -0.0067, 0.0107, -0.0307, 0.0228, 0.0027, 0.0046, 0.0296, -0.1323, 0.1093, -0.4649, 0.0183, 0.087, -0.0078, -0.1624, 0.0289, 0.0533, -0.0682, -0.0692, 0.104, 0.0964, 0.0392]\n","tok_id :  31\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0312, -0.0133, -0.0627, -0.0361, 0.0148, 0.0319, 0.0276, 0.0409, -0.0129, -0.0438, 0.0246, -0.087, -0.0367, -0.0649, -0.124, -0.0144, 0.0648, 0.0107, 0.1197, -0.0742, -0.0414, 0.0702, -0.094, -0.0256, -0.0283, -0.06, -0.1258, -0.0883, -0.0243, -0.1137, 0.0832, -0.0581, 0.1514, 0.0574, 0.0183, 0.0585, 0.0279, 0.0626, -0.0219, 0.0182, -0.0218, 0.031, -0.06, -0.0169, -0.0235, 0.0086, 0.0327, -0.0764, 0.0083, -0.002, -0.0496, -0.117, -0.6124, -0.009, 0.0031, -0.0017, -0.0477, -0.0916, -0.0452, -0.087, 0.0233, 0.0115, -0.0832, -0.0693, -0.0229, 0.1129, 0.0037, 0.0396, -0.0102, -0.0518, 0.052, -0.0792, -0.0331, -0.0026, 0.012, 0.0248, 0.0572, 0.0273, 0.109, 0.1978, -0.0371, -0.073, 0.0189, -0.2491, -0.007, 0.035, -0.0297, -0.043, -0.141, 0.0299, 0.1118, 0.0242, 0.0185, 0.0143, 0.0662, 0.0149, -0.0218, -0.0294, 0.0472, -0.0472, -0.133, -0.0284, -0.0129, 0.0475, -0.0595, -0.0138, 0.087, 0.0678, 0.0049, 0.0161, 0.0955, -0.1739, 0.0335, 0.1083, -0.0178, 0.0103, 0.0859, -0.0761, 0.0037, -0.3074, -0.0399, -0.0065, -0.0188, 0.0208, -0.1801, 0.1801, -0.0101, 0.1407, -0.1353, -0.0314, -0.029, 0.0156, -0.0953, -0.0124, 0.0264, -0.167, 0.0313, -0.1026, 0.0345, 0.0018, 0.0197, -0.0375, 0.0248, 0.3195, -0.0365, 0.0152, 0.1094, -0.026, -0.0107, -0.0482, 0.0186, -0.0329, 0.0716, 0.0384, 0.0098, 0.0439, -0.0697, 0.0827, 0.0656, 0.0292, 0.042, -0.0535, 0.0484, 0.0079, -0.1818, -0.0666, 0.1992, -0.0962, -0.0236, 0.0963, -0.0563, 0.009, 0.0392, 0.0302, 0.0433, -0.0182, 0.1542, -0.1861, 0.0033, 0.0275, -0.0038, -0.0268, -0.0119, 0.0041, 0.0624, 0.179, -0.0033, -0.1647, 0.0734, 0.0999, 0.0103, -0.0102, 0.0046, 0.0222, 0.0389, 0.0567, -0.0187, 0.0296, 0.3547, 0.0149, 0.0383, 0.0586, -0.0006, -0.0506, -0.0019, 0.0274, -0.0577, -0.0971, -0.0288, -0.0018, 0.1553, -0.0006, -0.0519, 0.0523, 0.0322, 0.0971, -0.2139, -0.0007, -0.0589, -0.0342, 0.1299, -0.0024, 0.0472, -0.0086, 0.0416, -0.1646, -0.0201, -0.0121, 0.0873, -0.0313, -0.0525, -0.0498, 0.3044, -0.0349, -0.1103, 0.1482, -0.0257, -0.1129, -0.2016, 0.0639, 0.0723, -0.0193, -0.0216, -0.0315, -0.0082, -0.0027, -0.0274, -0.0552, -0.0741, 0.2908, 0.0462, 0.0082, 0.0626, 0.0313, 0.0459, -0.0516, -0.1157, 0.0854, 0.0207, 0.0754, 0.0232, -0.0468, 0.0433, 0.0039, -0.1978, -0.0108, -0.0164, 0.0037, -0.0748, -0.0055, 0.1568, 0.0083, 0.0083, 0.0333, 0.0282, 0.0223, 0.005, -0.012, 0.0558, 0.0323, 0.0078, 0.013, 0.0351, -0.1201, -0.0071, -0.0138, -0.0476, 0.0112, -0.1684, 0.0376, -0.0111, -0.0568, -0.0641, 0.0521, 0.0665, -0.0576, -0.0074, 0.2201, 0.0738, -0.0633]\n","tok_id :  32\n","tok_id :  16\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0495, 0.0411, 0.0041, 0.0309, -0.0044, -0.1151, 0.006, 0.017, 0.0045, -0.0288, 0.017, 0.0007, 0.0533, 0.0094, -0.0609, -0.0267, 0.0497, 0.0474, 0.0054, 0.0511, -0.0715, 0.0876, 0.055, -0.001, -0.0746, 0.0008, 0.0258, -0.1404, 0.0022, 0.0469, 0.0114, 0.0083, -0.0127, -0.0453, 0.0011, -0.008, -0.013, -0.1271, 0.002, 0.0389, -0.0395, -0.0295, -0.0308, 0.0348, -0.1388, -0.0647, 0.0302, 0.0184, 0.0499, 0.0168, -0.0176, 0.089, -0.5547, 0.0144, 0.03, 0.0127, 0.0345, 0.1792, 0.0629, -0.0242, -0.0491, -0.0397, -0.0014, -0.0571, 0.0906, -0.0009, 0.0266, -0.0018, 0.0308, -0.0057, 0.0569, 0.0273, -0.0338, 0.1003, 0.0299, 0.0115, 0.0717, 0.0319, -0.0726, 0.1526, -0.0026, -0.1321, -0.0287, -0.2439, 0.0073, -0.0062, 0.0101, -0.0128, -0.0106, 0.0202, -0.0165, -0.0867, 0.0493, -0.0916, 0.0507, 0.1032, 0.0108, 0.0881, 0.0655, -0.0127, -0.0895, -0.0348, 0.0439, 0.0069, -0.3768, -0.0176, 0.1296, 0.0027, 0.2343, -0.0009, 0.0337, 0.0613, -0.0369, 0.0564, -0.0901, -0.0046, 0.036, 0.0341, -0.0171, -0.1717, -0.0041, -0.0553, -0.0661, 0.0957, -0.0804, 0.0868, -0.0181, -0.0602, -0.1523, -0.0104, -0.0034, -0.0547, 0.0094, -0.0223, -0.0184, -0.3151, -0.0358, 0.0354, 0.0393, 0.0526, 0.001, -0.0163, 0.0497, 0.2518, -0.0173, -0.0036, 0.018, -0.1081, 0.0368, -0.0141, -0.0436, 0.0291, -0.0366, -0.0523, 0.0464, 0.0018, -0.0183, 0.0766, 0.0156, 0.0276, 0.0522, -0.0221, 0.0408, -0.0703, -0.2291, -0.003, 0.0343, -0.0961, -0.0092, 0.0222, 0.0166, -0.0344, 0.0463, 0.0186, 0.0283, -0.0522, 0.0369, -0.4955, 0.0276, -0.0247, 0.0257, 0.0632, -0.0232, -0.0063, -0.0076, -0.3897, -0.0108, -0.0612, 0.1962, -0.006, -0.0353, -0.0994, -0.0124, -0.0031, 0.0427, 0.0134, -0.0043, -0.0102, 0.21, 0.0163, -0.0155, 0.1707, -0.0339, -0.0125, 0.02, 0.0148, -0.0342, -0.0254, 0.0001, 0.0412, -0.0258, -0.0169, 0.0113, 0.0031, 0.0075, -0.0059, 0.1255, 0.0225, 0.0005, 0.0462, 0.0096, -0.0664, 0.0138, 0.0511, 0.0372, 0.0073, -0.0187, 0.0186, -0.0021, -0.012, 0.0007, -0.0026, 0.1725, 0.079, 0.0265, -0.0066, -0.0765, 0.2336, -0.1445, 0.0072, -0.026, -0.0147, 0.0521, 0.0011, -0.0244, 0.0583, -0.0207, 0.032, 0.0294, 0.483, -0.0444, -0.087, -0.0754, 0.0276, -0.0606, -0.0227, -0.0057, -0.0298, 0.054, -0.0607, -0.0746, 0.0666, -0.024, -0.0399, -0.2321, 0.0054, 0.0233, 0.046, 0.1874, -0.053, -0.0285, -0.0521, -0.0146, 0.0264, -0.0093, 0.025, -0.0552, 0.0152, 0.0242, -0.0577, 0.006, 0.0511, 0.023, -0.0345, 0.0134, -0.0042, -0.1267, -0.1572, -0.0783, 0.0706, 0.0004, -0.0142, -0.0976, -0.0489, -0.0625, -0.0327, 0.007, 0.2371, -0.0298, -0.0284]\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0169, 0.0542, 0.0311, -0.0461, 0.0195, 0.0657, -0.049, 0.0718, 0.0308, -0.0474, 0.0373, -0.0207, -0.0222, -0.0486, -0.1308, 0.051, 0.0104, -0.1136, -0.1407, 0.0007, -0.0533, -0.0364, 0.0279, -0.1236, -0.0104, -0.0262, 0.0281, -0.0941, 0.0612, 0.0196, 0.0554, -0.0727, 0.0461, -0.0601, -0.0269, 0.0226, -0.0258, -0.0506, 0.0607, -0.0627, -0.0754, -0.0065, -0.1208, -0.0697, -0.0514, 0.055, -0.0268, 0.022, 0.0651, -0.063, 0.0938, -0.1551, -0.6362, 0.0753, 0.0465, -0.0253, 0.0198, 0.0698, 0.0703, 0.0622, 0.015, -0.0942, -0.065, -0.1049, 0.0751, -0.1141, 0.0022, 0.0171, -0.0676, -0.03, 0.0063, -0.0088, -0.0381, -0.0068, 0.0143, -0.0023, 0.0603, 0.023, -0.04, 0.1527, 0.0037, -0.0434, 0.0, -0.2494, -0.1049, -0.0362, 0.0832, 0.0071, 0.0319, 0.0803, 0.0325, -0.0535, -0.0142, -0.0326, -0.0205, -0.0343, -0.0712, -0.0522, 0.082, 0.0663, -0.1346, -0.0427, -0.0286, 0.0231, -0.201, -0.0192, 0.1474, -0.1347, -0.0674, 0.0379, 0.0173, 0.1309, -0.0477, 0.0143, -0.1489, 0.0666, -0.0036, -0.0256, -0.0121, -0.3078, -0.0362, 0.042, -0.0266, 0.1928, -0.0723, 0.1245, 0.0488, 0.117, 0.0043, -0.0332, 0.0002, -0.0555, 0.0043, -0.048, -0.0064, -0.1869, -0.042, -0.0004, 0.1103, -0.1727, -0.0189, 0.0143, 0.0159, 0.3573, 0.0272, 0.039, 0.0773, 0.0238, -0.0406, 0.009, 0.1301, -0.013, -0.0266, -0.0657, -0.002, 0.0254, -0.043, 0.0677, 0.0368, -0.0019, -0.0161, 0.0341, 0.0689, -0.0734, -0.285, 0.0103, 0.1173, 0.1027, -0.0588, -0.1237, 0.0464, 0.02, 0.0045, 0.0427, 0.2493, -0.0509, 0.1712, -0.0888, 0.1136, 0.0143, 0.0118, 0.0735, -0.0039, 0.0056, -0.0206, 0.0521, 0.0371, -0.0837, 0.2374, -0.0178, -0.0484, 0.0031, -0.0008, -0.0601, -0.0609, -0.0021, -0.0568, -0.0317, 0.2517, -0.0359, 0.0292, -0.0984, -0.0113, -0.0954, 0.0397, -0.1018, 0.0002, -0.0668, -0.0187, 0.0313, -0.0811, 0.0204, -0.0357, -0.035, -0.0121, -0.0259, -0.1144, 0.0894, -0.0788, -0.0201, 0.0817, -0.0239, -0.0632, -0.0535, 0.0203, 0.0705, 0.0715, -0.0494, -0.1694, -0.1397, -0.0321, 0.0185, 0.327, -0.093, -0.0162, 0.0699, -0.0131, 0.2046, -0.1557, 0.1149, 0.001, 0.0126, -0.0164, -0.0303, 0.0191, 0.0303, -0.0135, 0.0564, 0.0331, 0.2624, 0.0173, 0.007, 0.0385, -0.1233, -0.2565, 0.0582, -0.0977, -0.0546, 0.0624, 0.019, 0.1011, 0.0149, 0.0108, -0.0075, -0.1214, 0.0641, -0.0207, 0.0869, 0.0696, 0.085, -0.0308, -0.0189, 0.0067, -0.0064, 0.0047, -0.0595, 0.1695, -0.0391, 0.0638, -0.0239, 0.0583, 0.1853, -0.0096, -0.0887, 0.0432, -0.0111, 0.0581, 0.1766, 0.0378, 0.0417, 0.0937, -0.0021, -0.0388, -0.0136, -0.0179, -0.0308, -0.0366, 0.1723, 0.0272, -0.1241]\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.37s/it]\u001b[A\n","03/28/2021 18:11:40 - INFO - bert_utils -     flaw_f1 = 0.0\n","03/28/2021 18:11:40 - INFO - bert_utils -     flaw_precision = 0.0\n","03/28/2021 18:11:40 - INFO - bert_utils -     flaw_recall = 0.0\n","03/28/2021 18:11:40 - INFO - bert_utils -     loss = 0.17405396699905396\n","Epoch:  40%|██████████████▍                     | 10/25 [00:50<01:14,  5.00s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0897, 0.016, -0.0571, 0.0405, -0.0696, -0.1237, 0.0301, 0.0248, -0.0303, 0.0174, 0.0063, 0.0184, 0.0217, -0.0257, 0.035, -0.0242, 0.0029, 0.0188, -0.057, 0.0252, -0.021, -0.0008, 0.036, -0.0729, -0.0665, 0.0989, 0.0676, 0.0852, -0.0089, 0.0313, -0.0069, -0.0032, -0.0462, 0.0497, 0.0261, 0.0268, -0.031, -0.1361, -0.0062, 0.0375, -0.032, -0.0106, 0.0534, -0.0187, 0.0638, 0.0094, 0.0047, -0.053, 0.0093, -0.0087, 0.0004, 0.0493, -0.6296, 0.0222, 0.019, 0.0268, -0.0426, 0.0057, -0.1683, 0.0244, -0.0213, -0.0181, 0.0421, -0.0309, -0.0089, 0.0032, 0.0108, -0.0049, 0.0258, 0.0278, -0.0163, 0.02, 0.0164, -0.0954, -0.0032, 0.0043, 0.0104, -0.0088, 0.0007, 0.035, -0.0206, -0.0083, -0.0114, -0.1869, 0.0258, 0.001, 0.0085, 0.0151, 0.2125, 0.0071, 0.0319, -0.0482, 0.0621, 0.0626, 0.0159, -0.0013, 0.0087, 0.0686, -0.0034, 0.0238, -0.0452, -0.0198, 0.0112, 0.0109, -0.1022, -0.0272, 0.2337, -0.0465, 0.1592, -0.0407, -0.1029, -0.0487, -0.0676, 0.0676, -0.0328, 0.0323, 0.0077, 0.019, 0.0017, -0.2974, 0.0011, -0.0356, 0.0693, -0.048, -0.0821, -0.0644, -0.0284, -0.0191, -0.0233, 0.0353, -0.0463, 0.0656, 0.0019, -0.0212, -0.0309, -0.3534, -0.0309, 0.0076, -0.0419, 0.0457, -0.0306, 0.0357, 0.0667, 0.3659, 0.0149, -0.0443, 0.0068, -0.0378, 0.0146, 0.0215, 0.1081, 0.0124, -0.0437, -0.043, 0.0258, 0.0213, -0.0309, -0.0018, -0.0067, 0.0172, 0.0089, -0.0171, 0.0275, -0.0518, -0.184, -0.013, -0.0241, 0.0526, -0.028, 0.0051, 0.0163, -0.0165, 0.0161, 0.1237, 0.0804, -0.0789, 0.0386, -0.3892, 0.0157, -0.0246, 0.0477, -0.0045, -0.0214, 0.0173, -0.0191, -0.1382, -0.0111, 0.0712, 0.1514, 0.0291, 0.0555, -0.0039, 0.0028, -0.0277, -0.0275, -0.0177, -0.0338, -0.0372, 0.2071, 0.046, -0.0294, 0.0435, -0.0169, -0.0121, 0.0253, 0.0198, 0.0918, 0.0193, 0.0668, 0.0288, 0.004, -0.0439, -0.0302, 0.0064, 0.0364, 0.0543, -0.0338, 0.0159, 0.0617, -0.0941, -0.0086, -0.0092, 0.03, -0.0241, -0.035, -0.0621, 0.0175, 0.0374, 0.0034, 0.0344, 0.1286, -0.0267, 0.1861, 0.0489, -0.0032, 0.018, -0.0228, 0.2414, -0.0935, 0.0612, -0.0209, 0.0136, 0.0392, -0.0135, -0.0253, 0.0335, 0.0095, 0.0419, 0.0076, 0.4522, -0.0188, 0.0233, -0.0474, 0.0159, -0.009, 0.0265, 0.0336, 0.0221, 0.0472, 0.0048, 0.0962, 0.0344, -0.0515, -0.0087, -0.098, -0.0288, 0.0377, 0.0202, -0.2979, -0.0387, -0.0198, -0.0161, -0.0045, 0.0087, -0.0387, 0.0421, 0.0383, 0.0258, 0.0069, -0.0298, -0.0198, -0.0152, 0.0033, 0.0075, 0.0358, -0.0155, -0.0111, 0.076, -0.0452, 0.0697, 0.0299, -0.0029, -0.0348, -0.027, 0.0351, 0.0559, 0.0591, 0.1559, -0.0254, -0.0259]\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0685, 0.0436, 0.0876, 0.0343, -0.1407, -0.0022, 0.0907, 0.1207, -0.0634, 0.0474, -0.0613, -0.2585, 0.1362, 0.0302, 0.0678, -0.1044, 0.0679, -0.0501, -0.046, 0.0721, -0.0615, 0.0052, 0.0265, 0.0553, 0.0739, 0.1436, 0.0617, -0.2076, 0.0626, -0.0215, 0.0303, -0.0909, 0.0796, -0.0468, 0.0471, -0.0377, 0.1013, -0.2236, -0.0454, 0.0141, 0.0549, -0.0494, 0.0921, -0.0206, -0.0119, 0.0382, 0.0383, 0.068, 0.1218, 0.1234, -0.2106, 0.033, -0.8115, 0.0913, -0.0889, 0.1473, -0.2201, -0.0381, 0.1106, -0.0855, 0.0832, 0.054, -0.1591, -0.1177, 0.0305, -0.0727, 0.1166, -0.1095, 0.0617, 0.0556, -0.1038, -0.1466, -0.0321, 0.0165, 0.0803, 0.1344, 0.1113, 0.0537, 0.1112, 0.0829, -0.0197, 0.1339, -0.0772, -0.214, -0.0254, -0.1179, -0.1341, -0.104, 0.0344, 0.1171, -0.0044, -0.0009, 0.142, 0.0659, 0.0995, -0.0581, 0.1026, 0.1173, 0.0989, -0.1691, -0.141, 0.2469, -0.0646, -0.0783, 0.0477, -0.098, 0.217, -0.0115, 0.0215, 0.0928, 0.0171, -0.0789, 0.0312, 0.0426, -0.0341, 0.0256, 0.0014, 0.0331, -0.0163, -0.2818, -0.0578, 0.0467, -0.1878, 0.1264, -0.3744, 0.1664, 0.0603, 0.1012, -0.09, 0.0681, -0.1515, 0.0238, -0.1266, 0.0194, 0.1907, -0.2536, -0.1319, 0.0278, 0.0734, 0.0086, 0.0381, -0.0133, -0.0044, 0.2154, -0.0498, 0.0575, 0.0033, -0.0922, -0.0268, 0.1245, -0.0261, -0.1517, -0.0902, -0.1291, -0.0064, 0.0302, 0.1057, 0.1446, 0.0221, -0.0246, 0.1665, -0.0093, 0.0622, 0.0727, 0.1815, 0.1833, 0.1672, 0.0655, -0.1608, -0.0446, 0.0452, -0.0805, 0.2006, -0.0761, 0.1609, 0.005, 0.2726, 0.0181, -0.07, 0.0954, -0.0658, -0.0871, -0.2224, -0.0431, -0.0652, 0.1016, -0.0707, -0.1596, 0.0328, 0.0733, -0.1572, 0.0093, -0.2113, -0.106, -0.0783, 0.0909, 0.0886, 0.0824, 0.1612, -0.1643, 0.0743, 0.052, 0.0249, -0.1409, -0.0267, 0.0257, 0.0348, -0.111, -0.0206, 0.1474, 0.0508, -0.2169, -0.0269, -0.05, -0.0022, -0.0559, -0.0335, -0.0472, -0.1692, -0.0924, 0.2929, 0.1039, -0.1878, -0.0744, -0.0394, -0.1387, 0.2079, 0.038, 0.0911, -0.3023, 0.1811, -0.1264, 0.2608, -0.0484, 0.1155, 0.0116, -0.0354, -0.3764, -0.2078, 0.0478, -0.0017, -0.0003, 0.0043, 0.1262, -0.0336, -0.1264, 0.0736, -0.066, -0.1539, 0.3558, -0.1012, 0.1345, 0.1251, -0.0782, 0.026, 0.0163, -0.0148, 0.0403, 0.0377, 0.07, 0.0038, -0.1903, 0.2018, 0.16, 0.0563, 0.0419, 0.2017, 0.1132, -0.1395, 0.0497, -0.0405, 0.0217, 0.0512, -0.0171, -0.0249, 0.1802, 0.0679, -0.0776, -0.0647, 0.0203, -0.196, -0.2066, -0.1197, -0.1547, 0.3984, 0.0785, -0.0163, 0.199, -0.0673, -0.0226, -0.0658, 0.082, -0.0271, -0.1362, -0.0309, -0.0124, -0.0784, 0.0714, 0.1751, -0.0285]\n","tok_id :  36\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.38s/it]\u001b[A\n","03/28/2021 18:11:45 - INFO - bert_utils -     flaw_f1 = 0.0\n","03/28/2021 18:11:45 - INFO - bert_utils -     flaw_precision = 0.0\n","03/28/2021 18:11:45 - INFO - bert_utils -     flaw_recall = 0.0\n","03/28/2021 18:11:45 - INFO - bert_utils -     loss = 0.06341788917779922\n","Epoch:  44%|███████████████▊                    | 11/25 [00:55<01:09,  4.99s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0312, -0.0133, -0.0627, -0.0361, 0.0148, 0.0319, 0.0276, 0.0409, -0.0129, -0.0438, 0.0246, -0.087, -0.0367, -0.0649, -0.124, -0.0144, 0.0648, 0.0107, 0.1197, -0.0742, -0.0414, 0.0702, -0.094, -0.0256, -0.0283, -0.06, -0.1258, -0.0883, -0.0243, -0.1137, 0.0832, -0.0581, 0.1514, 0.0574, 0.0183, 0.0585, 0.0279, 0.0626, -0.0219, 0.0182, -0.0218, 0.031, -0.06, -0.0169, -0.0235, 0.0086, 0.0327, -0.0764, 0.0083, -0.002, -0.0496, -0.117, -0.6124, -0.009, 0.0031, -0.0017, -0.0477, -0.0916, -0.0452, -0.087, 0.0233, 0.0115, -0.0832, -0.0693, -0.0229, 0.1129, 0.0037, 0.0396, -0.0102, -0.0518, 0.052, -0.0792, -0.0331, -0.0026, 0.012, 0.0248, 0.0572, 0.0273, 0.109, 0.1978, -0.0371, -0.073, 0.0189, -0.2491, -0.007, 0.035, -0.0297, -0.043, -0.141, 0.0299, 0.1118, 0.0242, 0.0185, 0.0143, 0.0662, 0.0149, -0.0218, -0.0294, 0.0472, -0.0472, -0.133, -0.0284, -0.0129, 0.0475, -0.0595, -0.0138, 0.087, 0.0678, 0.0049, 0.0161, 0.0955, -0.1739, 0.0335, 0.1083, -0.0178, 0.0103, 0.0859, -0.0761, 0.0037, -0.3074, -0.0399, -0.0065, -0.0188, 0.0208, -0.1801, 0.1801, -0.0101, 0.1407, -0.1353, -0.0314, -0.029, 0.0156, -0.0953, -0.0124, 0.0264, -0.167, 0.0313, -0.1026, 0.0345, 0.0018, 0.0197, -0.0375, 0.0248, 0.3195, -0.0365, 0.0152, 0.1094, -0.026, -0.0107, -0.0482, 0.0186, -0.0329, 0.0716, 0.0384, 0.0098, 0.0439, -0.0697, 0.0827, 0.0656, 0.0292, 0.042, -0.0535, 0.0484, 0.0079, -0.1818, -0.0666, 0.1992, -0.0962, -0.0236, 0.0963, -0.0563, 0.009, 0.0392, 0.0302, 0.0433, -0.0182, 0.1542, -0.1861, 0.0033, 0.0275, -0.0038, -0.0268, -0.0119, 0.0041, 0.0624, 0.179, -0.0033, -0.1647, 0.0734, 0.0999, 0.0103, -0.0102, 0.0046, 0.0222, 0.0389, 0.0567, -0.0187, 0.0296, 0.3547, 0.0149, 0.0383, 0.0586, -0.0006, -0.0506, -0.0019, 0.0274, -0.0577, -0.0971, -0.0288, -0.0018, 0.1553, -0.0006, -0.0519, 0.0523, 0.0322, 0.0971, -0.2139, -0.0007, -0.0589, -0.0342, 0.1299, -0.0024, 0.0472, -0.0086, 0.0416, -0.1646, -0.0201, -0.0121, 0.0873, -0.0313, -0.0525, -0.0498, 0.3044, -0.0349, -0.1103, 0.1482, -0.0257, -0.1129, -0.2016, 0.0639, 0.0723, -0.0193, -0.0216, -0.0315, -0.0082, -0.0027, -0.0274, -0.0552, -0.0741, 0.2908, 0.0462, 0.0082, 0.0626, 0.0313, 0.0459, -0.0516, -0.1157, 0.0854, 0.0207, 0.0754, 0.0232, -0.0468, 0.0433, 0.0039, -0.1978, -0.0108, -0.0164, 0.0037, -0.0748, -0.0055, 0.1568, 0.0083, 0.0083, 0.0333, 0.0282, 0.0223, 0.005, -0.012, 0.0558, 0.0323, 0.0078, 0.013, 0.0351, -0.1201, -0.0071, -0.0138, -0.0476, 0.0112, -0.1684, 0.0376, -0.0111, -0.0568, -0.0641, 0.0521, 0.0665, -0.0576, -0.0074, 0.2201, 0.0738, -0.0633]\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0897, 0.016, -0.0571, 0.0405, -0.0696, -0.1237, 0.0301, 0.0248, -0.0303, 0.0174, 0.0063, 0.0184, 0.0217, -0.0257, 0.035, -0.0242, 0.0029, 0.0188, -0.057, 0.0252, -0.021, -0.0008, 0.036, -0.0729, -0.0665, 0.0989, 0.0676, 0.0852, -0.0089, 0.0313, -0.0069, -0.0032, -0.0462, 0.0497, 0.0261, 0.0268, -0.031, -0.1361, -0.0062, 0.0375, -0.032, -0.0106, 0.0534, -0.0187, 0.0638, 0.0094, 0.0047, -0.053, 0.0093, -0.0087, 0.0004, 0.0493, -0.6296, 0.0222, 0.019, 0.0268, -0.0426, 0.0057, -0.1683, 0.0244, -0.0213, -0.0181, 0.0421, -0.0309, -0.0089, 0.0032, 0.0108, -0.0049, 0.0258, 0.0278, -0.0163, 0.02, 0.0164, -0.0954, -0.0032, 0.0043, 0.0104, -0.0088, 0.0007, 0.035, -0.0206, -0.0083, -0.0114, -0.1869, 0.0258, 0.001, 0.0085, 0.0151, 0.2125, 0.0071, 0.0319, -0.0482, 0.0621, 0.0626, 0.0159, -0.0013, 0.0087, 0.0686, -0.0034, 0.0238, -0.0452, -0.0198, 0.0112, 0.0109, -0.1022, -0.0272, 0.2337, -0.0465, 0.1592, -0.0407, -0.1029, -0.0487, -0.0676, 0.0676, -0.0328, 0.0323, 0.0077, 0.019, 0.0017, -0.2974, 0.0011, -0.0356, 0.0693, -0.048, -0.0821, -0.0644, -0.0284, -0.0191, -0.0233, 0.0353, -0.0463, 0.0656, 0.0019, -0.0212, -0.0309, -0.3534, -0.0309, 0.0076, -0.0419, 0.0457, -0.0306, 0.0357, 0.0667, 0.3659, 0.0149, -0.0443, 0.0068, -0.0378, 0.0146, 0.0215, 0.1081, 0.0124, -0.0437, -0.043, 0.0258, 0.0213, -0.0309, -0.0018, -0.0067, 0.0172, 0.0089, -0.0171, 0.0275, -0.0518, -0.184, -0.013, -0.0241, 0.0526, -0.028, 0.0051, 0.0163, -0.0165, 0.0161, 0.1237, 0.0804, -0.0789, 0.0386, -0.3892, 0.0157, -0.0246, 0.0477, -0.0045, -0.0214, 0.0173, -0.0191, -0.1382, -0.0111, 0.0712, 0.1514, 0.0291, 0.0555, -0.0039, 0.0028, -0.0277, -0.0275, -0.0177, -0.0338, -0.0372, 0.2071, 0.046, -0.0294, 0.0435, -0.0169, -0.0121, 0.0253, 0.0198, 0.0918, 0.0193, 0.0668, 0.0288, 0.004, -0.0439, -0.0302, 0.0064, 0.0364, 0.0543, -0.0338, 0.0159, 0.0617, -0.0941, -0.0086, -0.0092, 0.03, -0.0241, -0.035, -0.0621, 0.0175, 0.0374, 0.0034, 0.0344, 0.1286, -0.0267, 0.1861, 0.0489, -0.0032, 0.018, -0.0228, 0.2414, -0.0935, 0.0612, -0.0209, 0.0136, 0.0392, -0.0135, -0.0253, 0.0335, 0.0095, 0.0419, 0.0076, 0.4522, -0.0188, 0.0233, -0.0474, 0.0159, -0.009, 0.0265, 0.0336, 0.0221, 0.0472, 0.0048, 0.0962, 0.0344, -0.0515, -0.0087, -0.098, -0.0288, 0.0377, 0.0202, -0.2979, -0.0387, -0.0198, -0.0161, -0.0045, 0.0087, -0.0387, 0.0421, 0.0383, 0.0258, 0.0069, -0.0298, -0.0198, -0.0152, 0.0033, 0.0075, 0.0358, -0.0155, -0.0111, 0.076, -0.0452, 0.0697, 0.0299, -0.0029, -0.0348, -0.027, 0.0351, 0.0559, 0.0591, 0.1559, -0.0254, -0.0259]\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.1208, 0.0144, -0.0927, -0.0181, 0.1125, 0.0495, -0.0467, -0.0193, 0.0746, -0.0119, 0.0817, 0.0189, 0.0596, 0.0681, -0.0196, 0.1208, -0.0401, -0.0571, -0.1717, 0.1402, -0.0256, 0.0317, 0.0454, 0.1437, -0.0175, 0.0, 0.0317, 0.201, 0.0216, -0.0175, 0.0565, -0.0301, 0.0244, -0.045, 0.0697, -0.031, 0.0226, -0.1532, -0.0043, -0.0578, 0.0305, -0.0136, 0.0062, -0.0937, -0.0747, 0.0217, -0.0568, 0.0469, 0.0378, -0.0502, -0.1851, 0.1019, -0.5416, -0.0081, 0.0269, 0.0144, 0.0698, -0.1973, -0.1727, 0.0096, 0.0363, 0.0037, -0.0497, 0.0526, -0.0885, -0.0309, 0.0668, -0.0395, 0.0433, -0.0078, -0.0366, 0.0286, -0.0301, 0.0023, 0.0284, -0.0965, -0.0228, -0.0075, -0.0968, 0.2231, 0.0464, -0.0177, -0.0262, -0.2496, -0.0343, 0.0082, -0.087, -0.0224, -0.5577, 0.0062, 0.0702, 0.0396, -0.0915, 0.0162, -0.0607, 0.0235, 0.0355, -0.1029, -0.0998, -0.0685, -0.271, 0.0459, 0.0225, 0.0368, 0.0759, -0.0153, -0.3556, 0.1072, 0.1017, -0.048, 0.0321, 0.0134, 0.0368, 0.0471, -0.2595, 0.0088, 0.0406, 0.0368, -0.0217, -0.2414, -0.0309, -0.0005, -0.0251, 0.0478, 0.1212, 0.2134, 0.0031, 0.2574, 0.0242, 0.0058, 0.0395, 0.027, -0.1224, -0.0122, 0.0541, -0.256, -0.0568, 0.0002, 0.0708, -0.0554, -0.0341, -0.0603, -0.0489, 0.4024, -0.0091, -0.0236, 0.1828, -0.0233, 0.0515, -0.108, -0.0503, -0.0573, 0.1002, -0.0205, 0.0517, 0.0068, -0.068, 0.0079, 0.0352, 0.0006, 0.0082, 0.0527, -0.0963, -0.0826, 0.1342, 0.0436, 0.1095, 0.0198, -0.0052, 0.0599, -0.1023, 0.0427, 0.08, -0.0834, 0.1454, 0.1132, 0.2139, -0.6224, -0.0544, -0.0541, 0.0465, 0.036, 0.0616, 0.0823, 0.0118, -0.3318, 0.0023, -0.0795, 0.6474, 0.0441, -0.0659, -0.0212, -0.0356, 0.0759, 0.0593, 0.0551, 0.0249, 0.0295, 0.279, -0.0214, -0.0544, -0.0026, 0.0026, -0.0114, 0.0507, 0.023, -0.0792, -0.0548, -0.0457, 0.0767, -0.1153, 0.0243, 0.034, 0.0527, -0.0762, 0.0999, -0.045, -0.0452, 0.0266, -0.0179, -0.0063, -0.0617, 0.0071, 0.0549, 0.1069, -0.0226, -0.0059, -0.0535, -0.0097, -0.0183, 0.2572, -0.0157, 0.1969, 0.0353, -0.1263, -0.4035, 0.0456, -0.1514, -0.2378, 0.124, 0.0007, 0.0017, 0.0054, 0.0166, -0.0424, 0.033, 0.0231, -0.0127, 0.0388, 0.3186, 0.0278, -0.0014, -0.0062, 0.0322, 0.3341, 0.003, -0.1596, 0.0029, -0.0605, -0.0301, -0.1263, -0.0143, -0.0255, 0.0705, -0.8316, -0.0347, 0.0973, 0.0364, -0.019, -0.018, 0.0257, 0.0578, -0.0185, 0.0114, -0.0141, 0.0957, 0.1123, -0.0257, 0.0211, -0.0602, 0.1877, -0.0612, 0.0284, -0.0978, -0.0529, -0.0266, -0.0446, -0.0117, -0.1348, -0.0104, 0.0987, -0.0837, 0.1619, 0.05, -0.0111, 0.0056, -0.1176, 0.2829, 0.0629, 0.0723]\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0314, 0.0149, -0.0205, 0.0557, 0.0205, -0.0405, 0.0044, -0.0118, -0.0424, -0.049, 0.0123, -0.0023, 0.0083, 0.0203, -0.0055, 0.0004, 0.0031, 0.0834, -0.0637, 0.0349, -0.0457, 0.0898, 0.0432, -0.0026, -0.0806, 0.0526, 0.0038, -0.0263, 0.0262, 0.0294, -0.0055, 0.0247, 0.0263, -0.018, -0.0112, 0.0273, -0.0116, 0.0214, -0.0195, 0.0116, -0.0549, -0.0488, 0.0112, 0.0063, -0.0783, -0.002, 0.0292, -0.0212, 0.0208, 0.0024, -0.0147, 0.0165, -0.5414, 0.03, 0.0143, -0.0017, -0.0407, 0.1298, -0.0201, 0.0314, -0.0184, -0.0424, 0.0014, -0.0571, 0.0164, 0.0138, 0.0341, 0.0563, 0.0247, 0.0347, 0.0689, 0.0543, -0.0183, -0.0371, 0.0431, 0.012, 0.0688, -0.0098, -0.0226, 0.1135, -0.0141, -0.0054, -0.0119, -0.0566, -0.0205, 0.0233, 0.0102, -0.0315, -0.0161, -0.0019, 0.0033, -0.0457, -0.0164, 0.0118, 0.0428, 0.0267, -0.0266, -0.0141, 0.0576, 0.0513, -0.071, -0.0518, 0.0271, 0.0022, -0.1131, 0.0104, -0.1406, 0.0032, 0.017, 0.0329, 0.002, -0.0997, -0.0957, 0.0234, 0.0161, -0.001, 0.0106, -0.0022, 0.0124, -0.2695, -0.0634, -0.0576, -0.0199, 0.0576, -0.1378, 0.0771, 0.0437, 0.0569, 0.0588, 0.0295, -0.0351, 0.0381, -0.0133, 0.0161, -0.0503, -0.2031, -0.0856, 0.0608, -0.0175, -0.022, -0.0389, 0.0169, 0.0498, 0.3705, -0.0604, -0.0628, -0.0244, -0.0707, -0.0015, -0.0172, 0.0158, 0.0173, -0.0505, -0.0219, 0.0269, 0.0487, -0.0391, 0.0063, -0.0457, -0.0057, 0.027, -0.0346, 0.0418, -0.0495, -0.3807, -0.0217, 0.0251, -0.0074, -0.0195, -0.0083, -0.1613, -0.0667, -0.0322, 0.0747, 0.0054, -0.0337, 0.0282, -0.2981, 0.052, -0.0155, 0.0078, -0.0601, 0.0236, 0.0141, 0.0156, 0.0074, 0.0129, -0.0426, 0.2257, 0.0365, -0.0322, -0.0239, 0.0033, -0.0038, 0.0397, -0.0383, -0.0171, -0.0329, -0.0741, 0.0276, 0.0548, 0.0042, -0.0282, 0.0351, 0.0503, 0.0134, -0.0078, 0.0157, 0.0043, 0.0211, -0.0642, 0.0078, -0.0224, 0.046, -0.0332, -0.019, -0.1574, -0.0022, 0.03, 0.0958, -0.0508, -0.0002, 0.0108, 0.0007, -0.0441, -0.031, -0.0396, 0.0195, -0.0184, 0.1056, 0.0989, -0.0166, 0.319, -0.0119, -0.0023, -0.018, 0.0394, -0.0697, -0.1624, 0.0192, 0.0027, 0.0104, 0.0139, 0.0033, -0.0001, -0.0441, 0.0124, -0.0177, 0.0182, 0.4824, 0.02, 0.0509, -0.0566, 0.0301, 0.0316, 0.0032, -0.0746, 0.0167, 0.0208, -0.025, -0.0214, 0.0037, -0.0355, 0.0386, -0.1528, -0.0324, 0.0454, 0.0605, 0.0038, 0.0018, 0.008, 0.0331, -0.005, -0.0109, -0.0723, 0.0122, 0.0056, 0.0147, 0.031, -0.0107, 0.0094, -0.0049, 0.0782, 0.0244, 0.0615, -0.0404, -0.0025, -0.0371, 0.0194, 0.0174, -0.0003, 0.0575, -0.0078, -0.0101, -0.0901, -0.0214, 0.0267, 0.098, 0.0893, 0.0148]\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0522, -0.0577, -0.08, -0.0138, -0.0632, 0.0383, -0.0158, 0.1009, 0.1504, 0.0328, 0.0768, -0.0675, -0.0245, 0.0406, -0.0328, -0.0579, -0.017, 0.011, -0.126, 0.1232, -0.0153, 0.0165, 0.105, -0.0045, 0.025, 0.053, -0.005, -0.1389, -0.0299, -0.0116, 0.0492, -0.0364, -0.1012, -0.0191, 0.0373, -0.081, 0.0657, 0.0358, 0.0732, -0.0816, 0.0009, -0.0249, -0.077, 0.1623, -0.1175, -0.0071, -0.038, 0.0305, 0.062, 0.0618, -0.0716, -0.1001, -0.5564, 0.0087, 0.0555, 0.0177, 0.0222, -0.0323, 0.1196, -0.0463, -0.0475, 0.053, -0.0289, -0.0057, 0.047, 0.0076, 0.0207, -0.0438, -0.0163, 0.011, 0.0221, -0.0711, -0.0315, -0.0356, 0.0074, 0.0709, 0.1003, 0.0979, 0.0106, 0.0881, 0.0003, 0.1519, 0.0095, -0.2199, -0.0371, 0.0366, -0.0174, -0.0459, -0.1171, 0.0885, -0.0168, -0.0144, -0.0345, 0.0175, 0.0443, -0.008, -0.0116, 0.0218, -0.0292, -0.0804, -0.1982, 0.017, 0.0099, 0.0297, 0.0073, -0.0415, 0.0753, -0.0301, -0.1676, 0.0376, 0.033, -0.3744, -0.049, -0.0712, 0.0666, -0.0117, 0.0585, -0.0962, -0.0816, -0.2582, -0.0403, -0.1146, -0.0818, 0.1487, -0.1585, 0.2021, -0.0174, 0.1464, -0.1206, 0.0154, -0.0007, -0.0399, 0.0218, -0.1013, 0.0487, -0.2436, 0.0481, -0.0288, 0.0094, 0.0108, -0.0466, -0.0301, 0.0111, 0.2631, 0.1462, 0.0456, 0.1315, -0.1163, -0.1031, -0.014, -0.0452, 0.01, -0.0869, -0.0759, 0.0424, 0.0302, -0.0585, -0.0625, -0.0263, -0.0134, 0.164, 0.1405, -0.0468, -0.0048, -0.3448, 0.0088, 0.0358, 0.0816, -0.0784, -0.0014, -0.0572, -0.0078, 0.0553, 0.0434, 0.3011, -0.0993, 0.2263, -0.1553, 0.0837, 0.0191, 0.029, -0.0192, -0.0538, -0.005, -0.0435, 0.0477, -0.0344, -0.1844, 0.2465, 0.02, -0.014, 0.0137, 0.0825, -0.0335, -0.061, 0.1011, -0.0039, -0.0336, 0.1575, 0.0063, 0.0207, 0.0494, 0.018, -0.0354, 0.0293, -0.1018, 0.0932, -0.1445, 0.1547, 0.0049, 0.0552, -0.0438, -0.0178, -0.0603, -0.0367, 0.0044, -0.0518, 0.0132, 0.0255, -0.0641, 0.1019, -0.1094, -0.1376, 0.0305, 0.0507, -0.1747, -0.0077, 0.0993, -0.0008, 0.0333, -0.0107, 0.0062, 0.2749, -0.2, 0.0457, 0.0986, 0.0683, -0.064, -0.2219, -0.0103, 0.0155, 0.0711, 0.0893, -0.0376, -0.0259, 0.0159, 0.0514, 0.033, 0.054, 0.3481, 0.0075, 0.0394, 0.0322, -0.0571, -0.107, -0.0318, 0.0374, -0.0441, 0.0561, 0.0034, -0.1182, -0.1773, 0.0183, -0.0646, -0.2369, 0.0798, -0.1296, -0.0233, -0.0756, 0.029, 0.0196, -0.0783, 0.0319, -0.035, -0.0019, 0.1052, -0.1602, -0.0377, -0.0288, -0.0471, 0.0298, 0.1499, 0.0558, 0.0641, 0.0663, 0.0251, -0.046, -0.1189, -0.1004, 0.1189, 0.0945, 0.0211, -0.0613, -0.0054, -0.1099, -0.076, -0.0626, 0.2131, 0.1156, -0.0522]\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.40s/it]\u001b[A\n","03/28/2021 18:11:50 - INFO - bert_utils -     flaw_f1 = 0.35294117647058826\n","03/28/2021 18:11:50 - INFO - bert_utils -     flaw_precision = 1.0\n","03/28/2021 18:11:50 - INFO - bert_utils -     flaw_recall = 0.21428571428571427\n","03/28/2021 18:11:50 - INFO - bert_utils -     loss = 0.04684960097074509\n","Epoch:  48%|█████████████████▎                  | 12/25 [00:59<01:04,  4.97s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0522, -0.0577, -0.08, -0.0138, -0.0632, 0.0383, -0.0158, 0.1009, 0.1504, 0.0328, 0.0768, -0.0675, -0.0245, 0.0406, -0.0328, -0.0579, -0.017, 0.011, -0.126, 0.1232, -0.0153, 0.0165, 0.105, -0.0045, 0.025, 0.053, -0.005, -0.1389, -0.0299, -0.0116, 0.0492, -0.0364, -0.1012, -0.0191, 0.0373, -0.081, 0.0657, 0.0358, 0.0732, -0.0816, 0.0009, -0.0249, -0.077, 0.1623, -0.1175, -0.0071, -0.038, 0.0305, 0.062, 0.0618, -0.0716, -0.1001, -0.5564, 0.0087, 0.0555, 0.0177, 0.0222, -0.0323, 0.1196, -0.0463, -0.0475, 0.053, -0.0289, -0.0057, 0.047, 0.0076, 0.0207, -0.0438, -0.0163, 0.011, 0.0221, -0.0711, -0.0315, -0.0356, 0.0074, 0.0709, 0.1003, 0.0979, 0.0106, 0.0881, 0.0003, 0.1519, 0.0095, -0.2199, -0.0371, 0.0366, -0.0174, -0.0459, -0.1171, 0.0885, -0.0168, -0.0144, -0.0345, 0.0175, 0.0443, -0.008, -0.0116, 0.0218, -0.0292, -0.0804, -0.1982, 0.017, 0.0099, 0.0297, 0.0073, -0.0415, 0.0753, -0.0301, -0.1676, 0.0376, 0.033, -0.3744, -0.049, -0.0712, 0.0666, -0.0117, 0.0585, -0.0962, -0.0816, -0.2582, -0.0403, -0.1146, -0.0818, 0.1487, -0.1585, 0.2021, -0.0174, 0.1464, -0.1206, 0.0154, -0.0007, -0.0399, 0.0218, -0.1013, 0.0487, -0.2436, 0.0481, -0.0288, 0.0094, 0.0108, -0.0466, -0.0301, 0.0111, 0.2631, 0.1462, 0.0456, 0.1315, -0.1163, -0.1031, -0.014, -0.0452, 0.01, -0.0869, -0.0759, 0.0424, 0.0302, -0.0585, -0.0625, -0.0263, -0.0134, 0.164, 0.1405, -0.0468, -0.0048, -0.3448, 0.0088, 0.0358, 0.0816, -0.0784, -0.0014, -0.0572, -0.0078, 0.0553, 0.0434, 0.3011, -0.0993, 0.2263, -0.1553, 0.0837, 0.0191, 0.029, -0.0192, -0.0538, -0.005, -0.0435, 0.0477, -0.0344, -0.1844, 0.2465, 0.02, -0.014, 0.0137, 0.0825, -0.0335, -0.061, 0.1011, -0.0039, -0.0336, 0.1575, 0.0063, 0.0207, 0.0494, 0.018, -0.0354, 0.0293, -0.1018, 0.0932, -0.1445, 0.1547, 0.0049, 0.0552, -0.0438, -0.0178, -0.0603, -0.0367, 0.0044, -0.0518, 0.0132, 0.0255, -0.0641, 0.1019, -0.1094, -0.1376, 0.0305, 0.0507, -0.1747, -0.0077, 0.0993, -0.0008, 0.0333, -0.0107, 0.0062, 0.2749, -0.2, 0.0457, 0.0986, 0.0683, -0.064, -0.2219, -0.0103, 0.0155, 0.0711, 0.0893, -0.0376, -0.0259, 0.0159, 0.0514, 0.033, 0.054, 0.3481, 0.0075, 0.0394, 0.0322, -0.0571, -0.107, -0.0318, 0.0374, -0.0441, 0.0561, 0.0034, -0.1182, -0.1773, 0.0183, -0.0646, -0.2369, 0.0798, -0.1296, -0.0233, -0.0756, 0.029, 0.0196, -0.0783, 0.0319, -0.035, -0.0019, 0.1052, -0.1602, -0.0377, -0.0288, -0.0471, 0.0298, 0.1499, 0.0558, 0.0641, 0.0663, 0.0251, -0.046, -0.1189, -0.1004, 0.1189, 0.0945, 0.0211, -0.0613, -0.0054, -0.1099, -0.076, -0.0626, 0.2131, 0.1156, -0.0522]\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0897, 0.016, -0.0571, 0.0405, -0.0696, -0.1237, 0.0301, 0.0248, -0.0303, 0.0174, 0.0063, 0.0184, 0.0217, -0.0257, 0.035, -0.0242, 0.0029, 0.0188, -0.057, 0.0252, -0.021, -0.0008, 0.036, -0.0729, -0.0665, 0.0989, 0.0676, 0.0852, -0.0089, 0.0313, -0.0069, -0.0032, -0.0462, 0.0497, 0.0261, 0.0268, -0.031, -0.1361, -0.0062, 0.0375, -0.032, -0.0106, 0.0534, -0.0187, 0.0638, 0.0094, 0.0047, -0.053, 0.0093, -0.0087, 0.0004, 0.0493, -0.6296, 0.0222, 0.019, 0.0268, -0.0426, 0.0057, -0.1683, 0.0244, -0.0213, -0.0181, 0.0421, -0.0309, -0.0089, 0.0032, 0.0108, -0.0049, 0.0258, 0.0278, -0.0163, 0.02, 0.0164, -0.0954, -0.0032, 0.0043, 0.0104, -0.0088, 0.0007, 0.035, -0.0206, -0.0083, -0.0114, -0.1869, 0.0258, 0.001, 0.0085, 0.0151, 0.2125, 0.0071, 0.0319, -0.0482, 0.0621, 0.0626, 0.0159, -0.0013, 0.0087, 0.0686, -0.0034, 0.0238, -0.0452, -0.0198, 0.0112, 0.0109, -0.1022, -0.0272, 0.2337, -0.0465, 0.1592, -0.0407, -0.1029, -0.0487, -0.0676, 0.0676, -0.0328, 0.0323, 0.0077, 0.019, 0.0017, -0.2974, 0.0011, -0.0356, 0.0693, -0.048, -0.0821, -0.0644, -0.0284, -0.0191, -0.0233, 0.0353, -0.0463, 0.0656, 0.0019, -0.0212, -0.0309, -0.3534, -0.0309, 0.0076, -0.0419, 0.0457, -0.0306, 0.0357, 0.0667, 0.3659, 0.0149, -0.0443, 0.0068, -0.0378, 0.0146, 0.0215, 0.1081, 0.0124, -0.0437, -0.043, 0.0258, 0.0213, -0.0309, -0.0018, -0.0067, 0.0172, 0.0089, -0.0171, 0.0275, -0.0518, -0.184, -0.013, -0.0241, 0.0526, -0.028, 0.0051, 0.0163, -0.0165, 0.0161, 0.1237, 0.0804, -0.0789, 0.0386, -0.3892, 0.0157, -0.0246, 0.0477, -0.0045, -0.0214, 0.0173, -0.0191, -0.1382, -0.0111, 0.0712, 0.1514, 0.0291, 0.0555, -0.0039, 0.0028, -0.0277, -0.0275, -0.0177, -0.0338, -0.0372, 0.2071, 0.046, -0.0294, 0.0435, -0.0169, -0.0121, 0.0253, 0.0198, 0.0918, 0.0193, 0.0668, 0.0288, 0.004, -0.0439, -0.0302, 0.0064, 0.0364, 0.0543, -0.0338, 0.0159, 0.0617, -0.0941, -0.0086, -0.0092, 0.03, -0.0241, -0.035, -0.0621, 0.0175, 0.0374, 0.0034, 0.0344, 0.1286, -0.0267, 0.1861, 0.0489, -0.0032, 0.018, -0.0228, 0.2414, -0.0935, 0.0612, -0.0209, 0.0136, 0.0392, -0.0135, -0.0253, 0.0335, 0.0095, 0.0419, 0.0076, 0.4522, -0.0188, 0.0233, -0.0474, 0.0159, -0.009, 0.0265, 0.0336, 0.0221, 0.0472, 0.0048, 0.0962, 0.0344, -0.0515, -0.0087, -0.098, -0.0288, 0.0377, 0.0202, -0.2979, -0.0387, -0.0198, -0.0161, -0.0045, 0.0087, -0.0387, 0.0421, 0.0383, 0.0258, 0.0069, -0.0298, -0.0198, -0.0152, 0.0033, 0.0075, 0.0358, -0.0155, -0.0111, 0.076, -0.0452, 0.0697, 0.0299, -0.0029, -0.0348, -0.027, 0.0351, 0.0559, 0.0591, 0.1559, -0.0254, -0.0259]\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0657, 0.046, 0.0251, -0.0332, 0.0141, -0.221, -0.0121, -0.0384, 0.0709, -0.0542, 0.06, 0.0671, 0.0604, 0.1536, -0.0443, 0.0414, 0.0221, 0.0859, -0.0448, -0.0593, -0.0176, -0.036, 0.0366, -0.296, 0.0502, -0.2343, 0.047, -0.0906, 0.0382, -0.2112, 0.0204, -0.0113, 0.2169, -0.0023, 0.0375, 0.0031, 0.0218, 0.0073, -0.0524, 0.0786, 0.0447, -0.0189, -0.1872, 0.0252, -0.0965, -0.0778, -0.1135, -0.0199, 0.0901, 0.0191, -0.0134, -0.001, -0.6779, -0.0296, -0.0169, 0.0048, 0.0055, 0.0217, 0.0459, 0.1198, -0.1142, -0.0131, 0.1316, -0.034, 0.1073, -0.0355, -0.0246, 0.0521, -0.055, 0.0158, 0.03, 0.0168, 0.0335, 0.1986, 0.072, -0.0165, 0.0566, -0.1098, -0.0796, -0.0808, -0.0356, 0.0266, 0.1186, -0.2048, -0.0201, -0.1187, -0.0025, -0.0004, -0.0488, 0.0154, -0.0453, -0.0443, -0.0276, -0.1272, -0.0878, 0.007, 0.0324, -0.0797, -0.0007, -0.0803, -0.1543, -0.01, 0.0158, 0.0556, -0.1504, -0.0414, 0.216, -0.0864, 0.149, -0.0059, 0.0869, 0.2644, -0.023, 0.0089, -0.0612, 0.0043, 0.0118, 0.1146, -0.017, -0.3391, 0.117, 0.0525, 0.0654, 0.188, 0.0733, 0.1355, -0.0028, -0.0488, -0.1325, -0.0084, 0.0245, -0.0142, -0.0509, 0.0929, 0.0061, -0.2864, 0.1034, -0.0612, -0.0258, -0.0505, -0.0298, 0.0362, 0.0213, 0.2663, -0.0181, -0.059, 0.0939, -0.0895, 0.0385, -0.0212, 0.1066, 0.1416, 0.0303, 0.0044, -0.085, -0.0252, -0.0332, 0.0527, -0.032, -0.0311, -0.0576, 0.0001, 0.0041, 0.0065, -0.1985, 0.0077, 0.1188, 0.008, 0.0286, -0.0599, 0.1298, 0.0204, 0.0183, 0.1724, 0.0711, 0.0252, 0.1688, -0.0282, 0.0433, 0.0193, -0.0003, 0.0717, 0.0823, 0.0143, 0.0575, -0.2815, -0.0972, -0.1434, 0.0879, -0.0272, -0.041, 0.0076, 0.0508, 0.0021, 0.0043, 0.0017, -0.0012, -0.0067, 0.1853, 0.0582, 0.0609, -0.0207, 0.0806, 0.0253, 0.0604, 0.0744, -0.1165, -0.0971, -0.0967, 0.0329, 0.0521, 0.0893, 0.0125, -0.0923, -0.0302, 0.014, -0.1939, -0.0287, 0.0101, 0.1531, 0.0165, -0.1121, 0.0018, 0.1513, 0.0316, -0.094, -0.0563, -0.0422, 0.0181, 0.1168, -0.1048, 0.0031, 0.2662, 0.0742, 0.0081, 0.1066, -0.0511, 0.0307, -0.1781, 0.0602, -0.0484, 0.0319, 0.0762, 0.0056, -0.0201, -0.0665, -0.0476, 0.0214, -0.0166, 0.3347, 0.0167, 0.0944, -0.0148, -0.022, -0.2036, 0.0307, -0.1116, -0.0157, 0.0638, 0.017, -0.1067, 0.0272, -0.0475, -0.0247, -0.0591, -0.0323, 0.1388, 0.0192, -0.0207, 0.0467, 0.0291, -0.0942, -0.0741, -0.0043, -0.0332, 0.051, -0.0713, 0.0526, 0.004, -0.0196, -0.1, -0.1013, -0.0433, -0.07, -0.0107, 0.0362, -0.0375, 0.1955, -0.1428, 0.0313, -0.0333, 0.0039, 0.0837, 0.0162, -0.1025, 0.0986, -0.0369, 0.2393, 0.0885, -0.0732]\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.30s/it]\u001b[A\n","03/28/2021 18:11:55 - INFO - bert_utils -     flaw_f1 = 0.6153846153846154\n","03/28/2021 18:11:55 - INFO - bert_utils -     flaw_precision = 0.8\n","03/28/2021 18:11:55 - INFO - bert_utils -     flaw_recall = 0.5\n","03/28/2021 18:11:55 - INFO - bert_utils -     loss = 0.04648766666650772\n","Epoch:  52%|██████████████████▋                 | 13/25 [01:04<00:59,  4.92s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.36s/it]\u001b[A\n","03/28/2021 18:12:00 - INFO - bert_utils -     flaw_f1 = 0.8999999999999999\n","03/28/2021 18:12:00 - INFO - bert_utils -     flaw_precision = 0.84375\n","03/28/2021 18:12:00 - INFO - bert_utils -     flaw_recall = 0.9642857142857143\n","03/28/2021 18:12:00 - INFO - bert_utils -     loss = 0.057157643139362335\n","Epoch:  56%|████████████████████▏               | 14/25 [01:09<00:54,  4.92s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0986, -0.2203, 0.1277, -0.0038, 0.1349, 0.1766, -0.0717, 0.0962, 0.0286, 0.1331, -0.088, 0.0097, 0.2899, -0.0971, 0.1511, -0.1695, -0.0228, 0.0897, 0.0779, 0.0124, -0.2479, 0.1565, -0.059, -0.1955, 0.1632, -0.0734, -0.1309, 0.1795, -0.0663, -0.2319, 0.0335, 0.0467, 0.0133, 0.1546, 0.3338, 0.3256, -0.0399, 0.1533, 0.0351, 0.0008, 0.0269, 0.1504, -0.1719, 0.003, -0.0687, -0.0554, 0.2062, -0.2141, -0.1168, -0.265, 0.1165, -0.1076, -0.7506, -0.0155, -0.0613, -0.1515, 0.0801, 0.021, 0.142, 0.0209, 0.0878, -0.3437, -0.0167, 0.1133, -0.0731, -0.1679, 0.1667, -0.0529, 0.1493, 0.1807, 0.0853, -0.0441, 0.097, 0.1113, -0.2308, -0.0581, -0.034, 0.1075, -0.0655, 0.2295, 0.1005, 0.0773, 0.0227, -0.1905, 0.0464, 0.0436, 0.1483, 0.0768, 0.2949, 0.1511, 0.1139, -0.0214, -0.0618, 0.031, -0.1978, -0.0764, 0.0518, -0.0625, 0.1776, -0.1261, -0.1297, 0.0028, -0.2233, 0.0226, 0.0023, 0.0425, -0.0286, -0.0679, 0.0191, 0.0678, 0.0301, 0.142, 0.1366, 0.0366, -0.0746, -0.0858, 0.1336, -0.0738, 0.2338, -0.3484, 0.2, 0.1991, 0.1148, -0.0628, 0.1148, 0.1448, 0.0919, -0.2645, 0.097, 0.1204, -0.0148, 0.0898, -0.01, -0.1413, -0.034, 0.1518, 0.1655, -0.1381, 0.033, 0.0163, 0.0248, -0.1674, 0.0202, 0.1834, -0.1282, -0.065, 0.1216, 0.0506, -0.2409, 0.1017, -0.1693, 0.1242, 0.1661, 0.0651, -0.1442, 0.1766, 0.055, -0.0391, 0.0088, -0.0457, -0.1151, -0.1501, -0.0316, 0.1901, 0.1254, -0.1613, 0.0873, -0.0148, -0.2089, 0.2145, 0.0062, -0.0076, 0.0744, -0.1763, 0.2016, 0.162, 0.2642, -0.118, -0.1484, 0.0179, -0.0896, -0.0677, -0.023, -0.263, 0.0056, -0.036, 0.1879, -0.0834, -0.2536, 0.0418, -0.0651, 0.0167, 0.1317, 0.0047, -0.0016, -0.1334, -0.1382, 0.0937, 0.1303, 0.0645, 0.0534, -0.0298, 0.0976, 0.1149, 0.0646, 0.1398, 0.1059, -0.2002, -0.004, 0.0898, 0.0947, -0.0584, -0.0236, 0.0199, -0.0228, 0.0102, -0.0002, 0.0256, -0.2023, 0.0615, 0.0891, -0.0925, -0.0225, -0.0586, 0.0243, -0.1384, 0.1393, -0.0206, -0.085, -0.1646, -0.1177, -0.1381, 0.2971, -0.2867, -0.1304, -0.2274, -0.0408, -0.0374, -0.2126, -0.078, 0.0264, -0.0744, -0.0357, 0.1726, 0.0159, 0.1339, 0.1118, -0.0977, 0.0761, 0.2989, 0.0438, 0.0818, 0.0813, 0.093, 0.1717, -0.0657, -0.0647, 0.0602, -0.0034, 0.1075, 0.0793, -0.0193, 0.0666, 0.0418, -0.5082, 0.232, 0.0267, 0.0283, -0.2717, -0.1061, -0.1167, 0.1112, 0.1064, -0.1985, -0.2026, 0.13, -0.054, 0.0633, 0.1677, -0.2039, 0.1521, 0.2566, -0.0923, 0.0955, -0.0315, 0.2171, -0.0028, -0.1608, 0.0689, -0.0604, 0.0939, 0.0334, 0.0282, -0.0633, -0.0004, -0.0849, 0.0033, -0.0475, 0.1096, 0.097]\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0177, -0.0273, -0.0135, 0.0351, -0.0135, -0.0357, -0.0058, -0.0239, 0.0311, -0.015, 0.046, 0.0713, 0.0199, 0.1177, -0.0441, 0.0061, 0.0334, 0.015, -0.1213, 0.0951, -0.0248, 0.0579, 0.0164, -0.0854, -0.0057, -0.2043, -0.0105, 0.0987, 0.0102, 0.022, -0.0094, -0.0339, 0.1424, -0.0115, -0.0111, 0.0551, 0.0272, -0.0901, 0.049, -0.0315, 0.0028, -0.0097, 0.0617, 0.0173, -0.1601, 0.1213, 0.0135, 0.0359, -0.0365, 0.0771, -0.0066, -0.0964, -0.5744, 0.0209, 0.0193, 0.0463, -0.0365, -0.0268, 0.1612, 0.0241, -0.0049, 0.0039, 0.0862, 0.0059, -0.1359, 0.0722, 0.0101, 0.0269, 0.0008, 0.0695, -0.0395, 0.0234, 0.0017, -0.0012, 0.0806, 0.0108, 0.0248, -0.0638, -0.0591, 0.0374, 0.0009, -0.0823, -0.0843, -0.2126, 0.0201, 0.0672, -0.0022, -0.0099, 0.0751, 0.0265, 0.0394, -0.0169, 0.034, 0.029, 0.0211, 0.0267, 0.0472, -0.0088, -0.0015, 0.0405, -0.1484, -0.025, 0.0326, -0.0136, -0.1963, -0.0048, 0.1806, -0.0943, 0.2022, 0.0232, 0.0321, -0.0148, 0.006, 0.0183, 0.0258, -0.0937, -0.0035, -0.0076, 0.0148, -0.1691, 0.0519, -0.0441, -0.0046, 0.1673, -0.0117, 0.16, 0.0364, -0.0148, 0.0751, 0.019, -0.083, 0.0424, 0.1003, -0.0553, 0.0296, -0.0735, -0.0384, 0.0942, -0.0709, 0.0028, -0.04, -0.0545, 0.0755, 0.2531, 0.0444, -0.0242, -0.0157, -0.0609, 0.0407, 0.0239, 0.0153, -0.0288, -0.0555, -0.0653, -0.0181, 0.0356, -0.059, -0.0639, -0.0358, -0.0805, -0.0492, -0.0448, 0.0934, 0.0278, -0.4626, -0.0006, 0.0442, -0.0443, 0.0646, 0.0288, -0.1348, -0.0047, -0.0405, -0.0361, 0.0506, -0.0172, 0.1548, -0.4293, 0.0389, 0.0129, -0.0289, -0.0432, -0.0958, -0.019, 0.0415, -0.0265, 0.0261, -0.0644, 0.3606, 0.0125, 0.015, 0.1054, 0.0149, 0.0168, -0.1102, 0.0427, -0.0326, -0.0481, 0.1979, 0.0206, -0.0647, 0.032, -0.0018, -0.036, 0.1749, 0.0343, 0.0379, -0.0489, -0.0602, 0.0921, -0.0934, 0.0158, -0.0161, 0.0573, 0.0169, -0.0587, -0.073, 0.0644, 0.0019, -0.0086, -0.013, -0.0641, 0.1164, 0.018, 0.0429, -0.0438, -0.0018, 0.052, 0.0021, 0.0613, 0.0506, 0.0133, 0.1732, 0.1022, -0.0072, 0.102, -0.0276, 0.085, -0.1872, -0.0474, 0.0236, -0.0105, 0.0169, -0.0141, -0.0175, -0.0766, 0.0296, -0.0054, -0.0303, 0.3495, 0.0092, 0.1807, -0.0925, 0.0223, -0.2088, 0.0025, 0.0295, -0.0186, 0.0535, 0.0086, -0.2061, 0.0099, 0.015, 0.0017, -0.1505, -0.0323, 0.0321, 0.0308, 0.0344, -0.007, -0.0379, 0.0385, -0.0204, 0.0254, -0.0234, -0.0235, 0.0157, 0.0321, 0.0237, 0.036, -0.1336, -0.1436, 0.1274, -0.0019, 0.044, -0.0512, -0.0246, -0.0182, -0.0126, 0.0601, 0.0466, 0.0236, -0.0276, -0.0362, -0.0115, -0.1296, 0.0037, 0.1877, 0.0338, -0.0671]\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0568, -0.1339, 0.1573, 0.0057, 0.194, -0.2087, 0.0217, 0.0051, -0.0037, 0.0886, -0.025, -0.1547, -0.0509, 0.0492, 0.1833, -0.0597, 0.0121, 0.0852, 0.256, 0.0516, 0.0196, 0.1505, 0.0116, -0.0267, -0.037, -0.1625, 0.0446, -0.256, 0.0354, -0.0035, 0.1073, 0.0501, -0.0761, -0.0933, 0.0849, 0.0552, 0.0571, -0.3266, -0.0249, -0.0003, 0.1035, -0.0916, 0.1449, -0.1644, 0.1403, -0.1167, 0.0611, 0.0411, -0.0707, 0.0029, -0.0496, 0.0168, -0.7128, -0.0906, 0.1049, -0.0882, -0.0613, 0.0491, 0.1263, 0.0096, 0.0423, -0.0286, 0.1267, -0.0772, -0.0205, -0.0492, 0.0136, 0.0094, -0.143, 0.0167, -0.0316, -0.0583, -0.0147, 0.1385, -0.0844, -0.0134, 0.1329, 0.0116, -0.2098, 0.2224, 0.002, 0.1558, 0.0542, -0.174, 0.0897, -0.032, 0.05, 0.006, -0.2922, -0.1066, 0.0215, 0.0971, -0.0657, 0.0037, 0.0508, -0.174, -0.0422, -0.0416, 0.0016, -0.0965, -0.2728, -0.1393, 0.0569, -0.0341, -0.0352, -0.0207, 0.2142, 0.079, -0.209, -0.0819, -0.0115, -0.1229, 0.0603, -0.13, -0.0065, 0.0507, 0.0453, -0.0568, 0.0429, -0.2566, 0.0585, -0.0201, -0.1377, 0.0948, -0.4483, 0.2669, -0.1096, -0.0509, -0.2165, 0.0468, -0.1828, 0.1138, 0.0407, 0.042, -0.021, -0.2902, 0.0045, 0.0677, 0.121, -0.0588, 0.0427, 0.033, 0.0429, 0.3968, -0.0114, -0.0931, 0.1555, -0.0371, -0.0992, -0.0378, -0.0278, -0.1709, -0.1218, -0.0116, 0.073, 0.0756, -0.1181, -0.0068, -0.0803, 0.0444, 0.0408, 0.0389, -0.0052, 0.0638, -0.3224, 0.1537, 0.1595, 0.004, 0.0665, 0.0536, -0.0066, -0.0646, 0.0127, 0.0308, 0.1717, -0.0062, 0.3631, -0.3776, 0.0954, -0.0606, 0.1313, -0.0308, -0.0911, 0.079, -0.0056, 0.2828, 0.0027, -0.1449, 0.0889, -0.0392, 0.0279, 0.0361, -0.1109, 0.0228, -0.0363, 0.049, -0.0457, -0.1489, 0.3391, 0.0055, 0.0712, 0.0943, 0.0467, 0.0785, -0.0447, -0.0143, 0.0106, -0.1578, -0.2198, 0.0843, 0.074, -0.0401, -0.0525, 0.027, 0.0177, -0.0929, -0.0504, -0.0542, -0.0809, 0.052, 0.1789, 0.1612, 0.0008, 0.0301, 0.0396, -0.346, -0.0021, 0.0136, 0.049, -0.0123, -0.0853, 0.0537, 0.3109, -0.0686, 0.151, 0.0611, 0.0794, -0.1792, -0.2695, -0.0054, -0.0379, -0.0062, 0.0115, 0.006, 0.0348, 0.0524, -0.0755, 0.1379, 0.107, 0.4634, -0.0354, -0.0732, -0.0586, 0.0211, 0.238, -0.0239, 0.1504, 0.0316, -0.0489, 0.1382, 0.0628, 0.0233, -0.1273, -0.0893, -0.4087, -0.0572, 0.1639, -0.0343, -0.1047, 0.215, -0.0951, -0.0839, -0.0705, -0.0843, 0.0309, 0.0536, -0.0857, -0.0801, 0.0284, 0.0525, -0.013, -0.0412, 0.0942, -0.114, 0.0839, 0.0898, 0.1567, -0.024, 0.065, 0.0236, -0.0525, -0.0036, -0.003, -0.0604, 0.0575, 0.1172, -0.0517, 0.1603, 0.0341, 0.033]\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.41s/it]\u001b[A\n","03/28/2021 18:12:05 - INFO - bert_utils -     flaw_f1 = 0.6976744186046512\n","03/28/2021 18:12:05 - INFO - bert_utils -     flaw_precision = 0.8333333333333334\n","03/28/2021 18:12:05 - INFO - bert_utils -     flaw_recall = 0.6\n","03/28/2021 18:12:05 - INFO - bert_utils -     loss = 0.058999400585889816\n","Epoch:  60%|█████████████████████▌              | 15/25 [01:14<00:49,  4.92s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0206, 0.0231, -0.0574, 0.0388, -0.1158, -0.0109, 0.0054, 0.0025, -0.063, -0.0564, 0.0296, -0.0682, 0.0355, -0.0558, 0.0059, -0.0383, 0.0515, 0.0712, -0.0886, 0.1198, -0.0334, 0.0043, 0.0388, 0.0457, -0.0428, 0.0495, -0.0072, 0.0304, -0.0174, 0.0421, 0.0032, -0.039, -0.0322, -0.0113, 0.0603, 0.0074, 0.0102, 0.0481, -0.0294, 0.0271, 0.005, -0.0374, 0.0533, -0.1492, 0.0262, 0.0029, -0.0423, 0.0086, -0.0379, -0.0297, -0.0117, 0.0891, -0.5834, -0.0196, 0.038, 0.0106, -0.023, -0.028, 0.0464, 0.009, -0.0389, -0.033, -0.1084, 0.0001, 0.0224, 0.1006, 0.0005, 0.0152, -0.0146, -0.0575, -0.0436, -0.0181, -0.0158, -0.0427, 0.0685, -0.0116, 0.029, 0.0035, -0.1194, -0.0918, 0.0197, 0.1237, -0.0245, -0.3306, -0.0037, -0.0307, -0.025, 0.0059, 0.1157, -0.0114, -0.0106, -0.0137, 0.0109, 0.0819, 0.052, 0.0564, 0.0283, -0.0403, 0.0134, -0.0875, -0.0785, -0.0019, 0.0188, 0.0821, -0.095, -0.0039, 0.0945, -0.0765, 0.1313, -0.0581, 0.0405, -0.0103, 0.0653, 0.0289, 0.0409, -0.0256, -0.0071, 0.0012, -0.0567, -0.2729, 0.0702, -0.0213, 0.0021, 0.1257, 0.0059, 0.0772, 0.0403, -0.0276, -0.101, -0.0033, -0.0749, -0.0207, -0.0789, 0.0385, -0.0658, -0.1691, -0.0115, -0.0056, 0.1989, 0.1064, -0.0167, 0.0653, 0.0628, 0.3884, -0.0158, -0.0042, 0.0209, -0.0511, -0.0213, -0.0188, -0.009, 0.0099, -0.023, -0.0427, 0.0403, 0.0124, -0.0669, -0.0269, -0.0124, 0.0256, -0.041, -0.0619, 0.0162, -0.1176, -0.2902, 0.0084, 0.1346, -0.0781, 0.0389, -0.0321, -0.0553, -0.0213, -0.0142, 0.0333, 0.0863, -0.1304, 0.1478, -0.5894, 0.0465, 0.0001, 0.0436, -0.0236, 0.0123, 0.0241, 0.02, -0.2658, -0.0006, -0.0608, 0.3386, -0.0067, 0.0549, 0.0206, -0.0162, 0.0078, -0.0411, 0.0081, 0.0067, -0.0451, 0.1383, 0.0427, -0.0006, -0.0881, 0.0111, 0.0129, -0.0609, -0.0975, -0.0001, 0.1469, 0.0451, 0.0174, -0.0055, -0.0166, -0.0333, 0.0994, 0.055, -0.0201, -0.333, -0.0084, 0.155, -0.0631, 0.0423, 0.0196, -0.0049, 0.0698, -0.0575, -0.1492, 0.026, 0.0842, -0.0507, 0.1491, 0.039, 0.0039, 0.2166, -0.0059, 0.013, -0.0529, -0.0177, 0.1542, -0.1744, 0.0889, -0.074, -0.0335, 0.0167, -0.0347, 0.0433, -0.064, 0.0335, -0.0394, 0.0444, 0.3293, -0.0081, -0.0297, 0.0637, 0.0484, -0.3762, 0.0191, -0.0618, 0.0386, 0.0234, 0.0003, 0.0235, 0.033, 0.0034, -0.0156, -0.1348, 0.0016, 0.0838, -0.0008, -0.0768, -0.0085, -0.0156, 0.0373, -0.0186, 0.0309, 0.0197, -0.0242, 0.042, 0.0556, 0.0171, 0.0195, -0.1021, 0.0454, -0.031, -0.0079, 0.0583, -0.0137, -0.0559, -0.0094, 0.0233, 0.04, 0.0042, -0.0218, -0.0945, -0.0154, -0.029, -0.0141, 0.008, 0.1221, 0.0558, -0.1314]\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0568, -0.1339, 0.1573, 0.0057, 0.194, -0.2087, 0.0217, 0.0051, -0.0037, 0.0886, -0.025, -0.1547, -0.0509, 0.0492, 0.1833, -0.0597, 0.0121, 0.0852, 0.256, 0.0516, 0.0196, 0.1505, 0.0116, -0.0267, -0.037, -0.1625, 0.0446, -0.256, 0.0354, -0.0035, 0.1073, 0.0501, -0.0761, -0.0933, 0.0849, 0.0552, 0.0571, -0.3266, -0.0249, -0.0003, 0.1035, -0.0916, 0.1449, -0.1644, 0.1403, -0.1167, 0.0611, 0.0411, -0.0707, 0.0029, -0.0496, 0.0168, -0.7128, -0.0906, 0.1049, -0.0882, -0.0613, 0.0491, 0.1263, 0.0096, 0.0423, -0.0286, 0.1267, -0.0772, -0.0205, -0.0492, 0.0136, 0.0094, -0.143, 0.0167, -0.0316, -0.0583, -0.0147, 0.1385, -0.0844, -0.0134, 0.1329, 0.0116, -0.2098, 0.2224, 0.002, 0.1558, 0.0542, -0.174, 0.0897, -0.032, 0.05, 0.006, -0.2922, -0.1066, 0.0215, 0.0971, -0.0657, 0.0037, 0.0508, -0.174, -0.0422, -0.0416, 0.0016, -0.0965, -0.2728, -0.1393, 0.0569, -0.0341, -0.0352, -0.0207, 0.2142, 0.079, -0.209, -0.0819, -0.0115, -0.1229, 0.0603, -0.13, -0.0065, 0.0507, 0.0453, -0.0568, 0.0429, -0.2566, 0.0585, -0.0201, -0.1377, 0.0948, -0.4483, 0.2669, -0.1096, -0.0509, -0.2165, 0.0468, -0.1828, 0.1138, 0.0407, 0.042, -0.021, -0.2902, 0.0045, 0.0677, 0.121, -0.0588, 0.0427, 0.033, 0.0429, 0.3968, -0.0114, -0.0931, 0.1555, -0.0371, -0.0992, -0.0378, -0.0278, -0.1709, -0.1218, -0.0116, 0.073, 0.0756, -0.1181, -0.0068, -0.0803, 0.0444, 0.0408, 0.0389, -0.0052, 0.0638, -0.3224, 0.1537, 0.1595, 0.004, 0.0665, 0.0536, -0.0066, -0.0646, 0.0127, 0.0308, 0.1717, -0.0062, 0.3631, -0.3776, 0.0954, -0.0606, 0.1313, -0.0308, -0.0911, 0.079, -0.0056, 0.2828, 0.0027, -0.1449, 0.0889, -0.0392, 0.0279, 0.0361, -0.1109, 0.0228, -0.0363, 0.049, -0.0457, -0.1489, 0.3391, 0.0055, 0.0712, 0.0943, 0.0467, 0.0785, -0.0447, -0.0143, 0.0106, -0.1578, -0.2198, 0.0843, 0.074, -0.0401, -0.0525, 0.027, 0.0177, -0.0929, -0.0504, -0.0542, -0.0809, 0.052, 0.1789, 0.1612, 0.0008, 0.0301, 0.0396, -0.346, -0.0021, 0.0136, 0.049, -0.0123, -0.0853, 0.0537, 0.3109, -0.0686, 0.151, 0.0611, 0.0794, -0.1792, -0.2695, -0.0054, -0.0379, -0.0062, 0.0115, 0.006, 0.0348, 0.0524, -0.0755, 0.1379, 0.107, 0.4634, -0.0354, -0.0732, -0.0586, 0.0211, 0.238, -0.0239, 0.1504, 0.0316, -0.0489, 0.1382, 0.0628, 0.0233, -0.1273, -0.0893, -0.4087, -0.0572, 0.1639, -0.0343, -0.1047, 0.215, -0.0951, -0.0839, -0.0705, -0.0843, 0.0309, 0.0536, -0.0857, -0.0801, 0.0284, 0.0525, -0.013, -0.0412, 0.0942, -0.114, 0.0839, 0.0898, 0.1567, -0.024, 0.065, 0.0236, -0.0525, -0.0036, -0.003, -0.0604, 0.0575, 0.1172, -0.0517, 0.1603, 0.0341, 0.033]\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.40s/it]\u001b[A\n","03/28/2021 18:12:10 - INFO - bert_utils -     flaw_f1 = 0.9019607843137256\n","03/28/2021 18:12:10 - INFO - bert_utils -     flaw_precision = 0.92\n","03/28/2021 18:12:10 - INFO - bert_utils -     flaw_recall = 0.8846153846153846\n","03/28/2021 18:12:10 - INFO - bert_utils -     loss = 0.038466230034828186\n","Epoch:  64%|███████████████████████             | 16/25 [01:19<00:45,  5.01s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.42s/it]\u001b[A\n","03/28/2021 18:12:15 - INFO - bert_utils -     flaw_f1 = 0.9032258064516129\n","03/28/2021 18:12:15 - INFO - bert_utils -     flaw_precision = 1.0\n","03/28/2021 18:12:15 - INFO - bert_utils -     flaw_recall = 0.8235294117647058\n","03/28/2021 18:12:15 - INFO - bert_utils -     loss = 0.030073976144194603\n","Epoch:  68%|████████████████████████▍           | 17/25 [01:24<00:39,  4.99s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0977, -0.0046, 0.1678, -0.2366, 0.096, -0.0685, -0.1005, 0.0104, -0.2248, -0.1104, -0.0225, 0.1047, 0.1715, -0.0981, -0.1278, -0.172, -0.1464, 0.0413, 0.2217, -0.1233, 0.0083, -0.0001, -0.0404, -0.1211, -0.0675, -0.0415, 0.1668, -0.0525, -0.0221, 0.033, -0.0224, -0.0258, 0.1263, 0.0212, -0.0878, -0.0212, 0.0781, -0.0119, 0.0874, 0.0193, -0.024, 0.1151, 0.0286, -0.0167, 0.0453, -0.1218, 0.0032, -0.0825, -0.1115, 0.1014, -0.0371, 0.1974, -0.7815, -0.0672, 0.0294, 0.0052, 0.0035, -0.0847, 0.0061, -0.0752, -0.0684, 0.0673, -0.1874, 0.0757, -0.4387, -0.0174, 0.0809, -0.02, 0.0018, 0.1324, -0.0337, -0.0411, 0.17, 0.3153, 0.0194, -0.0272, 0.1141, 0.0941, 0.1972, 0.2384, -0.0078, 0.0131, 0.0745, -0.2424, 0.0265, 0.0405, -0.1425, 0.0354, -0.2446, -0.0562, 0.1364, -0.0204, -0.046, 0.1489, 0.0747, 0.0372, 0.0702, -0.0465, -0.1113, -0.2096, -0.1664, -0.0771, 0.0402, 0.0347, -0.3003, -0.0309, 0.151, -0.1861, 0.1091, -0.2461, -0.0207, 0.1095, 0.021, -0.0239, -0.1748, -0.0801, -0.0092, 0.1564, -0.0733, -0.3962, 0.0037, -0.1287, 0.022, 0.1114, -0.1632, 0.1876, 0.0471, 0.0613, 0.0402, 0.0276, 0.1795, 0.2471, -0.0839, 0.0321, 0.0411, -0.0149, 0.0026, 0.2144, 0.0196, 0.0138, 0.0221, 0.0262, 0.0405, 0.2699, 0.1447, -0.1308, 0.1037, 0.159, 0.0208, -0.0643, -0.015, 0.0768, 0.0106, 0.0179, 0.062, 0.2155, 0.0385, -0.0043, -0.1243, -0.0494, -0.1242, -0.0394, -0.0041, 0.0435, 0.4762, -0.0185, 0.1576, 0.0315, -0.0019, -0.0857, 0.1446, 0.0885, 0.0451, -0.0665, 0.0509, 0.0814, 0.1838, -0.1182, -0.0709, 0.1544, 0.0081, -0.0903, -0.0498, -0.1137, -0.0396, 0.2853, 0.132, -0.1006, 0.3388, -0.077, 0.1302, 0.1694, -0.0511, 0.0214, 0.015, 0.0737, 0.0304, -0.0922, 0.215, -0.1299, 0.0955, 0.0302, -0.1777, -0.0824, 0.0342, 0.0227, 0.0413, -0.0219, -0.2044, 0.0451, -0.0646, -0.2535, 0.0122, -0.1319, 0.0349, 0.0311, -0.1455, 0.0431, -0.1364, -0.0079, 0.0205, -0.1821, 0.0237, -0.028, 0.1851, -0.1572, 0.0122, 0.0584, 0.0441, -0.0077, -0.1109, 0.039, 0.2915, -0.0956, 0.0431, -0.0056, 0.0395, 0.0331, -0.2264, -0.1199, -0.1122, 0.0995, 0.0369, -0.2666, -0.0484, -0.0905, 0.0507, -0.0015, 0.0612, 0.3071, -0.0275, 0.1221, -0.0302, -0.0878, 0.0682, -0.0117, 0.1408, 0.0152, 0.1823, 0.0063, 0.0173, 0.1291, -0.1599, -0.0053, 0.232, -0.0023, -0.045, -0.0407, -0.0718, 0.0484, -0.0575, 0.0106, 0.105, -0.0859, 0.1308, -0.0453, 0.0331, -0.0852, 0.0224, -0.0585, 0.0289, 0.0816, 0.0636, -0.073, 0.0029, -0.0036, -0.026, 0.1314, -0.1188, -0.0969, 0.0498, 0.1172, -0.0345, -0.0861, 0.0217, 0.0288, -0.0867, 0.2249, 0.0551, 0.1144]\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0437, -0.0144, -0.1032, -0.0202, -0.0252, 0.019, 0.0131, -0.0011, -0.0168, -0.0128, -0.0008, 0.0121, -0.0426, 0.0192, 0.0158, -0.1123, 0.0189, 0.0492, 0.1644, -0.0394, -0.0248, 0.0215, -0.0129, -0.0496, 0.005, 0.0421, -0.0329, -0.0741, -0.1048, -0.0552, 0.0227, -0.0345, -0.0368, -0.0959, -0.0059, 0.0261, -0.0136, 0.0411, -0.0187, 0.0081, -0.0292, -0.0747, -0.0101, -0.0148, 0.0238, 0.0097, -0.0126, 0.0149, -0.0238, -0.0384, 0.0375, 0.071, -0.5428, -0.0469, 0.0233, 0.0216, 0.0095, 0.0793, -0.043, 0.0157, 0.0183, -0.0651, -0.0323, -0.0266, 0.0534, -0.0686, 0.0119, -0.0291, -0.0892, -0.0047, 0.0317, 0.0145, 0.024, -0.0603, -0.0286, 0.0417, -0.0266, -0.0207, -0.0179, 0.0923, -0.0155, -0.0167, 0.0018, -0.167, -0.0138, -0.0397, 0.004, 0.069, 0.2466, 0.0105, -0.029, -0.0633, 0.0889, -0.0542, -0.0125, 0.0102, -0.0743, -0.0065, -0.0179, 0.0513, -0.0914, -0.0053, -0.0592, 0.0338, -0.1552, 0.002, -0.0752, 0.0243, -0.0747, -0.0947, -0.071, -0.1083, -0.0362, 0.0888, -0.007, -0.0735, 0.0336, -0.0083, 0.0342, -0.3091, -0.0721, -0.0342, -0.0242, -0.2222, -0.0489, 0.137, -0.0865, 0.0516, 0.03, -0.0035, 0.0154, -0.0025, -0.0195, -0.0189, -0.0473, -0.1336, -0.001, -0.0033, -0.0832, 0.0505, -0.0475, -0.0468, 0.0717, 0.1783, 0.0927, 0.0197, 0.0592, -0.0596, 0.0006, 0.0368, 0.0973, 0.0478, -0.021, -0.0317, -0.0101, 0.0674, 0.0452, 0.0379, -0.0198, -0.0358, -0.0723, -0.0105, -0.0479, 0.0109, -0.1331, -0.0287, 0.0535, -0.0281, -0.0316, -0.0065, -0.0265, 0.0235, 0.0284, 0.0521, 0.0836, -0.1519, 0.1407, -0.2958, 0.0723, -0.0243, 0.0768, -0.0225, 0.0749, 0.0447, 0.0244, 0.1271, -0.0649, 0.0196, 0.4245, 0.0026, 0.0269, 0.0098, -0.0427, 0.0266, 0.0082, -0.0294, -0.0156, -0.0197, 0.2449, -0.0039, 0.0266, -0.2229, -0.0209, -0.0469, 0.0384, 0.0065, 0.0036, 0.0006, -0.0314, 0.0044, 0.0778, 0.0198, -0.0378, -0.0136, 0.0212, -0.0012, 0.0102, 0.0594, 0.0661, -0.0734, 0.0559, 0.0097, 0.0514, 0.019, 0.025, -0.0928, 0.045, 0.005, -0.0685, -0.114, 0.1314, 0.0066, 0.2853, -0.0352, 0.0347, -0.365, -0.0628, 0.1728, -0.2572, 0.0756, -0.0777, 0.027, 0.0623, -0.0096, 0.0195, -0.0214, 0.0187, -0.0461, -0.0247, 0.3452, 0.0195, -0.0091, -0.0981, 0.0356, -0.0193, 0.0092, -0.0804, -0.0073, 0.0464, 0.0069, 0.0712, -0.0265, 0.0014, -0.0015, -0.3931, -0.0186, -0.0188, -0.009, -0.0198, -0.031, -0.051, -0.0472, 0.0292, 0.0231, -0.035, -0.005, 0.0204, 0.0888, -0.0003, 0.0259, 0.036, -0.2131, 0.0651, -0.0641, -0.0229, 0.0442, -0.0742, 0.0325, -0.0619, 0.0497, 0.0603, 0.0174, -0.0593, 0.0226, -0.0546, 0.013, 0.0049, 0.0448, -0.0326, -0.013]\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.27s/it]\u001b[A\n","03/28/2021 18:12:20 - INFO - bert_utils -     flaw_f1 = 0.7741935483870968\n","03/28/2021 18:12:20 - INFO - bert_utils -     flaw_precision = 1.0\n","03/28/2021 18:12:20 - INFO - bert_utils -     flaw_recall = 0.631578947368421\n","03/28/2021 18:12:20 - INFO - bert_utils -     loss = 0.031606525182724\n","Epoch:  72%|█████████████████████████▉          | 18/25 [01:29<00:34,  4.97s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.1138, -0.0086, -0.0358, -0.1292, -0.1042, 0.2159, -0.0948, 0.0822, -0.0946, -0.171, -0.0546, 0.0883, 0.0276, -0.0162, -0.0555, -0.0449, 0.0677, -0.0055, 0.032, 0.0333, -0.0292, -0.0298, -0.0027, -0.0719, -0.0803, -0.0633, 0.08, -0.1627, -0.0032, 0.0804, -0.0792, -0.0398, 0.0383, -0.0989, 0.0301, 0.0452, 0.0522, 0.017, 0.0502, -0.1751, -0.157, 0.0337, -0.0665, -0.0323, -0.2169, 0.0254, -0.0678, -0.0346, 0.172, 0.0173, -0.1511, 0.2079, -0.6075, -0.0328, 0.0448, 0.0231, 0.055, -0.0562, -0.1088, 0.055, -0.0864, 0.0499, 0.0773, -0.0079, -0.1727, 0.1625, 0.0592, -0.0056, 0.0117, -0.0138, 0.0838, 0.0398, 0.1314, 0.0249, 0.0877, -0.0444, -0.0031, 0.087, 0.1316, 0.1192, 0.012, -0.0509, -0.071, -0.1927, 0.1316, 0.0606, -0.0168, 0.0333, -0.3717, -0.0845, 0.113, -0.107, -0.0638, -0.0904, -0.0427, -0.0332, 0.0154, 0.0617, -0.0326, -0.0663, -0.2623, 0.0032, 0.1143, -0.0267, -0.0092, 0.0015, 0.1084, 0.0445, -0.1566, -0.2638, 0.0556, -0.0351, -0.1247, -0.1002, -0.0026, 0.0088, 0.0066, -0.0078, 0.0688, -0.3622, -0.0004, 0.007, 0.0154, 0.0362, -0.0629, 0.2735, -0.06, -0.1482, -0.2061, -0.0985, -0.0046, -0.0336, -0.0839, -0.1252, 0.0349, 0.2803, -0.0787, -0.0596, 0.1422, -0.0371, -0.001, 0.0921, 0.0639, 0.3127, -0.0255, -0.092, 0.0804, 0.1018, 0.0166, -0.0152, -0.1705, -0.1767, 0.0526, -0.0765, 0.0071, 0.0952, 0.0343, 0.0264, -0.0458, 0.0504, -0.0682, 0.0182, -0.1167, -0.0675, -0.5676, -0.0136, 0.1074, 0.0511, -0.0001, -0.0653, 0.4411, 0.0548, 0.0549, -0.1922, 0.1494, -0.026, 0.2688, -0.1489, -0.0553, -0.0184, 0.168, -0.0901, -0.0618, 0.0372, -0.0696, -0.0856, 0.1078, -0.0344, 0.3902, 0.1063, 0.055, 0.0355, 0.0267, 0.0182, -0.1027, -0.025, 0.2072, -0.0574, 0.2542, 0.0828, 0.0413, 0.1961, 0.0883, -0.0486, -0.0859, 0.1809, -0.0025, -0.0874, -0.2206, 0.0862, 0.0158, 0.0037, 0.0219, 0.0988, -0.0611, -0.0771, -0.1614, -0.025, 0.0336, 0.0398, -0.0367, -0.0249, 0.0613, 0.0209, 0.0581, -0.1388, -0.016, 0.1251, -0.0173, 0.127, 0.0165, -0.0759, 0.3781, -0.0017, 0.0432, -0.1666, -0.0013, -0.0575, -0.2927, 0.1561, 0.0846, -0.0398, 0.0959, 0.0397, -0.07, -0.0758, 0.0061, 0.037, -0.0062, 0.361, -0.0637, -0.076, -0.0469, -0.0494, 0.2322, -0.0612, 0.1924, -0.0631, 0.0397, -0.1119, -0.0904, -0.006, -0.0383, -0.0325, -0.0527, -0.0844, 0.1913, 0.0233, -0.1868, 0.0358, -0.0443, -0.0688, -0.0387, -0.1202, -0.0492, 0.031, -0.0585, 0.0265, -0.0176, -0.0295, 0.1128, 0.0698, 0.07, 0.0197, 0.0228, 0.0289, -0.0864, -0.0787, -0.1648, 0.0724, -0.0009, -0.0348, 0.0142, 0.0709, 0.0269, 0.0954, -0.0761, 0.18, 0.0421, -0.0483]\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.27s/it]\u001b[A\n","03/28/2021 18:12:25 - INFO - bert_utils -     flaw_f1 = 0.7586206896551725\n","03/28/2021 18:12:25 - INFO - bert_utils -     flaw_precision = 1.0\n","03/28/2021 18:12:25 - INFO - bert_utils -     flaw_recall = 0.6111111111111112\n","03/28/2021 18:12:25 - INFO - bert_utils -     loss = 0.03294838219881058\n","Epoch:  76%|███████████████████████████▎        | 19/25 [01:34<00:29,  4.96s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.1208, 0.0144, -0.0927, -0.0181, 0.1125, 0.0495, -0.0467, -0.0193, 0.0746, -0.0119, 0.0817, 0.0189, 0.0596, 0.0681, -0.0196, 0.1208, -0.0401, -0.0571, -0.1717, 0.1402, -0.0256, 0.0317, 0.0454, 0.1437, -0.0175, 0.0, 0.0317, 0.201, 0.0216, -0.0175, 0.0565, -0.0301, 0.0244, -0.045, 0.0697, -0.031, 0.0226, -0.1532, -0.0043, -0.0578, 0.0305, -0.0136, 0.0062, -0.0937, -0.0747, 0.0217, -0.0568, 0.0469, 0.0378, -0.0502, -0.1851, 0.1019, -0.5416, -0.0081, 0.0269, 0.0144, 0.0698, -0.1973, -0.1727, 0.0096, 0.0363, 0.0037, -0.0497, 0.0526, -0.0885, -0.0309, 0.0668, -0.0395, 0.0433, -0.0078, -0.0366, 0.0286, -0.0301, 0.0023, 0.0284, -0.0965, -0.0228, -0.0075, -0.0968, 0.2231, 0.0464, -0.0177, -0.0262, -0.2496, -0.0343, 0.0082, -0.087, -0.0224, -0.5577, 0.0062, 0.0702, 0.0396, -0.0915, 0.0162, -0.0607, 0.0235, 0.0355, -0.1029, -0.0998, -0.0685, -0.271, 0.0459, 0.0225, 0.0368, 0.0759, -0.0153, -0.3556, 0.1072, 0.1017, -0.048, 0.0321, 0.0134, 0.0368, 0.0471, -0.2595, 0.0088, 0.0406, 0.0368, -0.0217, -0.2414, -0.0309, -0.0005, -0.0251, 0.0478, 0.1212, 0.2134, 0.0031, 0.2574, 0.0242, 0.0058, 0.0395, 0.027, -0.1224, -0.0122, 0.0541, -0.256, -0.0568, 0.0002, 0.0708, -0.0554, -0.0341, -0.0603, -0.0489, 0.4024, -0.0091, -0.0236, 0.1828, -0.0233, 0.0515, -0.108, -0.0503, -0.0573, 0.1002, -0.0205, 0.0517, 0.0068, -0.068, 0.0079, 0.0352, 0.0006, 0.0082, 0.0527, -0.0963, -0.0826, 0.1342, 0.0436, 0.1095, 0.0198, -0.0052, 0.0599, -0.1023, 0.0427, 0.08, -0.0834, 0.1454, 0.1132, 0.2139, -0.6224, -0.0544, -0.0541, 0.0465, 0.036, 0.0616, 0.0823, 0.0118, -0.3318, 0.0023, -0.0795, 0.6474, 0.0441, -0.0659, -0.0212, -0.0356, 0.0759, 0.0593, 0.0551, 0.0249, 0.0295, 0.279, -0.0214, -0.0544, -0.0026, 0.0026, -0.0114, 0.0507, 0.023, -0.0792, -0.0548, -0.0457, 0.0767, -0.1153, 0.0243, 0.034, 0.0527, -0.0762, 0.0999, -0.045, -0.0452, 0.0266, -0.0179, -0.0063, -0.0617, 0.0071, 0.0549, 0.1069, -0.0226, -0.0059, -0.0535, -0.0097, -0.0183, 0.2572, -0.0157, 0.1969, 0.0353, -0.1263, -0.4035, 0.0456, -0.1514, -0.2378, 0.124, 0.0007, 0.0017, 0.0054, 0.0166, -0.0424, 0.033, 0.0231, -0.0127, 0.0388, 0.3186, 0.0278, -0.0014, -0.0062, 0.0322, 0.3341, 0.003, -0.1596, 0.0029, -0.0605, -0.0301, -0.1263, -0.0143, -0.0255, 0.0705, -0.8316, -0.0347, 0.0973, 0.0364, -0.019, -0.018, 0.0257, 0.0578, -0.0185, 0.0114, -0.0141, 0.0957, 0.1123, -0.0257, 0.0211, -0.0602, 0.1877, -0.0612, 0.0284, -0.0978, -0.0529, -0.0266, -0.0446, -0.0117, -0.1348, -0.0104, 0.0987, -0.0837, 0.1619, 0.05, -0.0111, 0.0056, -0.1176, 0.2829, 0.0629, 0.0723]\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0839, 0.0382, -0.1108, 0.0418, -0.0191, 0.1581, -0.0182, 0.0574, -0.0864, 0.0427, 0.1022, -0.0711, 0.0505, 0.0488, -0.0666, -0.1014, 0.0676, 0.0977, -0.1354, 0.0819, -0.0001, 0.1366, -0.071, 0.04, -0.0244, 0.0863, 0.0129, -0.2264, 0.0132, -0.1845, -0.1005, 0.0722, 0.0393, -0.0855, 0.0413, -0.1045, 0.065, -0.0166, 0.1502, -0.0352, 0.0771, -0.0824, -0.1802, 0.0184, -0.1091, 0.0243, -0.0091, -0.1028, -0.0099, 0.0345, 0.0325, 0.3405, -0.6737, -0.0297, 0.0188, -0.0256, -0.1056, 0.0104, 0.0458, -0.0169, 0.0757, -0.0534, -0.1105, -0.0027, 0.1807, -0.1049, 0.0421, 0.0484, -0.0371, 0.0172, 0.0086, -0.1292, -0.0454, -0.0359, -0.0262, 0.0779, 0.0578, -0.0272, -0.0398, 0.057, -0.0123, 0.0973, -0.0971, -0.1997, 0.0385, -0.0454, -0.0505, -0.0817, 0.2724, 0.0842, 0.0562, 0.0101, -0.0057, -0.1193, -0.0796, 0.0814, -0.0457, -0.084, 0.1044, 0.0162, -0.2209, -0.137, 0.0778, -0.1772, -0.0529, -0.0546, 0.103, 0.008, 0.0315, 0.094, 0.0053, -0.0557, 0.0331, -0.1311, -0.0538, -0.0128, -0.1017, -0.0731, -0.102, -0.2247, 0.0686, -0.0467, -0.1102, 0.1786, -0.2263, 0.2119, 0.1063, 0.0893, 0.1147, -0.0235, 0.0229, -0.0084, -0.0008, -0.0131, -0.0478, -0.2914, 0.0768, -0.0446, 0.0981, -0.0468, -0.053, -0.1576, -0.0075, 0.3016, -0.1322, -0.1272, 0.0803, 0.0594, 0.0183, 0.0009, -0.057, 0.0079, -0.0017, 0.0222, -0.042, -0.0511, 0.0492, -0.1309, -0.0179, -0.1224, -0.1487, 0.0536, 0.0283, 0.0269, 0.1121, 0.108, 0.0651, -0.0794, -0.002, 0.1156, 0.0159, -0.0186, 0.0271, -0.1147, -0.0095, -0.056, 0.3269, -0.0255, -0.0238, -0.0669, -0.0228, -0.1094, 0.0342, 0.0283, -0.0168, 0.0338, -0.0089, 0.1084, 0.019, -0.1894, -0.1229, -0.0557, -0.0551, 0.0829, -0.0882, 0.0817, 0.0927, 0.0584, 0.1822, -0.0861, 0.0825, 0.0111, -0.0728, -0.0015, 0.0952, 0.1117, 0.1838, -0.0249, 0.0914, 0.0199, 0.0693, 0.1073, -0.1251, -0.1747, -0.0744, -0.1413, -0.0534, -0.0247, -0.0113, -0.1281, -0.0008, 0.184, -0.0254, 0.0364, 0.1662, -0.0345, -0.0623, -0.0581, 0.1085, -0.3147, 0.1537, 0.068, 0.332, -0.1044, 0.1263, -0.2395, -0.0788, -0.1552, -0.2362, 0.15, -0.07, -0.0776, -0.0232, 0.0419, 0.0368, 0.0582, 0.0503, -0.042, 0.1468, 0.4063, -0.0531, 0.067, -0.0308, 0.1202, -0.1133, 0.0057, -0.1476, 0.0743, -0.0664, -0.1061, 0.0102, 0.0451, -0.0879, 0.0008, -0.0658, 0.0743, -0.288, -0.0033, -0.1804, 0.0048, -0.0975, 0.0069, 0.1446, -0.066, -0.0514, 0.0231, 0.0344, -0.033, -0.0296, -0.0736, -0.1621, -0.1, 0.1299, -0.0601, 0.0154, -0.0778, 0.0257, 0.0209, -0.0259, 0.0003, -0.0466, -0.0208, 0.0784, -0.0062, -0.0533, -0.1182, -0.1469, 0.0714, -0.0559, -0.1672]\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0206, 0.0231, -0.0574, 0.0388, -0.1158, -0.0109, 0.0054, 0.0025, -0.063, -0.0564, 0.0296, -0.0682, 0.0355, -0.0558, 0.0059, -0.0383, 0.0515, 0.0712, -0.0886, 0.1198, -0.0334, 0.0043, 0.0388, 0.0457, -0.0428, 0.0495, -0.0072, 0.0304, -0.0174, 0.0421, 0.0032, -0.039, -0.0322, -0.0113, 0.0603, 0.0074, 0.0102, 0.0481, -0.0294, 0.0271, 0.005, -0.0374, 0.0533, -0.1492, 0.0262, 0.0029, -0.0423, 0.0086, -0.0379, -0.0297, -0.0117, 0.0891, -0.5834, -0.0196, 0.038, 0.0106, -0.023, -0.028, 0.0464, 0.009, -0.0389, -0.033, -0.1084, 0.0001, 0.0224, 0.1006, 0.0005, 0.0152, -0.0146, -0.0575, -0.0436, -0.0181, -0.0158, -0.0427, 0.0685, -0.0116, 0.029, 0.0035, -0.1194, -0.0918, 0.0197, 0.1237, -0.0245, -0.3306, -0.0037, -0.0307, -0.025, 0.0059, 0.1157, -0.0114, -0.0106, -0.0137, 0.0109, 0.0819, 0.052, 0.0564, 0.0283, -0.0403, 0.0134, -0.0875, -0.0785, -0.0019, 0.0188, 0.0821, -0.095, -0.0039, 0.0945, -0.0765, 0.1313, -0.0581, 0.0405, -0.0103, 0.0653, 0.0289, 0.0409, -0.0256, -0.0071, 0.0012, -0.0567, -0.2729, 0.0702, -0.0213, 0.0021, 0.1257, 0.0059, 0.0772, 0.0403, -0.0276, -0.101, -0.0033, -0.0749, -0.0207, -0.0789, 0.0385, -0.0658, -0.1691, -0.0115, -0.0056, 0.1989, 0.1064, -0.0167, 0.0653, 0.0628, 0.3884, -0.0158, -0.0042, 0.0209, -0.0511, -0.0213, -0.0188, -0.009, 0.0099, -0.023, -0.0427, 0.0403, 0.0124, -0.0669, -0.0269, -0.0124, 0.0256, -0.041, -0.0619, 0.0162, -0.1176, -0.2902, 0.0084, 0.1346, -0.0781, 0.0389, -0.0321, -0.0553, -0.0213, -0.0142, 0.0333, 0.0863, -0.1304, 0.1478, -0.5894, 0.0465, 0.0001, 0.0436, -0.0236, 0.0123, 0.0241, 0.02, -0.2658, -0.0006, -0.0608, 0.3386, -0.0067, 0.0549, 0.0206, -0.0162, 0.0078, -0.0411, 0.0081, 0.0067, -0.0451, 0.1383, 0.0427, -0.0006, -0.0881, 0.0111, 0.0129, -0.0609, -0.0975, -0.0001, 0.1469, 0.0451, 0.0174, -0.0055, -0.0166, -0.0333, 0.0994, 0.055, -0.0201, -0.333, -0.0084, 0.155, -0.0631, 0.0423, 0.0196, -0.0049, 0.0698, -0.0575, -0.1492, 0.026, 0.0842, -0.0507, 0.1491, 0.039, 0.0039, 0.2166, -0.0059, 0.013, -0.0529, -0.0177, 0.1542, -0.1744, 0.0889, -0.074, -0.0335, 0.0167, -0.0347, 0.0433, -0.064, 0.0335, -0.0394, 0.0444, 0.3293, -0.0081, -0.0297, 0.0637, 0.0484, -0.3762, 0.0191, -0.0618, 0.0386, 0.0234, 0.0003, 0.0235, 0.033, 0.0034, -0.0156, -0.1348, 0.0016, 0.0838, -0.0008, -0.0768, -0.0085, -0.0156, 0.0373, -0.0186, 0.0309, 0.0197, -0.0242, 0.042, 0.0556, 0.0171, 0.0195, -0.1021, 0.0454, -0.031, -0.0079, 0.0583, -0.0137, -0.0559, -0.0094, 0.0233, 0.04, 0.0042, -0.0218, -0.0945, -0.0154, -0.029, -0.0141, 0.008, 0.1221, 0.0558, -0.1314]\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0541, -0.1693, -0.2085, 0.0336, 0.0164, 0.0185, 0.0572, 0.1305, 0.1083, 0.1635, -0.0928, -0.1733, -0.2562, 0.0145, 0.1272, 0.0667, -0.0638, -0.0656, -0.1194, 0.2281, -0.2363, 0.0972, -0.0492, -0.0691, -0.0449, 0.0405, 0.0308, 0.1126, -0.0709, 0.0084, 0.0317, 0.0308, 0.0168, 0.1272, -0.0534, -0.0581, 0.1446, -0.0116, -0.043, -0.022, -0.0283, 0.1325, 0.0688, 0.0994, -0.0853, -0.0225, 0.2092, -0.0275, 0.2151, 0.172, -0.1051, 0.0822, -0.5221, 0.1069, -0.0378, 0.0731, -0.0305, -0.1683, -0.0088, -0.0429, 0.0131, -0.1097, -0.0022, 0.0002, -0.0043, -0.096, -0.1099, -0.0747, -0.0131, 0.2035, -0.1784, -0.0369, 0.1545, -0.0019, 0.135, -0.0754, -0.1441, -0.031, -0.0962, -0.0743, 0.0001, -0.0974, 0.0039, -0.1964, 0.1196, 0.0615, -0.0953, 0.0185, 0.2042, -0.0597, -0.1038, -0.1591, 0.0298, -0.0939, -0.0512, -0.1588, -0.1518, 0.102, -0.0392, 0.2233, -0.2181, 0.1497, -0.0828, -0.0198, -0.1274, 0.0733, -0.1035, -0.0701, -0.0769, -0.0999, 0.0275, 0.0737, 0.1603, -0.1997, 0.1078, 0.0825, -0.2304, -0.0463, 0.1015, -0.4098, -0.0087, 0.0552, 0.1142, 0.1692, 0.0143, 0.2033, -0.0752, 0.022, 0.0012, -0.0148, -0.0752, 0.0268, -0.0599, -0.0152, -0.0523, 0.0308, -0.0994, 0.047, -0.0372, 0.0267, 0.0289, -0.1426, -0.1549, 0.1534, -0.0847, 0.0472, 0.0623, -0.036, 0.111, -0.0268, -0.1277, 0.0663, -0.0618, 0.1483, -0.1098, 0.0847, -0.2946, 0.0628, 0.1324, -0.0748, -0.084, 0.0243, -0.0539, 0.0629, 0.0344, -0.0506, 0.0951, -0.084, 0.0219, 0.0758, -0.1297, 0.0955, -0.1427, 0.1777, 0.1345, -0.077, 0.2827, -0.0153, 0.1393, 0.1167, 0.1465, -0.0822, -0.0677, -0.1025, 0.2061, 0.1091, -0.0583, 0.0067, -0.2186, 0.088, 0.0278, 0.0258, -0.1377, 0.0832, 0.1353, 0.2988, -0.035, 0.0496, 0.1578, -0.0074, 0.0041, 0.0927, -0.0824, -0.1153, -0.0026, 0.0871, 0.0515, -0.1433, -0.1, 0.1324, 0.0407, -0.0855, -0.153, 0.0834, -0.0173, 0.0197, -0.1147, -0.0146, -0.1977, -0.0408, 0.0307, -0.09, -0.0107, -0.0532, 0.0155, 0.0233, 0.1314, -0.0075, -0.1629, -0.1442, -0.1025, 0.0849, 0.3512, -0.1586, 0.0304, -0.0677, 0.1338, 0.092, -0.2702, 0.2873, -0.0466, 0.086, 0.1871, 0.0568, -0.0387, -0.1473, 0.0813, -0.0127, -0.0076, 0.3465, -0.0328, 0.0207, 0.05, -0.0542, 0.1882, -0.0193, -0.043, 0.1066, 0.0563, 0.0456, 0.009, 0.1324, 0.2351, 0.1135, -0.7036, 0.0765, -0.0756, 0.0219, 0.0337, 0.0331, -0.1379, -0.0574, -0.1276, 0.0043, -0.1431, 0.082, -0.0956, -0.0155, -0.0161, -0.0401, 0.0976, -0.0138, -0.0022, -0.1148, 0.043, -0.1129, 0.0314, 0.0043, 0.0565, 0.0013, -0.2174, -0.0845, -0.1171, 0.004, -0.1723, -0.0468, 0.0056, 0.059, -0.1025, -0.1085]\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.33s/it]\u001b[A\n","03/28/2021 18:12:30 - INFO - bert_utils -     flaw_f1 = 0.8444444444444443\n","03/28/2021 18:12:30 - INFO - bert_utils -     flaw_precision = 1.0\n","03/28/2021 18:12:30 - INFO - bert_utils -     flaw_recall = 0.7307692307692307\n","03/28/2021 18:12:30 - INFO - bert_utils -     loss = 0.0416310578584671\n","Epoch:  80%|████████████████████████████▊       | 20/25 [01:39<00:24,  4.95s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.44s/it]\u001b[A\n","03/28/2021 18:12:35 - INFO - bert_utils -     flaw_f1 = 0.972972972972973\n","03/28/2021 18:12:35 - INFO - bert_utils -     flaw_precision = 1.0\n","03/28/2021 18:12:35 - INFO - bert_utils -     flaw_recall = 0.9473684210526315\n","03/28/2021 18:12:35 - INFO - bert_utils -     loss = 0.013721185736358166\n","Epoch:  84%|██████████████████████████████▏     | 21/25 [01:44<00:19,  4.97s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  1\n","tok_id :  1\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0806, -0.0063, 0.0875, 0.0152, -0.068, -0.0948, 0.0018, 0.0061, -0.0728, -0.0068, -0.0113, 0.0812, 0.0365, -0.0536, -0.0777, 0.0078, 0.0177, 0.0004, 0.0115, -0.0501, 0.0093, 0.0002, 0.0282, 0.0255, -0.114, -0.1124, 0.0629, 0.1254, -0.0207, 0.0129, 0.0243, -0.0201, 0.0887, -0.0181, -0.007, 0.0058, -0.0462, -0.0616, 0.083, -0.0028, -0.0745, 0.0229, 0.0034, -0.0238, -0.0119, -0.0123, -0.0423, -0.0241, 0.0103, -0.019, 0.0154, 0.0061, -0.6269, 0.0171, -0.0113, -0.0304, 0.007, -0.1632, -0.3254, 0.0079, 0.044, -0.0183, 0.0466, -0.0078, -0.0634, -0.105, -0.0265, -0.0244, -0.0143, 0.0176, 0.0104, -0.0365, 0.0041, 0.0303, 0.0076, 0.023, -0.0337, -0.0088, 0.0106, 0.1418, -0.0157, -0.0251, 0.0121, -0.1602, 0.0105, 0.0241, -0.0038, 0.0239, -0.1055, -0.0054, -0.0658, -0.04, 0.0187, 0.099, 0.0372, -0.0159, -0.0113, 0.0156, 0.0953, -0.0334, -0.0971, -0.0237, 0.0123, 0.0271, -0.2827, -0.0086, 0.0576, 0.1455, 0.0356, -0.0489, 0.0021, 0.1179, -0.0209, 0.0518, 0.0245, -0.1199, 0.0084, 0.018, 0.0371, -0.3544, -0.0397, -0.0426, 0.0044, 0.0544, 0.0687, 0.0631, -0.0555, 0.0517, 0.0679, 0.0582, 0.045, -0.0167, 0.0014, 0.0793, 0.021, -0.3372, -0.0326, -0.0321, 0.055, -0.0962, -0.0316, 0.0132, 0.0309, 0.3101, -0.0624, 0.0419, 0.038, -0.113, -0.0231, 0.0135, 0.0323, 0.0158, 0.0779, -0.0368, 0.0279, 0.0072, -0.0174, 0.0178, 0.0026, -0.0547, 0.0492, 0.0599, 0.0472, -0.0817, -0.2665, 0.0267, -0.0128, 0.0237, -0.0342, -0.0213, -0.233, 0.0408, 0.0358, -0.0759, 0.2026, -0.0613, 0.0854, -0.3599, 0.0217, -0.0333, 0.0411, 0.0109, 0.0316, 0.0149, 0.0561, -0.0965, -0.0061, -0.1178, -0.0211, 0.0052, -0.0192, -0.0625, 0.0009, -0.0206, -0.0285, -0.0156, -0.0162, -0.0764, 0.1422, -0.0007, 0.0148, -0.0405, -0.0455, -0.0352, 0.0295, -0.0271, 0.0716, -0.0552, -0.0059, -0.0261, 0.0505, -0.0137, -0.0375, 0.0311, 0.0322, -0.0155, -0.1239, -0.0108, -0.0179, 0.0028, 0.0179, 0.0319, 0.0337, -0.0174, 0.0526, -0.0824, -0.0206, 0.0564, -0.0256, -0.2518, -0.0051, -0.0165, 0.2127, -0.0211, 0.0346, 0.2194, 0.0061, 0.0724, -0.086, -0.0035, -0.0597, 0.0046, 0.034, -0.0349, -0.0014, 0.038, -0.0007, -0.0122, -0.0254, 0.2632, -0.0164, 0.0878, -0.0171, 0.0378, 0.0345, 0.0363, 0.0725, 0.0042, -0.0122, 0.0374, -0.0208, -0.0353, -0.0012, 0.0018, -0.1729, 0.0315, -0.0483, 0.0162, 0.0853, -0.0103, -0.0061, -0.02, -0.0212, 0.0173, 0.0503, 0.0044, -0.087, 0.0067, -0.0138, 0.0075, 0.1034, -0.3706, -0.0438, 0.0262, 0.0773, -0.0511, -0.0179, 0.0647, 0.1465, 0.0517, 0.069, -0.0139, -0.025, -0.0271, -0.0258, -0.0259, -0.0265, 0.2192, 0.0188, -0.0608]\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0736, 0.0135, -0.1083, 0.1089, -0.1087, 0.0232, 0.1087, -0.0318, 0.0208, -0.011, -0.2369, -0.2483, -0.0633, -0.0387, 0.0319, 0.0891, -0.0856, -0.2158, -0.0927, 0.1301, -0.2474, -0.0753, -0.0966, 0.1835, 0.0419, 0.0195, -0.0634, 0.0602, -0.1821, 0.0648, 0.0741, -0.0607, 0.0716, -0.0231, 0.1012, 0.1186, -0.0177, 0.0323, -0.1141, -0.0585, -0.2028, 0.027, 0.0391, -0.0195, -0.0174, -0.1147, 0.0162, -0.0021, 0.0755, 0.0354, -0.077, -0.1115, -0.5843, -0.0472, 0.0425, 0.0145, -0.0537, 0.1364, -0.0622, -0.1121, 0.1621, -0.024, 0.0191, 0.1304, 0.1066, -0.0098, -0.1245, -0.0265, -0.033, 0.1369, -0.0176, 0.0889, 0.0956, -0.108, -0.0504, -0.0584, -0.0176, -0.034, 0.1054, -0.1764, 0.0025, -0.1407, 0.0732, -0.2656, 0.113, 0.0903, 0.0129, -0.1572, 0.2595, -0.1947, -0.0683, -0.1396, 0.1252, -0.1358, 0.092, 0.0609, 0.0963, -0.0151, -0.1351, 0.0229, -0.232, 0.019, 0.1418, -0.1494, -0.1934, 0.067, -0.1161, 0.1013, 0.0036, 0.0567, -0.0106, 0.0348, 0.0811, 0.0098, 0.1119, 0.0083, 0.0455, 0.1506, 0.0196, -0.4059, 0.0304, -0.1542, -0.0105, 0.2264, 0.0355, 0.1976, -0.0419, -0.029, -0.0962, 0.1047, 0.0111, -0.1088, -0.0032, 0.0993, 0.0412, 0.0858, -0.0176, -0.004, 0.1006, -0.0032, -0.0923, -0.0907, -0.2245, 0.2384, 0.0644, -0.0213, -0.0848, -0.022, 0.0247, -0.0943, 0.0088, 0.0523, 0.0838, -0.2077, -0.2299, -0.0537, -0.1127, 0.1194, 0.0332, 0.1894, 0.1053, -0.0035, -0.0954, 0.0303, 0.0863, 0.1312, 0.135, 0.0811, 0.1031, 0.0065, -0.1305, -0.1352, -0.0962, 0.0314, -0.0394, -0.1125, 0.2902, -0.1142, -0.0299, 0.0938, -0.1445, 0.0181, -0.0421, -0.0773, 0.0154, 0.0592, -0.0572, -0.004, -0.2083, 0.1658, 0.0263, 0.0904, 0.0257, 0.0339, 0.1064, -0.0344, -0.043, -0.077, 0.2063, 0.0351, -0.062, -0.0945, -0.1323, -0.0476, 0.0072, 0.1318, 0.0076, 0.0175, -0.0133, 0.0833, 0.0836, -0.0544, -0.0933, 0.0908, -0.0781, -0.1136, -0.1556, 0.0541, -0.029, 0.0579, 0.0779, -0.0817, 0.0241, -0.1043, 0.344, -0.1298, 0.0768, -0.3173, 0.0591, -0.1113, -0.1582, -0.0202, 0.3818, -0.1023, -0.0764, -0.0619, -0.1192, 0.0391, -0.3044, 0.0943, -0.1769, -0.1227, 0.1711, -0.0874, 0.0644, 0.0461, -0.0147, -0.009, -0.0068, 0.3903, -0.0584, 0.1163, -0.0564, 0.0528, 0.1174, -0.0036, -0.0747, 0.2458, -0.0048, 0.0845, -0.1193, 0.2023, 0.0851, -0.0029, -0.6706, 0.0114, -0.0332, -0.1013, 0.0241, 0.1329, 0.074, -0.0061, -0.0353, -0.1578, 0.0207, -0.106, -0.0048, 0.0931, -0.0634, -0.0418, 0.072, 0.1157, 0.1244, 0.0948, -0.1263, -0.1257, -0.0741, 0.085, 0.0408, 0.0385, 0.02, 0.054, 0.1094, -0.0355, 0.1336, -0.0817, -0.0935, 0.071, 0.0632, -0.0373]\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0495, 0.0411, 0.0041, 0.0309, -0.0044, -0.1151, 0.006, 0.017, 0.0045, -0.0288, 0.017, 0.0007, 0.0533, 0.0094, -0.0609, -0.0267, 0.0497, 0.0474, 0.0054, 0.0511, -0.0715, 0.0876, 0.055, -0.001, -0.0746, 0.0008, 0.0258, -0.1404, 0.0022, 0.0469, 0.0114, 0.0083, -0.0127, -0.0453, 0.0011, -0.008, -0.013, -0.1271, 0.002, 0.0389, -0.0395, -0.0295, -0.0308, 0.0348, -0.1388, -0.0647, 0.0302, 0.0184, 0.0499, 0.0168, -0.0176, 0.089, -0.5547, 0.0144, 0.03, 0.0127, 0.0345, 0.1792, 0.0629, -0.0242, -0.0491, -0.0397, -0.0014, -0.0571, 0.0906, -0.0009, 0.0266, -0.0018, 0.0308, -0.0057, 0.0569, 0.0273, -0.0338, 0.1003, 0.0299, 0.0115, 0.0717, 0.0319, -0.0726, 0.1526, -0.0026, -0.1321, -0.0287, -0.2439, 0.0073, -0.0062, 0.0101, -0.0128, -0.0106, 0.0202, -0.0165, -0.0867, 0.0493, -0.0916, 0.0507, 0.1032, 0.0108, 0.0881, 0.0655, -0.0127, -0.0895, -0.0348, 0.0439, 0.0069, -0.3768, -0.0176, 0.1296, 0.0027, 0.2343, -0.0009, 0.0337, 0.0613, -0.0369, 0.0564, -0.0901, -0.0046, 0.036, 0.0341, -0.0171, -0.1717, -0.0041, -0.0553, -0.0661, 0.0957, -0.0804, 0.0868, -0.0181, -0.0602, -0.1523, -0.0104, -0.0034, -0.0547, 0.0094, -0.0223, -0.0184, -0.3151, -0.0358, 0.0354, 0.0393, 0.0526, 0.001, -0.0163, 0.0497, 0.2518, -0.0173, -0.0036, 0.018, -0.1081, 0.0368, -0.0141, -0.0436, 0.0291, -0.0366, -0.0523, 0.0464, 0.0018, -0.0183, 0.0766, 0.0156, 0.0276, 0.0522, -0.0221, 0.0408, -0.0703, -0.2291, -0.003, 0.0343, -0.0961, -0.0092, 0.0222, 0.0166, -0.0344, 0.0463, 0.0186, 0.0283, -0.0522, 0.0369, -0.4955, 0.0276, -0.0247, 0.0257, 0.0632, -0.0232, -0.0063, -0.0076, -0.3897, -0.0108, -0.0612, 0.1962, -0.006, -0.0353, -0.0994, -0.0124, -0.0031, 0.0427, 0.0134, -0.0043, -0.0102, 0.21, 0.0163, -0.0155, 0.1707, -0.0339, -0.0125, 0.02, 0.0148, -0.0342, -0.0254, 0.0001, 0.0412, -0.0258, -0.0169, 0.0113, 0.0031, 0.0075, -0.0059, 0.1255, 0.0225, 0.0005, 0.0462, 0.0096, -0.0664, 0.0138, 0.0511, 0.0372, 0.0073, -0.0187, 0.0186, -0.0021, -0.012, 0.0007, -0.0026, 0.1725, 0.079, 0.0265, -0.0066, -0.0765, 0.2336, -0.1445, 0.0072, -0.026, -0.0147, 0.0521, 0.0011, -0.0244, 0.0583, -0.0207, 0.032, 0.0294, 0.483, -0.0444, -0.087, -0.0754, 0.0276, -0.0606, -0.0227, -0.0057, -0.0298, 0.054, -0.0607, -0.0746, 0.0666, -0.024, -0.0399, -0.2321, 0.0054, 0.0233, 0.046, 0.1874, -0.053, -0.0285, -0.0521, -0.0146, 0.0264, -0.0093, 0.025, -0.0552, 0.0152, 0.0242, -0.0577, 0.006, 0.0511, 0.023, -0.0345, 0.0134, -0.0042, -0.1267, -0.1572, -0.0783, 0.0706, 0.0004, -0.0142, -0.0976, -0.0489, -0.0625, -0.0327, 0.007, 0.2371, -0.0298, -0.0284]\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0568, -0.1339, 0.1573, 0.0057, 0.194, -0.2087, 0.0217, 0.0051, -0.0037, 0.0886, -0.025, -0.1547, -0.0509, 0.0492, 0.1833, -0.0597, 0.0121, 0.0852, 0.256, 0.0516, 0.0196, 0.1505, 0.0116, -0.0267, -0.037, -0.1625, 0.0446, -0.256, 0.0354, -0.0035, 0.1073, 0.0501, -0.0761, -0.0933, 0.0849, 0.0552, 0.0571, -0.3266, -0.0249, -0.0003, 0.1035, -0.0916, 0.1449, -0.1644, 0.1403, -0.1167, 0.0611, 0.0411, -0.0707, 0.0029, -0.0496, 0.0168, -0.7128, -0.0906, 0.1049, -0.0882, -0.0613, 0.0491, 0.1263, 0.0096, 0.0423, -0.0286, 0.1267, -0.0772, -0.0205, -0.0492, 0.0136, 0.0094, -0.143, 0.0167, -0.0316, -0.0583, -0.0147, 0.1385, -0.0844, -0.0134, 0.1329, 0.0116, -0.2098, 0.2224, 0.002, 0.1558, 0.0542, -0.174, 0.0897, -0.032, 0.05, 0.006, -0.2922, -0.1066, 0.0215, 0.0971, -0.0657, 0.0037, 0.0508, -0.174, -0.0422, -0.0416, 0.0016, -0.0965, -0.2728, -0.1393, 0.0569, -0.0341, -0.0352, -0.0207, 0.2142, 0.079, -0.209, -0.0819, -0.0115, -0.1229, 0.0603, -0.13, -0.0065, 0.0507, 0.0453, -0.0568, 0.0429, -0.2566, 0.0585, -0.0201, -0.1377, 0.0948, -0.4483, 0.2669, -0.1096, -0.0509, -0.2165, 0.0468, -0.1828, 0.1138, 0.0407, 0.042, -0.021, -0.2902, 0.0045, 0.0677, 0.121, -0.0588, 0.0427, 0.033, 0.0429, 0.3968, -0.0114, -0.0931, 0.1555, -0.0371, -0.0992, -0.0378, -0.0278, -0.1709, -0.1218, -0.0116, 0.073, 0.0756, -0.1181, -0.0068, -0.0803, 0.0444, 0.0408, 0.0389, -0.0052, 0.0638, -0.3224, 0.1537, 0.1595, 0.004, 0.0665, 0.0536, -0.0066, -0.0646, 0.0127, 0.0308, 0.1717, -0.0062, 0.3631, -0.3776, 0.0954, -0.0606, 0.1313, -0.0308, -0.0911, 0.079, -0.0056, 0.2828, 0.0027, -0.1449, 0.0889, -0.0392, 0.0279, 0.0361, -0.1109, 0.0228, -0.0363, 0.049, -0.0457, -0.1489, 0.3391, 0.0055, 0.0712, 0.0943, 0.0467, 0.0785, -0.0447, -0.0143, 0.0106, -0.1578, -0.2198, 0.0843, 0.074, -0.0401, -0.0525, 0.027, 0.0177, -0.0929, -0.0504, -0.0542, -0.0809, 0.052, 0.1789, 0.1612, 0.0008, 0.0301, 0.0396, -0.346, -0.0021, 0.0136, 0.049, -0.0123, -0.0853, 0.0537, 0.3109, -0.0686, 0.151, 0.0611, 0.0794, -0.1792, -0.2695, -0.0054, -0.0379, -0.0062, 0.0115, 0.006, 0.0348, 0.0524, -0.0755, 0.1379, 0.107, 0.4634, -0.0354, -0.0732, -0.0586, 0.0211, 0.238, -0.0239, 0.1504, 0.0316, -0.0489, 0.1382, 0.0628, 0.0233, -0.1273, -0.0893, -0.4087, -0.0572, 0.1639, -0.0343, -0.1047, 0.215, -0.0951, -0.0839, -0.0705, -0.0843, 0.0309, 0.0536, -0.0857, -0.0801, 0.0284, 0.0525, -0.013, -0.0412, 0.0942, -0.114, 0.0839, 0.0898, 0.1567, -0.024, 0.065, 0.0236, -0.0525, -0.0036, -0.003, -0.0604, 0.0575, 0.1172, -0.0517, 0.1603, 0.0341, 0.033]\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.44s/it]\u001b[A\n","03/28/2021 18:12:40 - INFO - bert_utils -     flaw_f1 = 0.8421052631578947\n","03/28/2021 18:12:40 - INFO - bert_utils -     flaw_precision = 0.9411764705882353\n","03/28/2021 18:12:40 - INFO - bert_utils -     flaw_recall = 0.7619047619047619\n","03/28/2021 18:12:40 - INFO - bert_utils -     loss = 0.0362454392015934\n","Epoch:  88%|███████████████████████████████▋    | 22/25 [01:49<00:14,  4.98s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0063, -0.0253, -0.0338, 0.0178, -0.0966, 0.0946, 0.0328, -0.0227, 0.0628, -0.0189, -0.0063, 0.028, 0.0215, -0.0924, -0.0071, -0.0246, 0.0363, -0.023, -0.0744, -0.0124, 0.0055, 0.0781, 0.0156, -0.1322, -0.049, 0.0756, 0.0529, 0.006, -0.0194, 0.0552, -0.0176, 0.0049, -0.1204, -0.0272, 0.0189, 0.0482, -0.0392, -0.105, 0.0358, 0.0432, -0.0006, -0.0452, 0.0313, 0.052, 0.03, 0.0132, -0.0345, -0.0012, -0.0105, 0.0289, -0.0064, 0.0337, -0.6136, 0.0142, 0.0334, 0.0008, -0.0354, -0.0456, -0.118, -0.0009, 0.0319, 0.0059, -0.0208, -0.0383, -0.0216, -0.0103, 0.0015, 0.0315, -0.0042, 0.0418, 0.0161, -0.0241, -0.0046, -0.1596, 0.0238, 0.0092, -0.0144, 0.0292, 0.0148, 0.058, 0.015, -0.02, 0.0254, -0.1357, 0.0079, -0.0345, 0.0288, 0.0071, 0.3238, 0.0305, 0.0306, 0.0288, 0.027, 0.0484, 0.0239, -0.0059, 0.0288, 0.0114, 0.0242, -0.0037, -0.0958, -0.027, 0.0234, 0.0275, -0.1558, -0.0034, 0.0985, -0.0422, 0.0911, 0.0191, -0.0207, 0.1338, -0.0164, 0.0123, 0.0567, -0.0961, 0.0141, 0.0091, 0.008, -0.118, -0.0499, -0.0656, 0.0867, 0.0707, -0.0513, 0.1399, -0.0287, -0.0949, -0.0987, 0.046, 0.0002, 0.0301, 0.0377, -0.0029, 0.0053, -0.0905, 0.0063, 0.021, -0.0647, -0.0603, 0.0118, -0.0129, 0.0166, 0.2834, -0.0506, -0.0332, 0.0189, -0.0091, 0.0069, 0.031, 0.1842, -0.011, 0.0169, -0.0496, -0.0089, 0.0083, 0.0131, 0.0724, 0.0011, 0.0095, 0.0181, 0.0133, 0.0425, -0.0187, -0.2456, -0.0242, 0.0195, -0.0001, -0.0793, -0.042, -0.026, -0.0363, -0.0072, 0.013, 0.1629, -0.0843, 0.1183, -0.2981, 0.0171, 0.008, 0.0109, 0.0102, 0.0291, -0.0157, -0.0113, -0.0126, -0.0179, 0.0381, 0.3813, 0.0404, 0.0459, -0.0778, -0.0129, -0.0218, -0.0194, 0.0301, -0.0795, -0.0375, 0.234, 0.0163, 0.0039, -0.0551, -0.0511, -0.003, 0.0312, -0.0064, 0.1368, -0.0918, -0.051, 0.0165, -0.034, 0.0267, -0.0197, 0.0153, 0.0328, 0.022, -0.0538, -0.002, 0.0477, 0.0268, -0.0481, -0.0166, 0.0202, -0.0226, -0.0569, 0.1067, 0.0382, 0.0267, -0.0204, 0.0269, 0.0877, -0.0313, 0.1969, -0.0524, -0.0059, -0.1442, -0.0296, 0.0781, -0.1937, -0.0414, -0.0156, -0.012, 0.0127, -0.0086, 0.0296, -0.0002, 0.0592, -0.0103, -0.0069, 0.3157, 0.0263, 0.0313, -0.1475, 0.021, -0.0327, 0.0169, 0.0181, -0.0009, 0.0492, -0.0543, -0.0555, 0.0065, -0.0051, 0.0113, -0.1789, 0.024, -0.001, 0.0108, -0.0587, 0.0118, -0.0764, -0.0438, 0.0592, 0.0092, -0.0187, -0.016, -0.0391, 0.0236, 0.016, 0.0025, -0.0836, -0.1061, 0.0585, 0.0568, 0.0207, 0.0205, 0.0175, 0.0661, 0.0756, 0.0728, -0.0402, 0.0075, 0.0015, -0.014, -0.0487, 0.0517, 0.0088, 0.1155, 0.0073, 0.0168]\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.018, 0.0137, 0.0563, 0.0203, -0.0224, -0.0579, 0.0017, -0.0083, -0.0074, 0.0621, 0.0457, -0.0904, 0.0844, 0.013, -0.1144, 0.0202, -0.0783, -0.0346, -0.0351, 0.0287, -0.0507, -0.0797, 0.0259, 0.0543, 0.0421, -0.1147, -0.0449, -0.0618, -0.0264, 0.0732, 0.0393, -0.0798, -0.0383, -0.0212, 0.0242, -0.0619, 0.0028, -0.0545, -0.1246, 0.0882, -0.0696, 0.0284, -0.1216, 0.0243, 0.0088, 0.0228, -0.0419, 0.0312, 0.0095, -0.0116, -0.0563, -0.0754, -0.6494, -0.0508, 0.0136, -0.0307, -0.0149, -0.052, 0.0104, 0.0411, 0.0321, -0.0849, 0.0666, -0.0499, -0.0406, -0.0305, 0.0453, 0.0657, -0.0713, 0.0026, -0.0071, -0.0073, -0.012, -0.0021, 0.0152, 0.0728, -0.0177, 0.0067, 0.0472, 0.2579, 0.0086, 0.0526, -0.0531, -0.2221, -0.005, -0.0434, 0.0486, 0.0129, -0.0179, 0.0281, -0.0121, 0.0198, 0.0175, -0.026, -0.0251, -0.0165, 0.0305, 0.0568, 0.0422, -0.0578, -0.1283, -0.0809, -0.0824, 0.0095, 0.0213, 0.0042, 0.1039, 0.2486, 0.0316, 0.0603, 0.0895, 0.0652, 0.0716, 0.0304, -0.2216, -0.0121, 0.0162, -0.0474, -0.0523, -0.3365, -0.0059, -0.0389, -0.0493, 0.054, 0.0473, 0.1572, -0.0403, 0.2288, -0.1701, 0.0341, 0.1491, -0.042, 0.0274, -0.0687, 0.0232, -0.2326, -0.0087, -0.0353, 0.0201, -0.0392, -0.0263, -0.0005, 0.0106, 0.3222, 0.1188, -0.0025, 0.1381, -0.0301, -0.1146, 0.0012, -0.0458, 0.0793, 0.0299, -0.0276, 0.0263, -0.0017, -0.0616, -0.0363, 0.0757, -0.0887, -0.0505, 0.0739, 0.0222, 0.0485, -0.1574, 0.0128, 0.115, -0.0137, 0.0246, 0.0834, 0.062, 0.0275, -0.0376, -0.0543, 0.242, 0.0166, 0.1765, -0.1171, 0.0097, 0.0407, 0.0245, 0.0482, 0.0543, 0.0164, 0.0306, 0.0662, -0.0758, -0.0842, -0.1406, 0.0708, -0.0021, -0.032, 0.0435, 0.0469, -0.0045, 0.0869, 0.0144, 0.0109, 0.1798, -0.0279, 0.0251, -0.0165, -0.0496, -0.0203, 0.0504, 0.0375, 0.055, -0.0736, -0.1372, 0.0084, 0.0426, -0.001, -0.0611, -0.003, 0.0637, -0.0185, 0.0292, 0.022, -0.0052, 0.0605, 0.1659, -0.0197, -0.073, 0.0347, 0.0514, -0.0462, -0.033, 0.1258, -0.0531, -0.1589, -0.0904, -0.0152, 0.3261, -0.1132, -0.0136, 0.0702, -0.02, 0.0705, -0.1598, 0.0617, -0.0651, 0.0309, 0.0323, -0.0752, -0.0333, 0.0489, -0.0132, 0.0433, 0.0011, 0.3065, 0.0577, 0.1041, 0.0583, -0.0108, -0.1463, -0.0195, -0.0661, 0.0006, -0.0628, 0.0766, -0.1766, -0.1066, -0.0112, -0.0637, -0.3468, -0.0268, -0.0201, -0.0342, 0.05, 0.047, -0.0543, 0.0142, -0.102, -0.0296, -0.0426, 0.0159, 0.0272, -0.065, -0.0514, -0.0284, 0.0657, -0.0163, 0.0494, -0.0867, 0.022, 0.0482, 0.0015, 0.0358, 0.0483, 0.0545, -0.0117, -0.0571, 0.014, -0.047, 0.0189, -0.0918, -0.0813, 0.2471, 0.0845, -0.0592]\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.39s/it]\u001b[A\n","03/28/2021 18:12:45 - INFO - bert_utils -     flaw_f1 = 0.896551724137931\n","03/28/2021 18:12:45 - INFO - bert_utils -     flaw_precision = 0.9285714285714286\n","03/28/2021 18:12:45 - INFO - bert_utils -     flaw_recall = 0.8666666666666667\n","03/28/2021 18:12:45 - INFO - bert_utils -     loss = 0.02710302732884884\n","Epoch:  92%|█████████████████████████████████   | 23/25 [01:54<00:09,  4.96s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0736, 0.0135, -0.1083, 0.1089, -0.1087, 0.0232, 0.1087, -0.0318, 0.0208, -0.011, -0.2369, -0.2483, -0.0633, -0.0387, 0.0319, 0.0891, -0.0856, -0.2158, -0.0927, 0.1301, -0.2474, -0.0753, -0.0966, 0.1835, 0.0419, 0.0195, -0.0634, 0.0602, -0.1821, 0.0648, 0.0741, -0.0607, 0.0716, -0.0231, 0.1012, 0.1186, -0.0177, 0.0323, -0.1141, -0.0585, -0.2028, 0.027, 0.0391, -0.0195, -0.0174, -0.1147, 0.0162, -0.0021, 0.0755, 0.0354, -0.077, -0.1115, -0.5843, -0.0472, 0.0425, 0.0145, -0.0537, 0.1364, -0.0622, -0.1121, 0.1621, -0.024, 0.0191, 0.1304, 0.1066, -0.0098, -0.1245, -0.0265, -0.033, 0.1369, -0.0176, 0.0889, 0.0956, -0.108, -0.0504, -0.0584, -0.0176, -0.034, 0.1054, -0.1764, 0.0025, -0.1407, 0.0732, -0.2656, 0.113, 0.0903, 0.0129, -0.1572, 0.2595, -0.1947, -0.0683, -0.1396, 0.1252, -0.1358, 0.092, 0.0609, 0.0963, -0.0151, -0.1351, 0.0229, -0.232, 0.019, 0.1418, -0.1494, -0.1934, 0.067, -0.1161, 0.1013, 0.0036, 0.0567, -0.0106, 0.0348, 0.0811, 0.0098, 0.1119, 0.0083, 0.0455, 0.1506, 0.0196, -0.4059, 0.0304, -0.1542, -0.0105, 0.2264, 0.0355, 0.1976, -0.0419, -0.029, -0.0962, 0.1047, 0.0111, -0.1088, -0.0032, 0.0993, 0.0412, 0.0858, -0.0176, -0.004, 0.1006, -0.0032, -0.0923, -0.0907, -0.2245, 0.2384, 0.0644, -0.0213, -0.0848, -0.022, 0.0247, -0.0943, 0.0088, 0.0523, 0.0838, -0.2077, -0.2299, -0.0537, -0.1127, 0.1194, 0.0332, 0.1894, 0.1053, -0.0035, -0.0954, 0.0303, 0.0863, 0.1312, 0.135, 0.0811, 0.1031, 0.0065, -0.1305, -0.1352, -0.0962, 0.0314, -0.0394, -0.1125, 0.2902, -0.1142, -0.0299, 0.0938, -0.1445, 0.0181, -0.0421, -0.0773, 0.0154, 0.0592, -0.0572, -0.004, -0.2083, 0.1658, 0.0263, 0.0904, 0.0257, 0.0339, 0.1064, -0.0344, -0.043, -0.077, 0.2063, 0.0351, -0.062, -0.0945, -0.1323, -0.0476, 0.0072, 0.1318, 0.0076, 0.0175, -0.0133, 0.0833, 0.0836, -0.0544, -0.0933, 0.0908, -0.0781, -0.1136, -0.1556, 0.0541, -0.029, 0.0579, 0.0779, -0.0817, 0.0241, -0.1043, 0.344, -0.1298, 0.0768, -0.3173, 0.0591, -0.1113, -0.1582, -0.0202, 0.3818, -0.1023, -0.0764, -0.0619, -0.1192, 0.0391, -0.3044, 0.0943, -0.1769, -0.1227, 0.1711, -0.0874, 0.0644, 0.0461, -0.0147, -0.009, -0.0068, 0.3903, -0.0584, 0.1163, -0.0564, 0.0528, 0.1174, -0.0036, -0.0747, 0.2458, -0.0048, 0.0845, -0.1193, 0.2023, 0.0851, -0.0029, -0.6706, 0.0114, -0.0332, -0.1013, 0.0241, 0.1329, 0.074, -0.0061, -0.0353, -0.1578, 0.0207, -0.106, -0.0048, 0.0931, -0.0634, -0.0418, 0.072, 0.1157, 0.1244, 0.0948, -0.1263, -0.1257, -0.0741, 0.085, 0.0408, 0.0385, 0.02, 0.054, 0.1094, -0.0355, 0.1336, -0.0817, -0.0935, 0.071, 0.0632, -0.0373]\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.33s/it]\u001b[A\n","03/28/2021 18:12:50 - INFO - bert_utils -     flaw_f1 = 0.9714285714285714\n","03/28/2021 18:12:50 - INFO - bert_utils -     flaw_precision = 1.0\n","03/28/2021 18:12:50 - INFO - bert_utils -     flaw_recall = 0.9444444444444444\n","03/28/2021 18:12:50 - INFO - bert_utils -     loss = 0.011465275660157204\n","Epoch:  96%|██████████████████████████████████▌ | 24/25 [01:59<00:04,  4.94s/it]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[Aexamples:  [[37  1 18 38 39 34 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n","  58  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1 29 30 31 32 16 33 34 35 36  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [21 18 22 23 24 18 25 26 27 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [13 14 15 16 17 18 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]\n"," [ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","   0  0  0  0  0  0  0  0]]\n","example:  37\n","tok_id :  37\n","tok_id :  1\n","tok_id :  18\n","tok_id :  38\n","tok_id :  39\n","tok_id :  34\n","tok_id :  40\n","tok_id :  41\n","tok_id :  42\n","tok_id :  43\n","tok_id :  44\n","tok_id :  45\n","tok_id :  46\n","tok_id :  47\n","tok_id :  48\n","tok_id :  49\n","tok_id :  50\n","tok_id :  51\n","tok_id :  52\n","tok_id :  53\n","tok_id :  54\n","tok_id :  55\n","tok_id :  56\n","tok_id :  57\n","tok_id :  58\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [0.0806, -0.0063, 0.0875, 0.0152, -0.068, -0.0948, 0.0018, 0.0061, -0.0728, -0.0068, -0.0113, 0.0812, 0.0365, -0.0536, -0.0777, 0.0078, 0.0177, 0.0004, 0.0115, -0.0501, 0.0093, 0.0002, 0.0282, 0.0255, -0.114, -0.1124, 0.0629, 0.1254, -0.0207, 0.0129, 0.0243, -0.0201, 0.0887, -0.0181, -0.007, 0.0058, -0.0462, -0.0616, 0.083, -0.0028, -0.0745, 0.0229, 0.0034, -0.0238, -0.0119, -0.0123, -0.0423, -0.0241, 0.0103, -0.019, 0.0154, 0.0061, -0.6269, 0.0171, -0.0113, -0.0304, 0.007, -0.1632, -0.3254, 0.0079, 0.044, -0.0183, 0.0466, -0.0078, -0.0634, -0.105, -0.0265, -0.0244, -0.0143, 0.0176, 0.0104, -0.0365, 0.0041, 0.0303, 0.0076, 0.023, -0.0337, -0.0088, 0.0106, 0.1418, -0.0157, -0.0251, 0.0121, -0.1602, 0.0105, 0.0241, -0.0038, 0.0239, -0.1055, -0.0054, -0.0658, -0.04, 0.0187, 0.099, 0.0372, -0.0159, -0.0113, 0.0156, 0.0953, -0.0334, -0.0971, -0.0237, 0.0123, 0.0271, -0.2827, -0.0086, 0.0576, 0.1455, 0.0356, -0.0489, 0.0021, 0.1179, -0.0209, 0.0518, 0.0245, -0.1199, 0.0084, 0.018, 0.0371, -0.3544, -0.0397, -0.0426, 0.0044, 0.0544, 0.0687, 0.0631, -0.0555, 0.0517, 0.0679, 0.0582, 0.045, -0.0167, 0.0014, 0.0793, 0.021, -0.3372, -0.0326, -0.0321, 0.055, -0.0962, -0.0316, 0.0132, 0.0309, 0.3101, -0.0624, 0.0419, 0.038, -0.113, -0.0231, 0.0135, 0.0323, 0.0158, 0.0779, -0.0368, 0.0279, 0.0072, -0.0174, 0.0178, 0.0026, -0.0547, 0.0492, 0.0599, 0.0472, -0.0817, -0.2665, 0.0267, -0.0128, 0.0237, -0.0342, -0.0213, -0.233, 0.0408, 0.0358, -0.0759, 0.2026, -0.0613, 0.0854, -0.3599, 0.0217, -0.0333, 0.0411, 0.0109, 0.0316, 0.0149, 0.0561, -0.0965, -0.0061, -0.1178, -0.0211, 0.0052, -0.0192, -0.0625, 0.0009, -0.0206, -0.0285, -0.0156, -0.0162, -0.0764, 0.1422, -0.0007, 0.0148, -0.0405, -0.0455, -0.0352, 0.0295, -0.0271, 0.0716, -0.0552, -0.0059, -0.0261, 0.0505, -0.0137, -0.0375, 0.0311, 0.0322, -0.0155, -0.1239, -0.0108, -0.0179, 0.0028, 0.0179, 0.0319, 0.0337, -0.0174, 0.0526, -0.0824, -0.0206, 0.0564, -0.0256, -0.2518, -0.0051, -0.0165, 0.2127, -0.0211, 0.0346, 0.2194, 0.0061, 0.0724, -0.086, -0.0035, -0.0597, 0.0046, 0.034, -0.0349, -0.0014, 0.038, -0.0007, -0.0122, -0.0254, 0.2632, -0.0164, 0.0878, -0.0171, 0.0378, 0.0345, 0.0363, 0.0725, 0.0042, -0.0122, 0.0374, -0.0208, -0.0353, -0.0012, 0.0018, -0.1729, 0.0315, -0.0483, 0.0162, 0.0853, -0.0103, -0.0061, -0.02, -0.0212, 0.0173, 0.0503, 0.0044, -0.087, 0.0067, -0.0138, 0.0075, 0.1034, -0.3706, -0.0438, 0.0262, 0.0773, -0.0511, -0.0179, 0.0647, 0.1465, 0.0517, 0.069, -0.0139, -0.025, -0.0271, -0.0258, -0.0259, -0.0265, 0.2192, 0.0188, -0.0608]\n","tok_id :  29\n","tok_id :  30\n","tok_id :  31\n","tok_id :  32\n","tok_id :  16\n","tok_id :  33\n","tok_id :  34\n","type of n;  <class 'int'>\n","Value of n:  20\n","type of emb:  <class 'list'>\n","PRINTING emb:  [-0.0714, -0.0961, -0.0543, -0.0089, -0.2126, 0.0534, -0.0409, -0.0517, 0.0936, 0.0113, -0.0077, 0.0641, 0.028, -0.0538, -0.0051, 0.0561, 0.0192, 0.0961, -0.1569, -0.0303, -0.0262, 0.1071, -0.0304, 0.0608, 0.0011, 0.0113, 0.0132, 0.0873, -0.1031, 0.0007, -0.0051, -0.0083, 0.0536, -0.01, -0.0242, -0.0871, 0.0095, -0.1401, 0.1626, 0.1108, -0.046, -0.0355, 0.0494, -0.0833, -0.1691, -0.0572, -0.0177, 0.0182, -0.0231, 0.0958, -0.104, 0.1079, -0.6455, 0.0117, 0.0832, 0.0286, 0.0462, -0.1509, -0.105, 0.0951, 0.0165, -0.0461, 0.1536, 0.0066, -0.0306, -0.0726, 0.0172, 0.0218, -0.0003, 0.1357, 0.0563, -0.0314, -0.0016, -0.043, -0.0665, 0.023, -0.0472, 0.0139, -0.0075, 0.0932, -0.0308, 0.0108, -0.056, -0.0816, 0.0244, 0.0641, 0.0434, 0.0032, 0.0787, -0.016, 0.0846, -0.0269, -0.0187, -0.0196, 0.0377, 0.0367, 0.1086, -0.0619, 0.0509, -0.0416, -0.1743, -0.0484, 0.0183, -0.0438, -0.0205, -0.0508, 0.2531, 0.1169, 0.2239, 0.0411, 0.0208, -0.0894, 0.0068, -0.0164, 0.116, -0.0687, 0.067, 0.0126, -0.0462, -0.2124, -0.0494, -0.0472, 0.073, 0.0385, 0.0644, 0.1669, -0.0893, -0.0032, 0.018, -0.0342, 0.0007, -0.0776, -0.0142, 0.0953, 0.0547, -0.2087, 0.0013, 0.0145, 0.0371, -0.0862, 0.0353, 0.0633, 0.0045, 0.0181, -0.0292, -0.048, 0.028, -0.0609, -0.0332, -0.0737, -0.1139, -0.0433, 0.0112, -0.0111, 0.0243, 0.0539, -0.0256, -0.0527, 0.0396, 0.0706, 0.0599, 0.014, 0.0007, 0.0058, -0.266, -0.0098, 0.0898, -0.0116, -0.0605, 0.0734, -0.0521, -0.0381, -0.0274, -0.0119, -0.0701, 0.0655, 0.1867, -0.0171, -0.001, -0.0367, 0.1, 0.026, -0.0961, -0.0065, -0.0965, 0.0331, -0.0445, -0.0174, 0.1617, 0.0258, -0.057, -0.0033, -0.064, -0.0004, -0.06, -0.0128, -0.0828, -0.1367, 0.2173, -0.0022, -0.0002, 0.0711, -0.0041, -0.0464, -0.0103, -0.0046, 0.0848, -0.0209, 0.0285, -0.1046, 0.0644, 0.0154, 0.0258, 0.0321, -0.0336, 0.0297, -0.1423, -0.0162, -0.1225, 0.0689, -0.0201, -0.0638, -0.0158, -0.0874, -0.0346, -0.0147, -0.0292, -0.012, -0.0561, -0.2855, 0.0462, 0.0129, 0.3125, -0.0379, -0.0039, 0.1701, 0.058, -0.1349, -0.1757, 0.1266, 0.0278, -0.0082, 0.0778, 0.0061, -0.0048, 0.069, -0.0048, 0.0676, 0.0007, 0.2385, -0.0287, -0.0028, -0.0125, 0.1112, -0.072, -0.0043, -0.0473, 0.0015, 0.0212, 0.0609, -0.0768, -0.0851, -0.0099, 0.0148, 0.0575, -0.0646, -0.0574, 0.0263, -0.057, -0.0036, 0.0167, -0.0115, 0.0138, -0.0927, 0.0076, 0.0136, -0.031, -0.0415, 0.0268, -0.0569, 0.0278, -0.0867, -0.0369, -0.0925, 0.0416, -0.0016, -0.1105, 0.0234, 0.0871, 0.0567, -0.0422, -0.0631, 0.0621, -0.0207, -0.1323, -0.053, 0.0177, 0.0577, 0.0075, -0.0248]\n","tok_id :  35\n","tok_id :  36\n","tok_id :  0\n","example:  21\n","tok_id :  21\n","tok_id :  18\n","tok_id :  22\n","tok_id :  23\n","tok_id :  24\n","tok_id :  18\n","tok_id :  25\n","tok_id :  26\n","tok_id :  27\n","tok_id :  28\n","tok_id :  0\n","example:  13\n","tok_id :  13\n","tok_id :  14\n","tok_id :  15\n","tok_id :  16\n","tok_id :  17\n","tok_id :  18\n","tok_id :  19\n","tok_id :  20\n","tok_id :  0\n","example:  1\n","tok_id :  1\n","tok_id :  2\n","tok_id :  3\n","tok_id :  4\n","tok_id :  5\n","tok_id :  6\n","tok_id :  7\n","tok_id :  8\n","tok_id :  9\n","tok_id :  10\n","tok_id :  11\n","tok_id :  12\n","tok_id :  0\n","\n","Iteration: 100%|██████████████████████████████████| 1/1 [00:04<00:00,  4.26s/it]\u001b[A\n","03/28/2021 18:12:54 - INFO - bert_utils -     flaw_f1 = 0.8070175438596493\n","03/28/2021 18:12:54 - INFO - bert_utils -     flaw_precision = 0.9583333333333334\n","03/28/2021 18:12:54 - INFO - bert_utils -     flaw_recall = 0.696969696969697\n","03/28/2021 18:12:54 - INFO - bert_utils -     loss = 0.06222153455018997\n","Epoch: 100%|████████████████████████████████████| 25/25 [02:04<00:00,  4.97s/it]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NPNAJlpUBU14"},"source":["!python bert_discriminator.py  --task_name sst-2  --do_train  --do_lower_case  --data_dir data/sst-2/  --bert_model bert-base-uncased  --max_seq_length 128  --train_batch_size 8  --learning_rate 2e-5  --num_train_epochs 25  --output_dir ./tmp/disc/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"tags":[],"id":"bO52Jg1Bg1YO","outputId":"f11b3163-5bb6-40cf-9d77-494267ebb7a4"},"source":["# Modified : Run this : \n","#Generator Train : Embedding Estimator train \n","!python bert_generator.py \\\n","--task_name sst-2\\\n","--do_train\\\n","--do_lower_case\\\n","--data_dir data/sst-2/\\\n","--bert_model bert-base-uncased\\\n","--max_seq_length 64\\\n","--train_batch_size 8\\\n","--learning_rate 2e-5\\\n","--num_train_epochs 25\\\n","--output_dir ./tmp/gnrt/\\\n","--no_cuda"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","03/28/2021 17:59:16 - INFO - bert_utils -   device: cpu n_gpu: 2, distributed training: False, 16-bits training: False\n","03/28/2021 17:59:17 - INFO - tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","03/28/2021 17:59:17 - INFO - bert_utils -   loading embeddings ... \n","03/28/2021 17:59:27 - INFO - bert_utils -   loading p index ...\n","03/28/2021 17:59:27 - INFO - bert_utils -   *** Example ***\n","03/28/2021 17:59:27 - INFO - bert_utils -   tokens: that loves its characters and communicates something rather beautiful about human nature\n","03/28/2021 17:59:27 - INFO - bert_utils -   token_ids: 1 2 3 4 5 6 7 8 9 10 11 12\n","03/28/2021 17:59:27 - INFO - bert_utils -   ngram_ids: [101, 101, 103, 7459, 2049, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [101, 2008, 103, 2049, 3494, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [2008, 7459, 103, 3494, 1998, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [7459, 2049, 103, 1998, 10639, 2015, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [2049, 3494, 103, 10639, 2015, 2242, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [3494, 1998, 103, 2242, 2738, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1998, 10639, 2015, 103, 2738, 3376, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [10639, 2015, 2242, 103, 3376, 2055, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [2242, 2738, 103, 2055, 2529, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [2738, 3376, 103, 2529, 3267, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [3376, 2055, 103, 3267, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [2055, 2529, 103, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","03/28/2021 17:59:27 - INFO - bert_utils -   ngram_labels: 1 2 3 4 5 6 7 8 9 10 11 12 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/28/2021 17:59:27 - INFO - bert_utils -   *** Example ***\n","03/28/2021 17:59:27 - INFO - bert_utils -   tokens: remains utterly satisfied to remain the same throughout\n","03/28/2021 17:59:27 - INFO - bert_utils -   token_ids: 13 14 15 16 17 18 19 20\n","03/28/2021 17:59:27 - INFO - bert_utils -   ngram_ids: [101, 101, 103, 12580, 8510, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [101, 3464, 103, 8510, 2000, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [3464, 12580, 103, 2000, 3961, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [12580, 8510, 103, 3961, 1996, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [8510, 2000, 103, 1996, 2168, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [2000, 3961, 103, 2168, 2802, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [3961, 1996, 103, 2802, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1996, 2168, 103, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","03/28/2021 17:59:27 - INFO - bert_utils -   ngram_labels: 13 14 15 16 17 18 19 20 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/28/2021 17:59:27 - INFO - bert_utils -   *** Example ***\n","03/28/2021 17:59:27 - INFO - bert_utils -   tokens: on the worst revenge-of-the-nerds clichés the filmmakers could dredge up\n","03/28/2021 17:59:27 - INFO - bert_utils -   token_ids: 21 18 22 23 24 18 25 26 27 28\n","03/28/2021 17:59:27 - INFO - bert_utils -   ngram_ids: [101, 101, 103, 1996, 5409, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [101, 2006, 103, 5409, 7195, 1011, 1997, 1011, 1996, 1011, 11265, 17811, 0, 0, 0, 0] [2006, 1996, 103, 7195, 1011, 1997, 1011, 1996, 1011, 11265, 17811, 18856, 17322, 2015, 0, 0] [1996, 5409, 103, 18856, 17322, 2015, 1996, 0, 0, 0, 0, 0, 0, 0, 0, 0] [5409, 7195, 1011, 1997, 1011, 1996, 1011, 11265, 17811, 103, 1996, 16587, 0, 0, 0, 0] [7195, 1011, 1997, 1011, 1996, 1011, 11265, 17811, 18856, 17322, 2015, 103, 16587, 2071, 0, 0] [18856, 17322, 2015, 1996, 103, 2071, 2852, 24225, 0, 0, 0, 0, 0, 0, 0, 0] [1996, 16587, 103, 2852, 24225, 2039, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [16587, 2071, 103, 2039, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [2071, 2852, 24225, 103, 102, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","03/28/2021 17:59:27 - INFO - bert_utils -   ngram_labels: 21 18 22 23 24 18 25 26 27 28 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/28/2021 17:59:27 - INFO - bert_utils -   ***** Running training *****\n","03/28/2021 17:59:27 - INFO - bert_utils -     Num examples = 5\n","03/28/2021 17:59:27 - INFO - bert_utils -     Num token vocab = 59\n","03/28/2021 17:59:27 - INFO - bert_utils -     Batch size = 8\n","03/28/2021 17:59:27 - INFO - bert_utils -     Num steps = 0\n","train_features:  <class 'list'>\n","train_features 1st element :  64\n","train_features length:  5\n","Type of ngram embeddings <class 'list'>\n","args max ngram length:  64\n","length of ngram_embeddings list:  5\n","printing it:    64\n","printing it:    64\n","printing it:    63\n","printing it:  [[0.0206, 0.0231, -0.0574, 0.0388, -0.1158, -0.0109, 0.0054, 0.0025, -0.063, -0.0564, 0.0296, -0.0682, 0.0355, -0.0558, 0.0059, -0.0383, 0.0515, 0.0712, -0.0886, 0.1198, -0.0334, 0.0043, 0.0388, 0.0457, -0.0428, 0.0495, -0.0072, 0.0304, -0.0174, 0.0421, 0.0032, -0.039, -0.0322, -0.0113, 0.0603, 0.0074, 0.0102, 0.0481, -0.0294, 0.0271, 0.005, -0.0374, 0.0533, -0.1492, 0.0262, 0.0029, -0.0423, 0.0086, -0.0379, -0.0297, -0.0117, 0.0891, -0.5834, -0.0196, 0.038, 0.0106, -0.023, -0.028, 0.0464, 0.009, -0.0389, -0.033, -0.1084, 0.0001, 0.0224, 0.1006, 0.0005, 0.0152, -0.0146, -0.0575, -0.0436, -0.0181, -0.0158, -0.0427, 0.0685, -0.0116, 0.029, 0.0035, -0.1194, -0.0918, 0.0197, 0.1237, -0.0245, -0.3306, -0.0037, -0.0307, -0.025, 0.0059, 0.1157, -0.0114, -0.0106, -0.0137, 0.0109, 0.0819, 0.052, 0.0564, 0.0283, -0.0403, 0.0134, -0.0875, -0.0785, -0.0019, 0.0188, 0.0821, -0.095, -0.0039, 0.0945, -0.0765, 0.1313, -0.0581, 0.0405, -0.0103, 0.0653, 0.0289, 0.0409, -0.0256, -0.0071, 0.0012, -0.0567, -0.2729, 0.0702, -0.0213, 0.0021, 0.1257, 0.0059, 0.0772, 0.0403, -0.0276, -0.101, -0.0033, -0.0749, -0.0207, -0.0789, 0.0385, -0.0658, -0.1691, -0.0115, -0.0056, 0.1989, 0.1064, -0.0167, 0.0653, 0.0628, 0.3884, -0.0158, -0.0042, 0.0209, -0.0511, -0.0213, -0.0188, -0.009, 0.0099, -0.023, -0.0427, 0.0403, 0.0124, -0.0669, -0.0269, -0.0124, 0.0256, -0.041, -0.0619, 0.0162, -0.1176, -0.2902, 0.0084, 0.1346, -0.0781, 0.0389, -0.0321, -0.0553, -0.0213, -0.0142, 0.0333, 0.0863, -0.1304, 0.1478, -0.5894, 0.0465, 0.0001, 0.0436, -0.0236, 0.0123, 0.0241, 0.02, -0.2658, -0.0006, -0.0608, 0.3386, -0.0067, 0.0549, 0.0206, -0.0162, 0.0078, -0.0411, 0.0081, 0.0067, -0.0451, 0.1383, 0.0427, -0.0006, -0.0881, 0.0111, 0.0129, -0.0609, -0.0975, -0.0001, 0.1469, 0.0451, 0.0174, -0.0055, -0.0166, -0.0333, 0.0994, 0.055, -0.0201, -0.333, -0.0084, 0.155, -0.0631, 0.0423, 0.0196, -0.0049, 0.0698, -0.0575, -0.1492, 0.026, 0.0842, -0.0507, 0.1491, 0.039, 0.0039, 0.2166, -0.0059, 0.013, -0.0529, -0.0177, 0.1542, -0.1744, 0.0889, -0.074, -0.0335, 0.0167, -0.0347, 0.0433, -0.064, 0.0335, -0.0394, 0.0444, 0.3293, -0.0081, -0.0297, 0.0637, 0.0484, -0.3762, 0.0191, -0.0618, 0.0386, 0.0234, 0.0003, 0.0235, 0.033, 0.0034, -0.0156, -0.1348, 0.0016, 0.0838, -0.0008, -0.0768, -0.0085, -0.0156, 0.0373, -0.0186, 0.0309, 0.0197, -0.0242, 0.042, 0.0556, 0.0171, 0.0195, -0.1021, 0.0454, -0.031, -0.0079, 0.0583, -0.0137, -0.0559, -0.0094, 0.0233, 0.04, 0.0042, -0.0218, -0.0945, -0.0154, -0.029, -0.0141, 0.008, 0.1221, 0.0558, -0.1314], [0.0897, 0.016, -0.0571, 0.0405, -0.0696, -0.1237, 0.0301, 0.0248, -0.0303, 0.0174, 0.0063, 0.0184, 0.0217, -0.0257, 0.035, -0.0242, 0.0029, 0.0188, -0.057, 0.0252, -0.021, -0.0008, 0.036, -0.0729, -0.0665, 0.0989, 0.0676, 0.0852, -0.0089, 0.0313, -0.0069, -0.0032, -0.0462, 0.0497, 0.0261, 0.0268, -0.031, -0.1361, -0.0062, 0.0375, -0.032, -0.0106, 0.0534, -0.0187, 0.0638, 0.0094, 0.0047, -0.053, 0.0093, -0.0087, 0.0004, 0.0493, -0.6296, 0.0222, 0.019, 0.0268, -0.0426, 0.0057, -0.1683, 0.0244, -0.0213, -0.0181, 0.0421, -0.0309, -0.0089, 0.0032, 0.0108, -0.0049, 0.0258, 0.0278, -0.0163, 0.02, 0.0164, -0.0954, -0.0032, 0.0043, 0.0104, -0.0088, 0.0007, 0.035, -0.0206, -0.0083, -0.0114, -0.1869, 0.0258, 0.001, 0.0085, 0.0151, 0.2125, 0.0071, 0.0319, -0.0482, 0.0621, 0.0626, 0.0159, -0.0013, 0.0087, 0.0686, -0.0034, 0.0238, -0.0452, -0.0198, 0.0112, 0.0109, -0.1022, -0.0272, 0.2337, -0.0465, 0.1592, -0.0407, -0.1029, -0.0487, -0.0676, 0.0676, -0.0328, 0.0323, 0.0077, 0.019, 0.0017, -0.2974, 0.0011, -0.0356, 0.0693, -0.048, -0.0821, -0.0644, -0.0284, -0.0191, -0.0233, 0.0353, -0.0463, 0.0656, 0.0019, -0.0212, -0.0309, -0.3534, -0.0309, 0.0076, -0.0419, 0.0457, -0.0306, 0.0357, 0.0667, 0.3659, 0.0149, -0.0443, 0.0068, -0.0378, 0.0146, 0.0215, 0.1081, 0.0124, -0.0437, -0.043, 0.0258, 0.0213, -0.0309, -0.0018, -0.0067, 0.0172, 0.0089, -0.0171, 0.0275, -0.0518, -0.184, -0.013, -0.0241, 0.0526, -0.028, 0.0051, 0.0163, -0.0165, 0.0161, 0.1237, 0.0804, -0.0789, 0.0386, -0.3892, 0.0157, -0.0246, 0.0477, -0.0045, -0.0214, 0.0173, -0.0191, -0.1382, -0.0111, 0.0712, 0.1514, 0.0291, 0.0555, -0.0039, 0.0028, -0.0277, -0.0275, -0.0177, -0.0338, -0.0372, 0.2071, 0.046, -0.0294, 0.0435, -0.0169, -0.0121, 0.0253, 0.0198, 0.0918, 0.0193, 0.0668, 0.0288, 0.004, -0.0439, -0.0302, 0.0064, 0.0364, 0.0543, -0.0338, 0.0159, 0.0617, -0.0941, -0.0086, -0.0092, 0.03, -0.0241, -0.035, -0.0621, 0.0175, 0.0374, 0.0034, 0.0344, 0.1286, -0.0267, 0.1861, 0.0489, -0.0032, 0.018, -0.0228, 0.2414, -0.0935, 0.0612, -0.0209, 0.0136, 0.0392, -0.0135, -0.0253, 0.0335, 0.0095, 0.0419, 0.0076, 0.4522, -0.0188, 0.0233, -0.0474, 0.0159, -0.009, 0.0265, 0.0336, 0.0221, 0.0472, 0.0048, 0.0962, 0.0344, -0.0515, -0.0087, -0.098, -0.0288, 0.0377, 0.0202, -0.2979, -0.0387, -0.0198, -0.0161, -0.0045, 0.0087, -0.0387, 0.0421, 0.0383, 0.0258, 0.0069, -0.0298, -0.0198, -0.0152, 0.0033, 0.0075, 0.0358, -0.0155, -0.0111, 0.076, -0.0452, 0.0697, 0.0299, -0.0029, -0.0348, -0.027, 0.0351, 0.0559, 0.0591, 0.1559, -0.0254, -0.0259], [0.0143, -0.0543, -0.1051, 0.0771, -0.0517, 0.159, 0.0023, 0.0041, 0.1165, -0.2022, -0.0472, -0.094, 0.0627, -0.0514, 0.1361, -0.0619, 0.0916, -0.1894, 0.3032, -0.0725, -0.0115, -0.0403, 0.0834, 0.0448, 0.0543, 0.1341, 0.0924, -0.1008, 0.0358, 0.0204, 0.0382, -0.1205, -0.1139, 0.0288, 0.1009, 0.084, -0.0333, -0.1662, 0.0438, -0.0211, 0.119, -0.0011, -0.1672, -0.1107, -0.0335, 0.0294, 0.0254, -0.018, -0.0518, 0.0907, 0.196, 0.0684, -0.7173, -0.1312, 0.0114, -0.0293, 0.0415, -0.0909, -0.0204, 0.019, -0.0496, 0.0192, 0.0837, -0.018, -0.0228, -0.2671, 0.1097, 0.1041, -0.0912, -0.0907, 0.001, -0.0216, -0.0183, -0.1755, 0.0833, 0.0609, 0.1786, -0.1091, -0.1792, 0.0464, -0.033, 0.0056, -0.062, -0.2019, -0.0117, -0.1002, -0.0035, -0.1013, 0.148, -0.0883, 0.0249, 0.0818, -0.1695, -0.1593, -0.0177, 0.0438, 0.018, -0.0386, 0.0306, 0.0984, -0.178, 0.1209, 0.0429, 0.0647, 0.0041, -0.0447, 0.2673, 0.0551, -0.0338, 0.0052, -0.2155, 0.1378, -0.071, -0.1129, -0.082, -0.1429, -0.1168, 0.1869, 0.0499, -0.2497, 0.0585, 0.0677, -0.1465, 0.1205, 0.1833, 0.2309, -0.1143, 0.1156, -0.0714, 0.1972, 0.0479, -0.0762, 0.0756, 0.1547, 0.1854, -0.4435, -0.0086, 0.0655, -0.0631, -0.2148, 0.0738, 0.1081, -0.1484, 0.2601, 0.0103, -0.1344, 0.0201, -0.0311, -0.0352, 0.069, 0.102, -0.1283, -0.0474, 0.1745, 0.0474, 0.1155, -0.0341, 0.2, -0.0765, 0.005, -0.0102, 0.0832, -0.0961, 0.03, 0.0569, 0.1179, 0.0911, -0.1376, 0.0509, -0.1254, 0.2475, -0.1036, -0.151, -0.0602, -0.0197, -0.0109, 0.2656, 0.1874, -0.124, -0.125, 0.0859, 0.0337, -0.145, -0.0752, -0.0396, 0.0002, -0.1337, -0.0621, 0.1229, 0.0378, 0.0574, 0.1162, -0.0134, -0.0242, -0.0272, 0.0871, -0.0428, -0.0971, 0.1347, 0.0422, -0.1023, 0.1704, -0.0811, 0.1585, 0.2222, 0.1999, 0.2117, -0.0486, 0.0009, 0.0811, 0.041, 0.0708, -0.0067, -0.0618, -0.0936, -0.0176, -0.103, -0.0052, 0.1627, 0.079, 0.082, -0.2438, -0.1182, -0.016, 0.1215, -0.0091, -0.0517, -0.03, -0.0589, -0.2315, -0.1286, -0.1199, 0.2866, 0.0122, 0.1046, 0.0232, 0.0164, -0.0132, -0.2337, -0.0218, -0.0405, -0.019, -0.0144, 0.0227, 0.0262, -0.0486, 0.0407, 0.0409, -0.0732, 0.4246, 0.103, 0.0808, -0.1494, 0.1471, 0.2057, -0.0533, -0.1855, 0.0616, 0.0348, 0.121, 0.271, -0.0521, 0.1651, 0.025, -0.0339, -0.07, 0.1155, -0.0905, -0.2679, 0.0552, -0.0485, 0.0351, 0.0582, -0.0744, -0.0191, 0.0294, 0.0786, -0.0611, -0.0638, 0.1417, 0.0177, -0.1093, -0.0368, -0.1943, -0.024, 0.1895, 0.088, -0.0517, -0.2148, 0.0574, 0.0077, 0.1147, 0.0485, -0.05, 0.176, -0.1182, 0.0062, 0.1549, -0.0883, -0.0034], [-0.1516, 0.0261, -0.1214, -0.0554, 0.1189, -0.0318, 0.0663, 0.007, 0.0326, 0.2224, -0.1209, -0.023, -0.0409, -0.1631, 0.1822, -0.1053, 0.127, -0.0679, 0.0279, -0.0594, -0.2264, 0.1447, 0.1304, -0.0832, 0.0398, 0.1593, -0.0254, 0.0029, -0.0111, 0.0802, -0.0959, -0.0435, 0.1217, -0.0023, 0.0125, 0.0479, -0.1467, -0.0639, 0.0946, 0.0305, -0.0139, -0.0694, -0.0195, -0.0004, -0.0273, -0.1561, 0.0345, -0.0749, 0.1438, 0.0614, -0.0707, -0.0107, -0.6549, 0.2256, 0.0823, 0.0814, -0.1385, -0.3124, 0.2189, 0.0438, 0.2011, 0.0777, -0.1083, -0.1452, 0.1372, 0.0356, -0.1708, -0.0939, -0.1239, -0.1943, -0.053, -0.0218, 0.1476, -0.2356, 0.0103, -0.0558, -0.0901, -0.0388, 0.0276, -0.0392, 0.0675, 0.0791, -0.1464, -0.1893, -0.0815, 0.0636, -0.0182, -0.2243, 0.2415, 0.0856, -0.009, -0.0234, 0.1402, -0.0363, -0.042, -0.3344, 0.2943, 0.0946, -0.2424, 0.0413, 0.1328, 0.181, -0.0299, 0.1109, 0.0168, 0.2168, -0.0956, 0.0227, 0.0275, 0.2631, -0.0734, 0.1344, -0.18, -0.2053, 0.1573, 0.0621, -0.0574, 0.0598, 0.1778, -0.4325, 0.0107, -0.0715, -0.2109, 0.1728, 0.0044, -0.2923, -0.1781, -0.0571, -0.0941, 0.1887, -0.0802, -0.1051, 0.1524, 0.0908, -0.0678, -0.0649, 0.1076, -0.0581, 0.213, -0.0256, 0.196, -0.1287, -0.1607, 0.0976, -0.1216, 0.0457, -0.0005, -0.1337, 0.0939, 0.081, -0.0775, -0.0077, -0.1135, 0.0251, -0.0352, 0.0153, 0.1876, 0.2257, 0.1956, -0.0751, 0.2021, -0.1221, 0.0264, 0.1743, 0.2078, -0.0412, 0.0684, 0.1525, -0.3519, -0.1587, -0.1308, 0.0614, -0.0619, 0.0761, 0.0409, -0.0189, 0.2209, -0.1827, -0.1356, 0.2158, 0.1883, 0.0224, -0.0051, -0.02, 0.0268, 0.0857, -0.1256, -0.0379, -0.2222, 0.0388, -0.2013, -0.1436, -0.2269, 0.1731, 0.0511, 0.3046, 0.0562, -0.1082, 0.2207, -0.0739, -0.1245, 0.2508, 0.0067, -0.1141, 0.2315, 0.0051, -0.0013, 0.0404, -0.1076, -0.0516, 0.0938, 0.1965, -0.1102, -0.0337, 0.1085, -0.0337, -0.2225, 0.0302, -0.1936, -0.199, 0.1831, 0.0049, 0.0237, -0.2115, -0.122, -0.1782, 0.0604, -0.1211, 0.0262, -0.1189, -0.2392, -0.0616, 0.3307, -0.3224, 0.0041, -0.0311, 0.0268, -0.0678, -0.2845, 0.0837, -0.0811, -0.0565, 0.1536, -0.007, 0.009, -0.0248, -0.0004, 0.102, -0.1167, 0.3847, 0.0886, 0.0723, 0.1374, 0.0931, 0.0807, -0.2107, -0.1093, 0.1742, 0.0211, 0.0566, 0.015, 0.114, 0.0128, -0.0062, -0.7042, 0.0187, -0.01, -0.0832, -0.1644, 0.1549, -0.2233, 0.0695, -0.0517, 0.0135, 0.0209, 0.0536, -0.1664, -0.0425, 0.1485, 0.0098, 0.222, -0.0455, -0.0158, -0.2935, 0.0842, 0.0782, 0.0276, 0.0811, 0.1665, -0.0177, -0.009, 0.2296, -0.0601, 0.0667, -0.0205, 0.0278, 0.0135, 0.1152, 0.068, -0.1444], [0.0897, 0.016, -0.0571, 0.0405, -0.0696, -0.1237, 0.0301, 0.0248, -0.0303, 0.0174, 0.0063, 0.0184, 0.0217, -0.0257, 0.035, -0.0242, 0.0029, 0.0188, -0.057, 0.0252, -0.021, -0.0008, 0.036, -0.0729, -0.0665, 0.0989, 0.0676, 0.0852, -0.0089, 0.0313, -0.0069, -0.0032, -0.0462, 0.0497, 0.0261, 0.0268, -0.031, -0.1361, -0.0062, 0.0375, -0.032, -0.0106, 0.0534, -0.0187, 0.0638, 0.0094, 0.0047, -0.053, 0.0093, -0.0087, 0.0004, 0.0493, -0.6296, 0.0222, 0.019, 0.0268, -0.0426, 0.0057, -0.1683, 0.0244, -0.0213, -0.0181, 0.0421, -0.0309, -0.0089, 0.0032, 0.0108, -0.0049, 0.0258, 0.0278, -0.0163, 0.02, 0.0164, -0.0954, -0.0032, 0.0043, 0.0104, -0.0088, 0.0007, 0.035, -0.0206, -0.0083, -0.0114, -0.1869, 0.0258, 0.001, 0.0085, 0.0151, 0.2125, 0.0071, 0.0319, -0.0482, 0.0621, 0.0626, 0.0159, -0.0013, 0.0087, 0.0686, -0.0034, 0.0238, -0.0452, -0.0198, 0.0112, 0.0109, -0.1022, -0.0272, 0.2337, -0.0465, 0.1592, -0.0407, -0.1029, -0.0487, -0.0676, 0.0676, -0.0328, 0.0323, 0.0077, 0.019, 0.0017, -0.2974, 0.0011, -0.0356, 0.0693, -0.048, -0.0821, -0.0644, -0.0284, -0.0191, -0.0233, 0.0353, -0.0463, 0.0656, 0.0019, -0.0212, -0.0309, -0.3534, -0.0309, 0.0076, -0.0419, 0.0457, -0.0306, 0.0357, 0.0667, 0.3659, 0.0149, -0.0443, 0.0068, -0.0378, 0.0146, 0.0215, 0.1081, 0.0124, -0.0437, -0.043, 0.0258, 0.0213, -0.0309, -0.0018, -0.0067, 0.0172, 0.0089, -0.0171, 0.0275, -0.0518, -0.184, -0.013, -0.0241, 0.0526, -0.028, 0.0051, 0.0163, -0.0165, 0.0161, 0.1237, 0.0804, -0.0789, 0.0386, -0.3892, 0.0157, -0.0246, 0.0477, -0.0045, -0.0214, 0.0173, -0.0191, -0.1382, -0.0111, 0.0712, 0.1514, 0.0291, 0.0555, -0.0039, 0.0028, -0.0277, -0.0275, -0.0177, -0.0338, -0.0372, 0.2071, 0.046, -0.0294, 0.0435, -0.0169, -0.0121, 0.0253, 0.0198, 0.0918, 0.0193, 0.0668, 0.0288, 0.004, -0.0439, -0.0302, 0.0064, 0.0364, 0.0543, -0.0338, 0.0159, 0.0617, -0.0941, -0.0086, -0.0092, 0.03, -0.0241, -0.035, -0.0621, 0.0175, 0.0374, 0.0034, 0.0344, 0.1286, -0.0267, 0.1861, 0.0489, -0.0032, 0.018, -0.0228, 0.2414, -0.0935, 0.0612, -0.0209, 0.0136, 0.0392, -0.0135, -0.0253, 0.0335, 0.0095, 0.0419, 0.0076, 0.4522, -0.0188, 0.0233, -0.0474, 0.0159, -0.009, 0.0265, 0.0336, 0.0221, 0.0472, 0.0048, 0.0962, 0.0344, -0.0515, -0.0087, -0.098, -0.0288, 0.0377, 0.0202, -0.2979, -0.0387, -0.0198, -0.0161, -0.0045, 0.0087, -0.0387, 0.0421, 0.0383, 0.0258, 0.0069, -0.0298, -0.0198, -0.0152, 0.0033, 0.0075, 0.0358, -0.0155, -0.0111, 0.076, -0.0452, 0.0697, 0.0299, -0.0029, -0.0348, -0.027, 0.0351, 0.0559, 0.0591, 0.1559, -0.0254, -0.0259], [-0.0455, 0.2169, -0.045, -0.1449, 0.0315, -0.0419, 0.2311, 0.2965, 0.0666, 0.0629, 0.0198, 0.113, -0.2449, 0.0175, 0.0883, 0.0854, 0.0701, -0.1096, -0.028, -0.1094, -0.3251, 0.0504, -0.0819, 0.0199, -0.0759, -0.0156, 0.0021, 0.2765, -0.0474, -0.1035, 0.0427, -0.0551, 0.0641, -0.0611, -0.0518, 0.1525, -0.0606, 0.0785, 0.0682, 0.1768, -0.0766, 0.0349, 0.0267, 0.0824, 0.0422, 0.0942, -0.0785, -0.075, 0.1675, -0.0544, 0.2628, 0.0023, -0.6394, 0.1559, 0.1765, 0.0651, -0.0255, 0.0073, 0.0251, 0.0821, -0.0506, 0.0795, 0.0042, -0.0591, -0.0546, 0.0919, -0.1361, 0.1442, -0.0495, -0.1155, 0.0202, 0.0177, 0.0534, 0.0331, -0.0241, -0.2127, 0.1117, -0.0832, -0.0365, 0.2927, -0.0237, 0.147, -0.0489, -0.2541, 0.2297, 0.0248, 0.0782, -0.2193, 0.072, -0.084, -0.1034, -0.1727, -0.0788, 0.0693, -0.0286, -0.1217, 0.0104, -0.0005, 0.0687, 0.0051, -0.1218, -0.1055, -0.103, 0.1064, -0.253, 0.074, -0.0645, 0.0713, 0.0915, 0.0479, -0.0029, 0.0341, -0.0275, -0.1296, -0.0062, -0.0279, -0.0489, -0.0853, 0.0262, -0.369, 0.0512, -0.2761, 0.0339, 0.0558, -0.0562, 0.1133, -0.123, 0.0184, 0.1064, -0.1874, -0.0688, 0.1317, -0.0355, -0.0461, -0.1048, 0.0028, -0.0095, -0.0501, 0.0169, -0.066, 0.0848, 0.0103, -0.1681, 0.0017, 0.0057, -0.1019, -0.0982, 0.0543, 0.1098, 0.2491, -0.0535, 0.0186, 0.0757, -0.0243, 0.1771, 0.0988, 0.0174, -0.0504, 0.1588, -0.1371, 0.1396, -0.2422, -0.0725, 0.0042, 0.016, 0.0036, 0.0601, -0.0851, -0.1195, -0.2016, -0.0865, 0.0556, -0.0251, 0.0856, -0.058, -0.0954, 0.2181, 0.0978, 0.1717, -0.048, 0.0292, 0.1121, -0.1031, -0.0349, 0.1859, 0.0179, -0.0794, 0.1225, -0.3095, 0.0048, -0.1176, -0.0507, -0.1813, 0.0849, 0.0489, 0.3092, 0.1104, 0.106, 0.1833, -0.1318, -0.1152, 0.0651, 0.2678, -0.0722, 0.0947, -0.1414, 0.0365, -0.1402, -0.009, 0.0396, -0.0218, -0.0268, 0.0875, 0.0372, -0.045, 0.1391, -0.0775, 0.1772, -0.3194, -0.083, 0.072, -0.0003, 0.075, -0.0854, 0.0564, 0.1475, -0.1642, 0.0939, -0.0234, -0.1082, 0.0726, 0.004, 0.2956, -0.07, -0.1524, -0.0799, 0.0644, 0.1934, -0.2858, 0.1708, 0.0498, -0.1527, -0.0686, 0.1355, 0.2039, -0.0426, 0.0943, 0.1789, 0.0321, 0.3679, 0.174, 0.1584, -0.1019, -0.1073, 0.4471, 0.2862, -0.0626, 0.0859, -0.1308, 0.2145, -0.0207, -0.0537, -0.079, 0.0873, -0.7401, 0.1595, -0.039, -0.0173, -0.0115, 0.0917, -0.1477, 0.006, 0.1513, -0.0682, -0.0532, 0.0731, -0.0389, -0.0997, -0.0045, 0.0345, -0.0181, 0.0577, -0.1213, -0.1275, -0.025, 0.0256, -0.0919, 0.1334, -0.0633, 0.1814, -0.0024, 0.0277, -0.0574, -0.2292, -0.0546, -0.0158, -0.1111, 0.0665, -0.0223, -0.115], [-0.0452, -0.1182, -0.0588, -0.0678, 0.0659, -0.0131, 0.0226, 0.0341, 0.0073, -0.0948, 0.0425, 0.1141, -0.0269, 0.0057, -0.0998, 0.0446, -0.0107, -0.046, -0.0858, 0.1738, -0.013, 0.0453, -0.1062, 0.1329, 0.0352, 0.0535, 0.0053, 0.1091, -0.0301, -0.0369, -0.0765, -0.0133, -0.0308, 0.1176, 0.0911, 0.0312, 0.049, -0.0843, 0.1036, -0.0138, 0.0216, -0.0034, 0.0214, -0.0578, -0.1358, 0.0589, 0.0092, 0.0299, 0.0109, -0.0453, 0.0458, 0.0886, -0.5181, 0.0412, 0.0049, -0.0017, 0.0471, -0.1153, -0.2281, -0.1125, 0.0473, -0.0311, -0.0006, -0.0075, -0.1309, -0.0087, 0.0068, 0.0634, 0.0376, 0.0001, 0.0125, -0.0212, -0.0006, -0.1096, -0.056, 0.0224, -0.0342, 0.06, -0.0298, 0.2647, 0.0342, 0.0083, -0.006, -0.3098, -0.0, 0.0341, -0.0454, 0.0164, -0.5405, 0.0691, -0.0402, 0.0763, -0.0947, -0.0367, -0.0085, 0.0024, 0.0071, -0.1708, -0.0697, -0.0473, -0.1802, -0.0478, 0.002, 0.0089, 0.0125, 0.0277, -0.1764, 0.0552, 0.0754, -0.0075, -0.0053, 0.0124, -0.013, 0.0183, -0.2257, -0.004, 0.1549, 0.0242, -0.0479, -0.2813, -0.0232, -0.0071, 0.0019, 0.0709, 0.0374, 0.2256, -0.1018, 0.232, -0.037, 0.0355, -0.0028, -0.0077, -0.0419, 0.0492, 0.0353, -0.2993, -0.0554, -0.0579, -0.0191, -0.0706, 0.006, -0.0416, 0.0982, 0.3701, 0.004, 0.1287, 0.1455, 0.0185, -0.0102, -0.1441, -0.1069, 0.0642, 0.087, 0.0936, 0.0824, -0.042, -0.1653, 0.0034, -0.0284, -0.0616, 0.0449, 0.0362, 0.0063, -0.1503, 0.1723, 0.014, 0.0642, 0.1124, 0.1234, 0.0643, -0.1091, 0.0408, 0.1279, -0.0234, 0.1254, 0.1637, 0.2048, -0.7466, 0.0269, -0.019, 0.0579, 0.0034, 0.093, 0.1473, 0.0041, -0.3608, -0.1192, -0.1101, 0.6456, 0.0752, -0.07, -0.055, 0.0097, 0.0175, 0.0034, 0.0171, -0.0259, -0.0431, 0.2949, 0.0442, -0.0568, -0.0246, -0.0825, -0.0895, -0.0354, 0.0302, -0.0512, -0.1258, -0.0261, 0.039, 0.0185, 0.0146, 0.0754, -0.0044, -0.0718, 0.0796, -0.0583, 0.0494, -0.0567, 0.0146, 0.0428, -0.0613, 0.0115, -0.0007, 0.0787, -0.0534, 0.0449, 0.1126, 0.0175, 0.0473, 0.2723, -0.0599, 0.2096, -0.0041, -0.0395, -0.4713, 0.0233, -0.0937, -0.2639, 0.0466, -0.1424, 0.001, -0.0245, -0.0115, -0.0302, 0.0034, -0.0401, 0.0055, 0.013, 0.356, 0.069, -0.0326, -0.06, 0.0033, 0.23, 0.0421, -0.1639, 0.0208, 0.0544, 0.0217, -0.049, -0.0096, -0.0298, 0.0323, -0.7646, -0.0145, 0.1061, -0.1425, -0.0049, -0.0913, 0.0375, -0.0735, -0.0046, 0.0877, 0.0725, -0.0258, -0.0401, -0.0095, -0.0906, -0.1003, 0.2793, -0.0684, 0.0113, -0.1215, -0.0354, -0.047, -0.0268, 0.0227, -0.1376, 0.0929, 0.0013, 0.0696, 0.1652, -0.068, 0.0175, -0.0667, -0.0633, 0.2623, 0.0747, 0.025], [-0.0326, 0.0195, 0.0364, -0.1522, -0.0004, -0.1664, -0.1484, -0.0419, -0.267, -0.0867, -0.0967, 0.1412, 0.049, -0.1076, 0.1205, 0.1043, 0.0353, 0.1153, -0.1742, -0.2729, -0.4423, -0.0395, 0.2611, -0.0571, -0.0127, -0.1157, 0.0721, -0.0517, -0.2769, -0.0741, 0.1076, 0.1005, 0.0459, 0.2092, -0.215, 0.1929, -0.0161, -0.2282, -0.0651, -0.0653, 0.1085, -0.1041, -0.0867, -0.033, 0.0878, -0.2261, -0.0212, -0.0315, -0.2479, 0.0607, -0.12, 0.0408, -0.8369, -0.1042, -0.1361, 0.0352, 0.0124, 0.1088, 0.0509, 0.0047, 0.0219, 0.0814, -0.0404, -0.0903, -0.0295, -0.0709, -0.0619, -0.0012, -0.1265, 0.1139, 0.0489, -0.0884, -0.0212, -0.0213, 0.2818, 0.0265, 0.0981, -0.5025, -0.2206, -0.0274, 0.0092, 0.0006, 0.1065, -0.282, 0.1825, -0.2823, -0.0556, 0.0994, 0.0301, 0.2853, -0.1554, -0.0155, 0.1182, -0.2357, 0.0372, 0.0412, -0.0469, -0.1763, -0.0437, -0.061, -0.1358, 0.0631, 0.0861, -0.0006, -0.0699, -0.0475, -0.1164, 0.1694, 0.0653, 0.1353, 0.0626, -0.056, -0.036, -0.0176, -0.2072, 0.1721, 0.093, 0.1898, -0.1265, -0.292, 0.1351, -0.1685, 0.0872, 0.0529, 0.1249, 0.1556, -0.0189, 0.1228, -0.0232, 0.0005, 0.0116, -0.0448, 0.1589, 0.0311, 0.2283, 0.2629, 0.1098, -0.2181, 0.0711, 0.0021, 0.0404, -0.0385, 0.1605, 0.1123, 0.021, -0.0397, -0.2564, -0.2977, 0.1308, -0.0305, -0.1551, 0.2805, -0.0386, -0.0466, -0.2589, 0.179, -0.0679, 0.1405, -0.212, 0.0176, -0.0757, -0.26, -0.0182, 0.0827, -0.1437, 0.03, -0.0128, -0.1292, 0.1008, 0.035, 0.2977, 0.2411, -0.0608, -0.1024, 0.1391, -0.1677, 0.3231, -0.1087, 0.0269, -0.0593, 0.1357, -0.0963, -0.1021, -0.1126, -0.0657, -0.4809, 0.0893, -0.1207, -0.1273, -0.0757, -0.0831, 0.2692, -0.0536, -0.1892, 0.0861, -0.1484, 0.0321, 0.1093, 0.0251, 0.1879, -0.0447, 0.0748, 0.1338, -0.0289, 0.0128, 0.0625, 0.173, -0.1717, -0.2312, 0.0046, 0.0477, 0.1302, 0.0672, -0.1898, -0.0803, 0.1801, -0.0964, 0.1186, 0.0623, 0.0322, 0.0902, -0.072, -0.0564, 0.1925, -0.2658, -0.1864, -0.105, 0.0615, -0.0711, 0.0126, 0.0044, 0.13, 0.1656, -0.1325, 0.0699, -0.0184, 0.0919, -0.0046, -0.1545, -0.0473, -0.0922, 0.1955, -0.0724, 0.4568, 0.0782, 0.2548, 0.0745, -0.1355, -0.0421, 0.372, 0.1428, 0.0172, 0.1141, -0.1431, 0.0519, -0.1439, 0.0232, 0.0016, -0.0564, 0.0573, 0.0371, 0.0915, 0.0967, -0.1458, -0.1127, -0.212, -0.0881, -0.1117, -0.1259, -0.0701, -0.0795, 0.1875, 0.0183, -0.0661, -0.0428, -0.0551, 0.0231, -0.297, -0.0825, -0.0378, 0.0166, -0.0777, -0.0733, 0.1054, -0.0045, 0.1439, 0.0198, 0.3949, -0.0875, -0.1, 0.1736, -0.0556, -0.0239, -0.1806, -0.2101, 0.1066, -0.1304, 0.0249, 0.0083, -0.1229], [-0.0657, 0.046, 0.0251, -0.0332, 0.0141, -0.221, -0.0121, -0.0384, 0.0709, -0.0542, 0.06, 0.0671, 0.0604, 0.1536, -0.0443, 0.0414, 0.0221, 0.0859, -0.0448, -0.0593, -0.0176, -0.036, 0.0366, -0.296, 0.0502, -0.2343, 0.047, -0.0906, 0.0382, -0.2112, 0.0204, -0.0113, 0.2169, -0.0023, 0.0375, 0.0031, 0.0218, 0.0073, -0.0524, 0.0786, 0.0447, -0.0189, -0.1872, 0.0252, -0.0965, -0.0778, -0.1135, -0.0199, 0.0901, 0.0191, -0.0134, -0.001, -0.6779, -0.0296, -0.0169, 0.0048, 0.0055, 0.0217, 0.0459, 0.1198, -0.1142, -0.0131, 0.1316, -0.034, 0.1073, -0.0355, -0.0246, 0.0521, -0.055, 0.0158, 0.03, 0.0168, 0.0335, 0.1986, 0.072, -0.0165, 0.0566, -0.1098, -0.0796, -0.0808, -0.0356, 0.0266, 0.1186, -0.2048, -0.0201, -0.1187, -0.0025, -0.0004, -0.0488, 0.0154, -0.0453, -0.0443, -0.0276, -0.1272, -0.0878, 0.007, 0.0324, -0.0797, -0.0007, -0.0803, -0.1543, -0.01, 0.0158, 0.0556, -0.1504, -0.0414, 0.216, -0.0864, 0.149, -0.0059, 0.0869, 0.2644, -0.023, 0.0089, -0.0612, 0.0043, 0.0118, 0.1146, -0.017, -0.3391, 0.117, 0.0525, 0.0654, 0.188, 0.0733, 0.1355, -0.0028, -0.0488, -0.1325, -0.0084, 0.0245, -0.0142, -0.0509, 0.0929, 0.0061, -0.2864, 0.1034, -0.0612, -0.0258, -0.0505, -0.0298, 0.0362, 0.0213, 0.2663, -0.0181, -0.059, 0.0939, -0.0895, 0.0385, -0.0212, 0.1066, 0.1416, 0.0303, 0.0044, -0.085, -0.0252, -0.0332, 0.0527, -0.032, -0.0311, -0.0576, 0.0001, 0.0041, 0.0065, -0.1985, 0.0077, 0.1188, 0.008, 0.0286, -0.0599, 0.1298, 0.0204, 0.0183, 0.1724, 0.0711, 0.0252, 0.1688, -0.0282, 0.0433, 0.0193, -0.0003, 0.0717, 0.0823, 0.0143, 0.0575, -0.2815, -0.0972, -0.1434, 0.0879, -0.0272, -0.041, 0.0076, 0.0508, 0.0021, 0.0043, 0.0017, -0.0012, -0.0067, 0.1853, 0.0582, 0.0609, -0.0207, 0.0806, 0.0253, 0.0604, 0.0744, -0.1165, -0.0971, -0.0967, 0.0329, 0.0521, 0.0893, 0.0125, -0.0923, -0.0302, 0.014, -0.1939, -0.0287, 0.0101, 0.1531, 0.0165, -0.1121, 0.0018, 0.1513, 0.0316, -0.094, -0.0563, -0.0422, 0.0181, 0.1168, -0.1048, 0.0031, 0.2662, 0.0742, 0.0081, 0.1066, -0.0511, 0.0307, -0.1781, 0.0602, -0.0484, 0.0319, 0.0762, 0.0056, -0.0201, -0.0665, -0.0476, 0.0214, -0.0166, 0.3347, 0.0167, 0.0944, -0.0148, -0.022, -0.2036, 0.0307, -0.1116, -0.0157, 0.0638, 0.017, -0.1067, 0.0272, -0.0475, -0.0247, -0.0591, -0.0323, 0.1388, 0.0192, -0.0207, 0.0467, 0.0291, -0.0942, -0.0741, -0.0043, -0.0332, 0.051, -0.0713, 0.0526, 0.004, -0.0196, -0.1, -0.1013, -0.0433, -0.07, -0.0107, 0.0362, -0.0375, 0.1955, -0.1428, 0.0313, -0.0333, 0.0039, 0.0837, 0.0162, -0.1025, 0.0986, -0.0369, 0.2393, 0.0885, -0.0732], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n","printing it:    64\n","printing it:    64\n","maximum no. of cols:  300\n","maximum no. of rows:  64\n","bert_generator.py:255: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  all_ngram_embeddings = torch.tensor(ngram_embeddings_padded, dtype=torch.float)\n","03/28/2021 17:59:28 - INFO - bert_utils -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/28/2021 17:59:28 - INFO - bert_utils -   extracting archive file /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmphb0ui5lq\n","03/28/2021 17:59:31 - INFO - bert_utils -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/28/2021 17:59:34 - INFO - bert_utils -   Weights of BertForNgramClassification not initialized from pretrained model: ['converter.weight', 'converter.bias']\n","03/28/2021 17:59:34 - INFO - bert_utils -   Weights from pretrained model not used in BertForNgramClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:104: UserWarning: \n","GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n","The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n","If you want to use the GeForce RTX 3090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n","\n","  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n","Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]\n","Iteration:   0%|                                          | 0/1 [00:00<?, ?it/s]\u001b[A\n","Epoch:   0%|                                             | 0/25 [00:00<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"bert_generator.py\", line 432, in <module>\n","    main() \n","  File \"bert_generator.py\", line 315, in main\n","    loss = model(ngram_ids, ngram_masks, ngram_embeddings) \n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/data_parallel.py\", line 155, in forward\n","    \"them on device: {}\".format(self.src_device_obj, t.device))\n","RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DjwNfkjrg1YO"},"source":["Generate attacks - DISP random attacks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"OPALMeyig1YP","executionInfo":{"status":"ok","timestamp":1617241032243,"user_tz":240,"elapsed":3460,"user":{"displayName":"sriram sanjeev pratti","photoUrl":"https://lh3.googleusercontent.com/-x9kOW5PtcK0/AAAAAAAAAAI/AAAAAAAARGg/gGBrVWqYABU/s64/photo.jpg","userId":"07241238899528141574"}},"outputId":"1364925b-ef72-4627-b9c7-06b03537c56f"},"source":["!python bert_random_attacks.py \\\n","--task_name sst-2 \\\n","--do_lower_case \\\n","--data_dir data/sst-2/add_1/dev_attacks.tsv \\\n","--bert_model bert-base-uncased \\\n","--max_seq_length 128 \\\n","--output_dir ./data/sst-2/add_1/\\\n","#--output_dir_attacks ./data/sst-2/add_1/\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.4) or chardet (3.0.4) doesn't match a supported version!\n","  RequestsDependencyWarning)\n","Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","usage: bert_random_attacks.py [-h] --data_dir DATA_DIR --bert_model BERT_MODEL\n","                              --output_dir OUTPUT_DIR\n","                              [--word_embedding_file WORD_EMBEDDING_FILE]\n","                              [--index_path INDEX_PATH]\n","                              [--word_embedding_info WORD_EMBEDDING_INFO]\n","                              [--data_file DATA_FILE]\n","                              [--max_seq_length MAX_SEQ_LENGTH]\n","                              [--max_ngram_length MAX_NGRAM_LENGTH]\n","                              [--embedding_size EMBEDDING_SIZE] --task_name\n","                              TASK_NAME [--do_lower_case]\n","                              [--output_dir_attacks] [--local_rank LOCAL_RANK]\n","bert_random_attacks.py: error: unrecognized arguments: ./data/sst-2/add_1/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_HK0fT3yiNkT","executionInfo":{"status":"ok","timestamp":1617243295386,"user_tz":240,"elapsed":51921,"user":{"displayName":"sriram sanjeev pratti","photoUrl":"https://lh3.googleusercontent.com/-x9kOW5PtcK0/AAAAAAAAAAI/AAAAAAAARGg/gGBrVWqYABU/s64/photo.jpg","userId":"07241238899528141574"}},"outputId":"806e1143-8f9c-4c1c-f4db-8e8647043528"},"source":["!python bert_random_attacks.py  --task_name sst-2  --do_lower_case  --data_dir data/sst-2/add_1/dev_attacks.tsv  --bert_model bert-base-uncased --max_seq_length 128  --output_dir ./data/sst-2/add_1"],"execution_count":18,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","token_ids_seq:  [2, 4]\n","Printing prob:  0.19124576998191212\n","label:  0\n","idx:  17\n","tok_flaw:  unequivocally\n","flaw_tokens_seq:  ['the', 'way', 'copbpola', 'professes', 'hiPs', 'love', 'for', 'movies', '--', 'both', 'colorful', 'pop', 'junk', 'and', 'the', 'classics', 'that', 'unequivocally']\n","token_ids_seq:  [2, 4]\n","Printing prob:  0.657739248492895\n","label:  0\n","idx:  18\n","tok_flaw:  qualify\n","flaw_tokens_seq:  ['the', 'way', 'copbpola', 'professes', 'hiPs', 'love', 'for', 'movies', '--', 'both', 'colorful', 'pop', 'junk', 'and', 'the', 'classics', 'that', 'unequivocally', 'qualify']\n","token_ids_seq:  [2, 4]\n","Printing prob:  0.11513492362588817\n","label:  1\n","idx:  19\n","tok_flaw:  ags\n","flaw_tokens_seq:  ['the', 'way', 'copbpola', 'professes', 'hiPs', 'love', 'for', 'movies', '--', 'both', 'colorful', 'pop', 'junk', 'and', 'the', 'classics', 'that', 'unequivocally', 'qualify', 'ags']\n","token_ids_seq:  [2, 4, 19]\n","Printing prob:  0.33210153992636604\n","label:  0\n","idx:  20\n","tok_flaw:  art\n","flaw_tokens_seq:  ['the', 'way', 'copbpola', 'professes', 'hiPs', 'love', 'for', 'movies', '--', 'both', 'colorful', 'pop', 'junk', 'and', 'the', 'classics', 'that', 'unequivocally', 'qualify', 'ags', 'art']\n","token_ids_seq:  [2, 4, 19]\n","Printing prob:  0.3186585051183187\n","label:  0\n","idx:  21\n","tok_flaw:  --\n","flaw_tokens_seq:  ['the', 'way', 'copbpola', 'professes', 'hiPs', 'love', 'for', 'movies', '--', 'both', 'colorful', 'pop', 'junk', 'and', 'the', 'classics', 'that', 'unequivocally', 'qualify', 'ags', 'art', '--']\n","token_ids_seq:  [2, 4, 19]\n","Printing prob:  0.37579145175984685\n","label:  0\n","idx:  22\n","tok_flaw:  is\n","flaw_tokens_seq:  ['the', 'way', 'copbpola', 'professes', 'hiPs', 'love', 'for', 'movies', '--', 'both', 'colorful', 'pop', 'junk', 'and', 'the', 'classics', 'that', 'unequivocally', 'qualify', 'ags', 'art', '--', 'is']\n","token_ids_seq:  [2, 4, 19]\n","Printing prob:  0.6414767306935008\n","label:  0\n","idx:  23\n","tok_flaw:  giddily\n","flaw_tokens_seq:  ['the', 'way', 'copbpola', 'professes', 'hiPs', 'love', 'for', 'movies', '--', 'both', 'colorful', 'pop', 'junk', 'and', 'the', 'classics', 'that', 'unequivocally', 'qualify', 'ags', 'art', '--', 'is', 'giddily']\n","token_ids_seq:  [2, 4, 19]\n","Printing prob:  0.9558634114409059\n","label:  0\n","idx:  24\n","tok_flaw:  entertaining\n","flaw_tokens_seq:  ['the', 'way', 'copbpola', 'professes', 'hiPs', 'love', 'for', 'movies', '--', 'both', 'colorful', 'pop', 'junk', 'and', 'the', 'classics', 'that', 'unequivocally', 'qualify', 'ags', 'art', '--', 'is', 'giddily', 'entertaining']\n","token_ids_seq:  [2, 4, 19]\n","Printing prob:  0.8793309084801326\n","label:  0\n","idx:  25\n","tok_flaw:  .\n","flaw_tokens_seq:  ['the', 'way', 'copbpola', 'professes', 'hiPs', 'love', 'for', 'movies', '--', 'both', 'colorful', 'pop', 'junk', 'and', 'the', 'classics', 'that', 'unequivocally', 'qualify', 'ags', 'art', '--', 'is', 'giddily', 'entertaining', '.']\n","token_ids_seq:  [2, 4, 19]\n","all_flaw_tokens:  [['the', 'way', 'copbpola', 'professes', 'hiPs', 'love', 'for', 'movies', '--', 'both', 'colorful', 'pop', 'junk', 'and', 'the', 'classics', 'that', 'unequivocally', 'qualify', 'ags', 'art', '--', 'is', 'giddily', 'entertaining', '.']]\n","all_token_idx:  [[2, 4, 19]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","attacks:  98% 1781/1820 [00:35<00:00, 45.80it/s]emb_dict:  None\n","embeddings: None\n","Printing prob:  0.6500743951208857\n","label:  0\n","idx:  0\n","tok_flaw:  what\n","flaw_tokens_seq:  ['what']\n","token_ids_seq:  []\n","Printing prob:  0.880490203898702\n","label:  0\n","idx:  1\n","tok_flaw:  happened\n","flaw_tokens_seq:  ['what', 'happened']\n","token_ids_seq:  []\n","Printing prob:  0.934603935412183\n","label:  0\n","idx:  2\n","tok_flaw:  with\n","flaw_tokens_seq:  ['what', 'happened', 'with']\n","token_ids_seq:  []\n","Printing prob:  0.20142361182098856\n","label:  0\n","idx:  3\n","tok_flaw:  pluto\n","flaw_tokens_seq:  ['what', 'happened', 'with', 'pluto']\n","token_ids_seq:  []\n","Printing prob:  0.2699652363864957\n","label:  0\n","idx:  4\n","tok_flaw:  nash\n","flaw_tokens_seq:  ['what', 'happened', 'with', 'pluto', 'nash']\n","token_ids_seq:  []\n","Printing prob:  0.29536746639760425\n","label:  0\n","idx:  5\n","tok_flaw:  ?\n","flaw_tokens_seq:  ['what', 'happened', 'with', 'pluto', 'nash', '?']\n","token_ids_seq:  []\n","all_flaw_tokens:  [['what', 'happened', 'with', 'pluto', 'nash', '?']]\n","all_token_idx:  [[]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.6905489909909436\n","label:  0\n","idx:  0\n","tok_flaw:  take\n","flaw_tokens_seq:  ['take']\n","token_ids_seq:  []\n","Printing prob:  0.995826789362989\n","label:  0\n","idx:  1\n","tok_flaw:  care\n","flaw_tokens_seq:  ['take', 'care']\n","token_ids_seq:  []\n","Printing prob:  0.34740890749458997\n","label:  0\n","idx:  2\n","tok_flaw:  of\n","flaw_tokens_seq:  ['take', 'care', 'of']\n","token_ids_seq:  []\n","Printing prob:  0.8726106448294932\n","label:  0\n","idx:  3\n","tok_flaw:  my\n","flaw_tokens_seq:  ['take', 'care', 'of', 'my']\n","token_ids_seq:  []\n","Printing prob:  0.22479105798250842\n","label:  0\n","idx:  4\n","tok_flaw:  cat\n","flaw_tokens_seq:  ['take', 'care', 'of', 'my', 'cat']\n","token_ids_seq:  []\n","Printing prob:  0.574338589143699\n","label:  0\n","idx:  5\n","tok_flaw:  offers\n","flaw_tokens_seq:  ['take', 'care', 'of', 'my', 'cat', 'offers']\n","token_ids_seq:  []\n","Printing prob:  0.2522415064370027\n","label:  0\n","idx:  6\n","tok_flaw:  a\n","flaw_tokens_seq:  ['take', 'care', 'of', 'my', 'cat', 'offers', 'a']\n","token_ids_seq:  []\n","Printing prob:  0.40260229708648076\n","label:  0\n","idx:  7\n","tok_flaw:  refreshingly\n","flaw_tokens_seq:  ['take', 'care', 'of', 'my', 'cat', 'offers', 'a', 'refreshingly']\n","token_ids_seq:  []\n","Printing prob:  0.20557362671283763\n","label:  0\n","idx:  8\n","tok_flaw:  different\n","flaw_tokens_seq:  ['take', 'care', 'of', 'my', 'cat', 'offers', 'a', 'refreshingly', 'different']\n","token_ids_seq:  []\n","Printing prob:  0.03439726747466676\n","label:  1\n","idx:  9\n","tok_flaw:  slce\n","flaw_tokens_seq:  ['take', 'care', 'of', 'my', 'cat', 'offers', 'a', 'refreshingly', 'different', 'slce']\n","token_ids_seq:  [9]\n","Printing prob:  0.10349639128056776\n","label:  1\n","idx:  10\n","tok_flaw:  f\n","flaw_tokens_seq:  ['take', 'care', 'of', 'my', 'cat', 'offers', 'a', 'refreshingly', 'different', 'slce', 'f']\n","token_ids_seq:  [9, 10]\n","Printing prob:  0.6646815723321031\n","label:  0\n","idx:  11\n","tok_flaw:  asian\n","flaw_tokens_seq:  ['take', 'care', 'of', 'my', 'cat', 'offers', 'a', 'refreshingly', 'different', 'slce', 'f', 'asian']\n","token_ids_seq:  [9, 10]\n","Printing prob:  0.9669342754007165\n","label:  0\n","idx:  12\n","tok_flaw:  cinema\n","flaw_tokens_seq:  ['take', 'care', 'of', 'my', 'cat', 'offers', 'a', 'refreshingly', 'different', 'slce', 'f', 'asian', 'cinema']\n","token_ids_seq:  [9, 10]\n","Printing prob:  0.4588750592381373\n","label:  0\n","idx:  13\n","tok_flaw:  .\n","flaw_tokens_seq:  ['take', 'care', 'of', 'my', 'cat', 'offers', 'a', 'refreshingly', 'different', 'slce', 'f', 'asian', 'cinema', '.']\n","token_ids_seq:  [9, 10]\n","all_flaw_tokens:  [['take', 'care', 'of', 'my', 'cat', 'offers', 'a', 'refreshingly', 'different', 'slce', 'f', 'asian', 'cinema', '.']]\n","all_token_idx:  [[9, 10]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.4999366953022828\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.25711975554488664\n","label:  0\n","idx:  1\n","tok_flaw:  a\n","flaw_tokens_seq:  ['``', 'a']\n","token_ids_seq:  []\n","Printing prob:  0.1320275907601982\n","label:  0\n","idx:  2\n","tok_flaw:  stunning\n","flaw_tokens_seq:  ['``', 'a', 'stunning']\n","token_ids_seq:  []\n","Printing prob:  0.9006975154491824\n","label:  0\n","idx:  3\n","tok_flaw:  piece\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece']\n","token_ids_seq:  []\n","Printing prob:  0.1982303205134699\n","label:  0\n","idx:  4\n","tok_flaw:  of\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of']\n","token_ids_seq:  []\n","Printing prob:  0.5350643428854428\n","label:  0\n","idx:  5\n","tok_flaw:  visual\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual']\n","token_ids_seq:  []\n","Printing prob:  0.8739929443322675\n","label:  0\n","idx:  6\n","tok_flaw:  poetry\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry']\n","token_ids_seq:  []\n","Printing prob:  0.46065898195805866\n","label:  0\n","idx:  7\n","tok_flaw:  that\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that']\n","token_ids_seq:  []\n","Printing prob:  0.16528195798373002\n","label:  0\n","idx:  8\n","tok_flaw:  will\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will']\n","token_ids_seq:  []\n","Printing prob:  0.2660568407410445\n","label:  0\n","idx:  9\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',']\n","token_ids_seq:  []\n","Printing prob:  0.3941140238974976\n","label:  0\n","idx:  10\n","tok_flaw:  hopefully\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully']\n","token_ids_seq:  []\n","Printing prob:  0.3505746927374177\n","label:  0\n","idx:  11\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',']\n","token_ids_seq:  []\n","Printing prob:  0.7842314944225726\n","label:  0\n","idx:  12\n","tok_flaw:  be\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be']\n","token_ids_seq:  []\n","Printing prob:  0.7693437968576649\n","label:  0\n","idx:  13\n","tok_flaw:  remembered\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered']\n","token_ids_seq:  []\n","Printing prob:  0.9321995311556497\n","label:  0\n","idx:  14\n","tok_flaw:  as\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as']\n","token_ids_seq:  []\n","Printing prob:  0.7211682344757144\n","label:  0\n","idx:  15\n","tok_flaw:  one\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one']\n","token_ids_seq:  []\n","Printing prob:  0.7426493672889619\n","label:  0\n","idx:  16\n","tok_flaw:  of\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of']\n","token_ids_seq:  []\n","Printing prob:  0.598944740481311\n","label:  0\n","idx:  17\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the']\n","token_ids_seq:  []\n","Printing prob:  0.6729149671047173\n","label:  0\n","idx:  18\n","tok_flaw:  most\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the', 'most']\n","token_ids_seq:  []\n","Printing prob:  0.6400722003683602\n","label:  0\n","idx:  19\n","tok_flaw:  important\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the', 'most', 'important']\n","token_ids_seq:  []\n","Printing prob:  0.5354107157816531\n","label:  0\n","idx:  20\n","tok_flaw:  stories\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the', 'most', 'important', 'stories']\n","token_ids_seq:  []\n","Printing prob:  0.6601208502244278\n","label:  0\n","idx:  21\n","tok_flaw:  to\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the', 'most', 'important', 'stories', 'to']\n","token_ids_seq:  []\n","Printing prob:  0.7635438250459226\n","label:  0\n","idx:  22\n","tok_flaw:  be\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the', 'most', 'important', 'stories', 'to', 'be']\n","token_ids_seq:  []\n","Printing prob:  0.21768906658547538\n","label:  0\n","idx:  23\n","tok_flaw:  told\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the', 'most', 'important', 'stories', 'to', 'be', 'told']\n","token_ids_seq:  []\n","Printing prob:  0.48825989658925806\n","label:  0\n","idx:  24\n","tok_flaw:  in\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the', 'most', 'important', 'stories', 'to', 'be', 'told', 'in']\n","token_ids_seq:  []\n","Printing prob:  0.028186620837786003\n","label:  1\n","idx:  25\n","tok_flaw:  austrlia\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the', 'most', 'important', 'stories', 'to', 'be', 'told', 'in', 'austrlia']\n","token_ids_seq:  [25]\n","Printing prob:  0.6746985045930471\n","label:  0\n","idx:  26\n","tok_flaw:  's\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the', 'most', 'important', 'stories', 'to', 'be', 'told', 'in', 'austrlia', \"'s\"]\n","token_ids_seq:  [25]\n","Printing prob:  0.4448275772594251\n","label:  0\n","idx:  27\n","tok_flaw:  film\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the', 'most', 'important', 'stories', 'to', 'be', 'told', 'in', 'austrlia', \"'s\", 'film']\n","token_ids_seq:  [25]\n","Printing prob:  0.6645110328432474\n","label:  0\n","idx:  28\n","tok_flaw:  history\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the', 'most', 'important', 'stories', 'to', 'be', 'told', 'in', 'austrlia', \"'s\", 'film', 'history']\n","token_ids_seq:  [25]\n","Printing prob:  0.17145834614853384\n","label:  0\n","idx:  29\n","tok_flaw:  .\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the', 'most', 'important', 'stories', 'to', 'be', 'told', 'in', 'austrlia', \"'s\", 'film', 'history', '.']\n","token_ids_seq:  [25]\n","Printing prob:  0.9151153027997718\n","label:  0\n","idx:  30\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the', 'most', 'important', 'stories', 'to', 'be', 'told', 'in', 'austrlia', \"'s\", 'film', 'history', '.', \"''\"]\n","token_ids_seq:  [25]\n","all_flaw_tokens:  [['``', 'a', 'stunning', 'piece', 'of', 'visual', 'poetry', 'that', 'will', ',', 'hopefully', ',', 'be', 'remembered', 'as', 'one', 'of', 'the', 'most', 'important', 'stories', 'to', 'be', 'told', 'in', 'austrlia', \"'s\", 'film', 'history', '.', \"''\"]]\n","all_token_idx:  [[25]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.3658721248481812\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.413546580194598\n","label:  0\n","idx:  1\n","tok_flaw:  an\n","flaw_tokens_seq:  ['``', 'an']\n","token_ids_seq:  []\n","Printing prob:  0.11635525709406425\n","label:  1\n","idx:  2\n","tok_flaw:  tamusing\n","flaw_tokens_seq:  ['``', 'an', 'tamusing']\n","token_ids_seq:  [2]\n","Printing prob:  0.16340206361351728\n","label:  0\n","idx:  3\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'an', 'tamusing', ',']\n","token_ids_seq:  [2]\n","Printing prob:  0.8175658673978424\n","label:  0\n","idx:  4\n","tok_flaw:  breezily\n","flaw_tokens_seq:  ['``', 'an', 'tamusing', ',', 'breezily']\n","token_ids_seq:  [2]\n","Printing prob:  0.30204760857169577\n","label:  0\n","idx:  5\n","tok_flaw:  apolitical\n","flaw_tokens_seq:  ['``', 'an', 'tamusing', ',', 'breezily', 'apolitical']\n","token_ids_seq:  [2]\n","Printing prob:  0.4351749165155072\n","label:  0\n","idx:  6\n","tok_flaw:  documentary\n","flaw_tokens_seq:  ['``', 'an', 'tamusing', ',', 'breezily', 'apolitical', 'documentary']\n","token_ids_seq:  [2]\n","Printing prob:  0.8575047681352217\n","label:  0\n","idx:  7\n","tok_flaw:  about\n","flaw_tokens_seq:  ['``', 'an', 'tamusing', ',', 'breezily', 'apolitical', 'documentary', 'about']\n","token_ids_seq:  [2]\n","Printing prob:  0.3148983788967433\n","label:  0\n","idx:  8\n","tok_flaw:  life\n","flaw_tokens_seq:  ['``', 'an', 'tamusing', ',', 'breezily', 'apolitical', 'documentary', 'about', 'life']\n","token_ids_seq:  [2]\n","Printing prob:  0.9904604710424684\n","label:  0\n","idx:  9\n","tok_flaw:  on\n","flaw_tokens_seq:  ['``', 'an', 'tamusing', ',', 'breezily', 'apolitical', 'documentary', 'about', 'life', 'on']\n","token_ids_seq:  [2]\n","Printing prob:  0.42663057097715285\n","label:  0\n","idx:  10\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'an', 'tamusing', ',', 'breezily', 'apolitical', 'documentary', 'about', 'life', 'on', 'the']\n","token_ids_seq:  [2]\n","Printing prob:  0.44473198832954897\n","label:  0\n","idx:  11\n","tok_flaw:  campaign\n","flaw_tokens_seq:  ['``', 'an', 'tamusing', ',', 'breezily', 'apolitical', 'documentary', 'about', 'life', 'on', 'the', 'campaign']\n","token_ids_seq:  [2]\n","Printing prob:  0.9501759237897831\n","label:  0\n","idx:  12\n","tok_flaw:  trail\n","flaw_tokens_seq:  ['``', 'an', 'tamusing', ',', 'breezily', 'apolitical', 'documentary', 'about', 'life', 'on', 'the', 'campaign', 'trail']\n","token_ids_seq:  [2]\n","Printing prob:  0.5649902326653834\n","label:  0\n","idx:  13\n","tok_flaw:  .\n","flaw_tokens_seq:  ['``', 'an', 'tamusing', ',', 'breezily', 'apolitical', 'documentary', 'about', 'life', 'on', 'the', 'campaign', 'trail', '.']\n","token_ids_seq:  [2]\n","Printing prob:  0.019428276267119737\n","label:  1\n","idx:  14\n","tok_flaw:  'R'\n","flaw_tokens_seq:  ['``', 'an', 'tamusing', ',', 'breezily', 'apolitical', 'documentary', 'about', 'life', 'on', 'the', 'campaign', 'trail', '.', \"'R'\"]\n","token_ids_seq:  [2, 14]\n","all_flaw_tokens:  [['``', 'an', 'tamusing', ',', 'breezily', 'apolitical', 'documentary', 'about', 'life', 'on', 'the', 'campaign', 'trail', '.', \"'R'\"]]\n","all_token_idx:  [[2, 14]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.26226686904072594\n","label:  0\n","idx:  0\n","tok_flaw:  the\n","flaw_tokens_seq:  ['the']\n","token_ids_seq:  []\n","Printing prob:  0.964022978130118\n","label:  0\n","idx:  1\n","tok_flaw:  screenplay\n","flaw_tokens_seq:  ['the', 'screenplay']\n","token_ids_seq:  []\n","Printing prob:  0.4844037680340788\n","label:  0\n","idx:  2\n","tok_flaw:  sabotages\n","flaw_tokens_seq:  ['the', 'screenplay', 'sabotages']\n","token_ids_seq:  []\n","Printing prob:  0.25042494336934795\n","label:  0\n","idx:  3\n","tok_flaw:  the\n","flaw_tokens_seq:  ['the', 'screenplay', 'sabotages', 'the']\n","token_ids_seq:  []\n","Printing prob:  0.9414723730416256\n","label:  0\n","idx:  4\n","tok_flaw:  movie\n","flaw_tokens_seq:  ['the', 'screenplay', 'sabotages', 'the', 'movie']\n","token_ids_seq:  []\n","Printing prob:  0.6312342034899769\n","label:  0\n","idx:  5\n","tok_flaw:  's\n","flaw_tokens_seq:  ['the', 'screenplay', 'sabotages', 'the', 'movie', \"'s\"]\n","token_ids_seq:  []\n","Printing prob:  0.8710716597689698\n","label:  0\n","idx:  6\n","tok_flaw:  strengths\n","flaw_tokens_seq:  ['the', 'screenplay', 'sabotages', 'the', 'movie', \"'s\", 'strengths']\n","token_ids_seq:  []\n","Printing prob:  0.29112797308853977\n","label:  0\n","idx:  7\n","tok_flaw:  at\n","flaw_tokens_seq:  ['the', 'screenplay', 'sabotages', 'the', 'movie', \"'s\", 'strengths', 'at']\n","token_ids_seq:  []\n","Printing prob:  0.4504424375135426\n","label:  0\n","idx:  8\n","tok_flaw:  almost\n","flaw_tokens_seq:  ['the', 'screenplay', 'sabotages', 'the', 'movie', \"'s\", 'strengths', 'at', 'almost']\n","token_ids_seq:  []\n","Printing prob:  0.3704042636413182\n","label:  0\n","idx:  9\n","tok_flaw:  every\n","flaw_tokens_seq:  ['the', 'screenplay', 'sabotages', 'the', 'movie', \"'s\", 'strengths', 'at', 'almost', 'every']\n","token_ids_seq:  []\n","Printing prob:  0.08712581747435422\n","label:  1\n","idx:  10\n","tok_flaw:  junctupre\n","flaw_tokens_seq:  ['the', 'screenplay', 'sabotages', 'the', 'movie', \"'s\", 'strengths', 'at', 'almost', 'every', 'junctupre']\n","token_ids_seq:  [10]\n","Printing prob:  0.5158242152793806\n","label:  0\n","idx:  11\n","tok_flaw:  .\n","flaw_tokens_seq:  ['the', 'screenplay', 'sabotages', 'the', 'movie', \"'s\", 'strengths', 'at', 'almost', 'every', 'junctupre', '.']\n","token_ids_seq:  [10]\n","all_flaw_tokens:  [['the', 'screenplay', 'sabotages', 'the', 'movie', \"'s\", 'strengths', 'at', 'almost', 'every', 'junctupre', '.']]\n","all_token_idx:  [[10]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","attacks:  98% 1786/1820 [00:35<00:00, 46.47it/s]emb_dict:  None\n","embeddings: None\n","Printing prob:  0.7889902841484325\n","label:  0\n","idx:  0\n","tok_flaw:  this\n","flaw_tokens_seq:  ['this']\n","token_ids_seq:  []\n","Printing prob:  0.7580216322544583\n","label:  0\n","idx:  1\n","tok_flaw:  formulaic\n","flaw_tokens_seq:  ['this', 'formulaic']\n","token_ids_seq:  []\n","Printing prob:  0.20134540316127691\n","label:  0\n","idx:  2\n","tok_flaw:  chiller\n","flaw_tokens_seq:  ['this', 'formulaic', 'chiller']\n","token_ids_seq:  []\n","Printing prob:  0.07759627960744964\n","label:  1\n","idx:  3\n","tok_flaw:  wiLl\n","flaw_tokens_seq:  ['this', 'formulaic', 'chiller', 'wiLl']\n","token_ids_seq:  [3]\n","Printing prob:  0.42549894185119763\n","label:  0\n","idx:  4\n","tok_flaw:  do\n","flaw_tokens_seq:  ['this', 'formulaic', 'chiller', 'wiLl', 'do']\n","token_ids_seq:  [3]\n","Printing prob:  0.41294000386021856\n","label:  0\n","idx:  5\n","tok_flaw:  little\n","flaw_tokens_seq:  ['this', 'formulaic', 'chiller', 'wiLl', 'do', 'little']\n","token_ids_seq:  [3]\n","Printing prob:  0.24729664221448577\n","label:  0\n","idx:  6\n","tok_flaw:  to\n","flaw_tokens_seq:  ['this', 'formulaic', 'chiller', 'wiLl', 'do', 'little', 'to']\n","token_ids_seq:  [3]\n","Printing prob:  0.3154661099035755\n","label:  0\n","idx:  7\n","tok_flaw:  boost\n","flaw_tokens_seq:  ['this', 'formulaic', 'chiller', 'wiLl', 'do', 'little', 'to', 'boost']\n","token_ids_seq:  [3]\n","Printing prob:  0.5004413821638617\n","label:  0\n","idx:  8\n","tok_flaw:  stallone\n","flaw_tokens_seq:  ['this', 'formulaic', 'chiller', 'wiLl', 'do', 'little', 'to', 'boost', 'stallone']\n","token_ids_seq:  [3]\n","Printing prob:  0.03126208964591304\n","label:  1\n","idx:  9\n","tok_flaw:  Js\n","flaw_tokens_seq:  ['this', 'formulaic', 'chiller', 'wiLl', 'do', 'little', 'to', 'boost', 'stallone', 'Js']\n","token_ids_seq:  [3, 9]\n","Printing prob:  0.8397614498775483\n","label:  0\n","idx:  10\n","tok_flaw:  career\n","flaw_tokens_seq:  ['this', 'formulaic', 'chiller', 'wiLl', 'do', 'little', 'to', 'boost', 'stallone', 'Js', 'career']\n","token_ids_seq:  [3, 9]\n","Printing prob:  0.9665309587222918\n","label:  0\n","idx:  11\n","tok_flaw:  .\n","flaw_tokens_seq:  ['this', 'formulaic', 'chiller', 'wiLl', 'do', 'little', 'to', 'boost', 'stallone', 'Js', 'career', '.']\n","token_ids_seq:  [3, 9]\n","all_flaw_tokens:  [['this', 'formulaic', 'chiller', 'wiLl', 'do', 'little', 'to', 'boost', 'stallone', 'Js', 'career', '.']]\n","all_token_idx:  [[3, 9]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.49136271425282063\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.3603559399708518\n","label:  0\n","idx:  1\n","tok_flaw:  these\n","flaw_tokens_seq:  ['``', 'these']\n","token_ids_seq:  []\n","Printing prob:  0.26420581887846917\n","label:  0\n","idx:  2\n","tok_flaw:  are\n","flaw_tokens_seq:  ['``', 'these', 'are']\n","token_ids_seq:  []\n","Printing prob:  0.992690505518951\n","label:  0\n","idx:  3\n","tok_flaw:  names\n","flaw_tokens_seq:  ['``', 'these', 'are', 'names']\n","token_ids_seq:  []\n","Printing prob:  0.6841055197270793\n","label:  0\n","idx:  4\n","tok_flaw:  to\n","flaw_tokens_seq:  ['``', 'these', 'are', 'names', 'to']\n","token_ids_seq:  []\n","Printing prob:  0.33507606259967004\n","label:  0\n","idx:  5\n","tok_flaw:  remember\n","flaw_tokens_seq:  ['``', 'these', 'are', 'names', 'to', 'remember']\n","token_ids_seq:  []\n","Printing prob:  0.5833702179800571\n","label:  0\n","idx:  6\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'these', 'are', 'names', 'to', 'remember', ',']\n","token_ids_seq:  []\n","Printing prob:  0.9797714866556324\n","label:  0\n","idx:  7\n","tok_flaw:  in\n","flaw_tokens_seq:  ['``', 'these', 'are', 'names', 'to', 'remember', ',', 'in']\n","token_ids_seq:  []\n","Printing prob:  0.01112248941914995\n","label:  1\n","idx:  8\n","tok_flaw:  ordeD\n","flaw_tokens_seq:  ['``', 'these', 'are', 'names', 'to', 'remember', ',', 'in', 'ordeD']\n","token_ids_seq:  [8]\n","Printing prob:  0.4976043627971479\n","label:  0\n","idx:  9\n","tok_flaw:  to\n","flaw_tokens_seq:  ['``', 'these', 'are', 'names', 'to', 'remember', ',', 'in', 'ordeD', 'to']\n","token_ids_seq:  [8]\n","Printing prob:  0.631136745908296\n","label:  0\n","idx:  10\n","tok_flaw:  avoid\n","flaw_tokens_seq:  ['``', 'these', 'are', 'names', 'to', 'remember', ',', 'in', 'ordeD', 'to', 'avoid']\n","token_ids_seq:  [8]\n","Printing prob:  0.18784250274827452\n","label:  0\n","idx:  11\n","tok_flaw:  them\n","flaw_tokens_seq:  ['``', 'these', 'are', 'names', 'to', 'remember', ',', 'in', 'ordeD', 'to', 'avoid', 'them']\n","token_ids_seq:  [8]\n","Printing prob:  0.7875146736070784\n","label:  0\n","idx:  12\n","tok_flaw:  in\n","flaw_tokens_seq:  ['``', 'these', 'are', 'names', 'to', 'remember', ',', 'in', 'ordeD', 'to', 'avoid', 'them', 'in']\n","token_ids_seq:  [8]\n","Printing prob:  0.35234764702984833\n","label:  0\n","idx:  13\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'these', 'are', 'names', 'to', 'remember', ',', 'in', 'ordeD', 'to', 'avoid', 'them', 'in', 'the']\n","token_ids_seq:  [8]\n","Printing prob:  0.3519936907356088\n","label:  0\n","idx:  14\n","tok_flaw:  future\n","flaw_tokens_seq:  ['``', 'these', 'are', 'names', 'to', 'remember', ',', 'in', 'ordeD', 'to', 'avoid', 'them', 'in', 'the', 'future']\n","token_ids_seq:  [8]\n","Printing prob:  0.13053516185705794\n","label:  0\n","idx:  15\n","tok_flaw:  .\n","flaw_tokens_seq:  ['``', 'these', 'are', 'names', 'to', 'remember', ',', 'in', 'ordeD', 'to', 'avoid', 'them', 'in', 'the', 'future', '.']\n","token_ids_seq:  [8]\n","Printing prob:  0.6492147985460831\n","label:  0\n","idx:  16\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', 'these', 'are', 'names', 'to', 'remember', ',', 'in', 'ordeD', 'to', 'avoid', 'them', 'in', 'the', 'future', '.', \"''\"]\n","token_ids_seq:  [8]\n","all_flaw_tokens:  [['``', 'these', 'are', 'names', 'to', 'remember', ',', 'in', 'ordeD', 'to', 'avoid', 'them', 'in', 'the', 'future', '.', \"''\"]]\n","all_token_idx:  [[8]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.9747432182005278\n","label:  0\n","idx:  0\n","tok_flaw:  to\n","flaw_tokens_seq:  ['to']\n","token_ids_seq:  []\n","Printing prob:  0.5895647155845701\n","label:  0\n","idx:  1\n","tok_flaw:  imagine\n","flaw_tokens_seq:  ['to', 'imagine']\n","token_ids_seq:  []\n","Printing prob:  0.4141365585639888\n","label:  0\n","idx:  2\n","tok_flaw:  the\n","flaw_tokens_seq:  ['to', 'imagine', 'the']\n","token_ids_seq:  []\n","Printing prob:  0.6365503009006027\n","label:  0\n","idx:  3\n","tok_flaw:  life\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life']\n","token_ids_seq:  []\n","Printing prob:  0.060298703550208055\n","label:  1\n","idx:  4\n","tok_flaw:  f\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f']\n","token_ids_seq:  [4]\n","Printing prob:  0.3111323989242315\n","label:  0\n","idx:  5\n","tok_flaw:  harry\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry']\n","token_ids_seq:  [4]\n","Printing prob:  0.1435830587582726\n","label:  0\n","idx:  6\n","tok_flaw:  potter\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter']\n","token_ids_seq:  [4]\n","Printing prob:  0.6741731645987935\n","label:  0\n","idx:  7\n","tok_flaw:  as\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as']\n","token_ids_seq:  [4]\n","Printing prob:  0.10882546946493499\n","label:  1\n","idx:  8\n","tok_flaw:  Ga\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga']\n","token_ids_seq:  [4, 8]\n","Printing prob:  0.08950038294490525\n","label:  1\n","idx:  9\n","tok_flaw:  artial\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial']\n","token_ids_seq:  [4, 8, 9]\n","Printing prob:  0.8995596887929571\n","label:  0\n","idx:  10\n","tok_flaw:  arts\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts']\n","token_ids_seq:  [4, 8, 9]\n","Printing prob:  0.17624013939144412\n","label:  0\n","idx:  11\n","tok_flaw:  adventure\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure']\n","token_ids_seq:  [4, 8, 9]\n","Printing prob:  0.7049523312874896\n","label:  0\n","idx:  12\n","tok_flaw:  told\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told']\n","token_ids_seq:  [4, 8, 9]\n","Printing prob:  0.9037486029775424\n","label:  0\n","idx:  13\n","tok_flaw:  by\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by']\n","token_ids_seq:  [4, 8, 9]\n","Printing prob:  0.47092760574886405\n","label:  0\n","idx:  14\n","tok_flaw:  a\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a']\n","token_ids_seq:  [4, 8, 9]\n","Printing prob:  0.07586980835410984\n","label:  1\n","idx:  15\n","tok_flaw:  lobotkmized\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized']\n","token_ids_seq:  [4, 8, 9, 15]\n","Printing prob:  0.02792768631481002\n","label:  1\n","idx:  16\n","tok_flaw:  woCdy\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy']\n","token_ids_seq:  [4, 8, 9, 15, 16]\n","Printing prob:  0.107354927368435\n","label:  1\n","idx:  17\n","tok_flaw:  alle\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17]\n","Printing prob:  0.23734120842023076\n","label:  0\n","idx:  18\n","tok_flaw:  is\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17]\n","Printing prob:  0.18229096418224033\n","label:  0\n","idx:  19\n","tok_flaw:  to\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17]\n","Printing prob:  0.15277740458890832\n","label:  0\n","idx:  20\n","tok_flaw:  have\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17]\n","Printing prob:  0.7792598693507655\n","label:  0\n","idx:  21\n","tok_flaw:  some\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17]\n","Printing prob:  0.7763510458561923\n","label:  0\n","idx:  22\n","tok_flaw:  idea\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17]\n","Printing prob:  0.9238733541266941\n","label:  0\n","idx:  23\n","tok_flaw:  of\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17]\n","Printing prob:  0.8677737681629701\n","label:  0\n","idx:  24\n","tok_flaw:  the\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17]\n","Printing prob:  0.4650855099031631\n","label:  0\n","idx:  25\n","tok_flaw:  fate\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17]\n","Printing prob:  0.6878716266741506\n","label:  0\n","idx:  26\n","tok_flaw:  that\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17]\n","Printing prob:  0.28289205275412554\n","label:  0\n","idx:  27\n","tok_flaw:  lies\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17]\n","Printing prob:  0.4081777307052121\n","label:  0\n","idx:  28\n","tok_flaw:  in\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17]\n","Printing prob:  0.026161531831902507\n","label:  1\n","idx:  29\n","tok_flaw:  sVtore\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29]\n","Printing prob:  0.9005653720182463\n","label:  0\n","idx:  30\n","tok_flaw:  for\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29]\n","Printing prob:  0.5669962626707771\n","label:  0\n","idx:  31\n","tok_flaw:  moviegoers\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29]\n","Printing prob:  0.15588483587017254\n","label:  0\n","idx:  32\n","tok_flaw:  lured\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers', 'lured']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29]\n","Printing prob:  0.6191415757265931\n","label:  0\n","idx:  33\n","tok_flaw:  to\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers', 'lured', 'to']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29]\n","Printing prob:  0.172264234530647\n","label:  0\n","idx:  34\n","tok_flaw:  the\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers', 'lured', 'to', 'the']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29]\n","Printing prob:  0.4487679269377577\n","label:  0\n","idx:  35\n","tok_flaw:  mediocrity\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers', 'lured', 'to', 'the', 'mediocrity']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29]\n","Printing prob:  0.015555629051880016\n","label:  1\n","idx:  36\n","tok_flaw:  hat\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers', 'lured', 'to', 'the', 'mediocrity', 'hat']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29, 36]\n","Printing prob:  0.021471106091635717\n","label:  1\n","idx:  37\n","tok_flaw:  i\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers', 'lured', 'to', 'the', 'mediocrity', 'hat', 'i']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29, 36, 37]\n","Printing prob:  0.06700324839282568\n","label:  1\n","idx:  38\n","tok_flaw:  kuQng\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers', 'lured', 'to', 'the', 'mediocrity', 'hat', 'i', 'kuQng']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29, 36, 37, 38]\n","Printing prob:  0.6061404252571377\n","label:  0\n","idx:  39\n","tok_flaw:  pow\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers', 'lured', 'to', 'the', 'mediocrity', 'hat', 'i', 'kuQng', 'pow']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29, 36, 37, 38]\n","Printing prob:  0.17927908672337167\n","label:  0\n","idx:  40\n","tok_flaw:  :\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers', 'lured', 'to', 'the', 'mediocrity', 'hat', 'i', 'kuQng', 'pow', ':']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29, 36, 37, 38]\n","Printing prob:  0.09279202623305582\n","label:  1\n","idx:  41\n","tok_flaw:  ente\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers', 'lured', 'to', 'the', 'mediocrity', 'hat', 'i', 'kuQng', 'pow', ':', 'ente']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29, 36, 37, 38, 41]\n","Printing prob:  0.823312309339888\n","label:  0\n","idx:  42\n","tok_flaw:  the\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers', 'lured', 'to', 'the', 'mediocrity', 'hat', 'i', 'kuQng', 'pow', ':', 'ente', 'the']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29, 36, 37, 38, 41]\n","Printing prob:  0.851828488199484\n","label:  0\n","idx:  43\n","tok_flaw:  fist\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers', 'lured', 'to', 'the', 'mediocrity', 'hat', 'i', 'kuQng', 'pow', ':', 'ente', 'the', 'fist']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29, 36, 37, 38, 41]\n","Printing prob:  0.8737693471620039\n","label:  0\n","idx:  44\n","tok_flaw:  .\n","flaw_tokens_seq:  ['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers', 'lured', 'to', 'the', 'mediocrity', 'hat', 'i', 'kuQng', 'pow', ':', 'ente', 'the', 'fist', '.']\n","token_ids_seq:  [4, 8, 9, 15, 16, 17, 29, 36, 37, 38, 41]\n","all_flaw_tokens:  [['to', 'imagine', 'the', 'life', 'f', 'harry', 'potter', 'as', 'Ga', 'artial', 'arts', 'adventure', 'told', 'by', 'a', 'lobotkmized', 'woCdy', 'alle', 'is', 'to', 'have', 'some', 'idea', 'of', 'the', 'fate', 'that', 'lies', 'in', 'sVtore', 'for', 'moviegoers', 'lured', 'to', 'the', 'mediocrity', 'hat', 'i', 'kuQng', 'pow', ':', 'ente', 'the', 'fist', '.']]\n","all_token_idx:  [[4, 8, 9, 15, 16, 17, 29, 36, 37, 38, 41]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.05063545255586166\n","label:  1\n","idx:  0\n","tok_flaw:  windtalKers\n","flaw_tokens_seq:  ['windtalKers']\n","token_ids_seq:  [0]\n","Printing prob:  0.9585319082662196\n","label:  0\n","idx:  1\n","tok_flaw:  celebrates\n","flaw_tokens_seq:  ['windtalKers', 'celebrates']\n","token_ids_seq:  [0]\n","Printing prob:  0.8966617311007812\n","label:  0\n","idx:  2\n","tok_flaw:  the\n","flaw_tokens_seq:  ['windtalKers', 'celebrates', 'the']\n","token_ids_seq:  [0]\n","Printing prob:  0.9837446310126038\n","label:  0\n","idx:  3\n","tok_flaw:  human\n","flaw_tokens_seq:  ['windtalKers', 'celebrates', 'the', 'human']\n","token_ids_seq:  [0]\n","Printing prob:  0.10539467613041353\n","label:  1\n","idx:  4\n","tok_flaw:  sXpirit\n","flaw_tokens_seq:  ['windtalKers', 'celebrates', 'the', 'human', 'sXpirit']\n","token_ids_seq:  [0, 4]\n","Printing prob:  0.8062426284867628\n","label:  0\n","idx:  5\n","tok_flaw:  and\n","flaw_tokens_seq:  ['windtalKers', 'celebrates', 'the', 'human', 'sXpirit', 'and']\n","token_ids_seq:  [0, 4]\n","Printing prob:  0.7162147521019829\n","label:  0\n","idx:  6\n","tok_flaw:  packs\n","flaw_tokens_seq:  ['windtalKers', 'celebrates', 'the', 'human', 'sXpirit', 'and', 'packs']\n","token_ids_seq:  [0, 4]\n","Printing prob:  0.09857222710775315\n","label:  1\n","idx:  7\n","tok_flaw:  van\n","flaw_tokens_seq:  ['windtalKers', 'celebrates', 'the', 'human', 'sXpirit', 'and', 'packs', 'van']\n","token_ids_seq:  [0, 4, 7]\n","Printing prob:  0.46695973978885874\n","label:  0\n","idx:  8\n","tok_flaw:  emotional\n","flaw_tokens_seq:  ['windtalKers', 'celebrates', 'the', 'human', 'sXpirit', 'and', 'packs', 'van', 'emotional']\n","token_ids_seq:  [0, 4, 7]\n","Printing prob:  0.10304473378453849\n","label:  1\n","idx:  9\n","tok_flaw:  wallorp\n","flaw_tokens_seq:  ['windtalKers', 'celebrates', 'the', 'human', 'sXpirit', 'and', 'packs', 'van', 'emotional', 'wallorp']\n","token_ids_seq:  [0, 4, 7, 9]\n","Printing prob:  0.08878962537498813\n","label:  1\n","idx:  10\n","tok_flaw:  B\n","flaw_tokens_seq:  ['windtalKers', 'celebrates', 'the', 'human', 'sXpirit', 'and', 'packs', 'van', 'emotional', 'wallorp', 'B']\n","token_ids_seq:  [0, 4, 7, 9, 10]\n","all_flaw_tokens:  [['windtalKers', 'celebrates', 'the', 'human', 'sXpirit', 'and', 'packs', 'van', 'emotional', 'wallorp', 'B']]\n","all_token_idx:  [[0, 4, 7, 9, 10]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.9570357439145964\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.1802840488839802\n","label:  0\n","idx:  1\n","tok_flaw:  visits\n","flaw_tokens_seq:  ['``', 'visits']\n","token_ids_seq:  []\n","Printing prob:  0.5521797327689725\n","label:  0\n","idx:  2\n","tok_flaw:  spy-movie\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie']\n","token_ids_seq:  []\n","Printing prob:  0.39247751280963616\n","label:  0\n","idx:  3\n","tok_flaw:  territory\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory']\n","token_ids_seq:  []\n","Printing prob:  0.20317971320269135\n","label:  0\n","idx:  4\n","tok_flaw:  like\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like']\n","token_ids_seq:  []\n","Printing prob:  0.7677470490094251\n","label:  0\n","idx:  5\n","tok_flaw:  a\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a']\n","token_ids_seq:  []\n","Printing prob:  0.7305163861405284\n","label:  0\n","idx:  6\n","tok_flaw:  novel\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel']\n","token_ids_seq:  []\n","Printing prob:  0.973060723386308\n","label:  0\n","idx:  7\n","tok_flaw:  you\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you']\n","token_ids_seq:  []\n","Printing prob:  0.4449865876475818\n","label:  0\n","idx:  8\n","tok_flaw:  ca\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca']\n","token_ids_seq:  []\n","Printing prob:  0.45691830197746963\n","label:  0\n","idx:  9\n","tok_flaw:  n't\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\"]\n","token_ids_seq:  []\n","Printing prob:  0.20673729734629942\n","label:  0\n","idx:  10\n","tok_flaw:  put\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put']\n","token_ids_seq:  []\n","Printing prob:  0.26036360686379434\n","label:  0\n","idx:  11\n","tok_flaw:  down\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down']\n","token_ids_seq:  []\n","Printing prob:  0.5198345520807272\n","label:  0\n","idx:  12\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',']\n","token_ids_seq:  []\n","Printing prob:  0.15707865245810526\n","label:  0\n","idx:  13\n","tok_flaw:  examines\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines']\n","token_ids_seq:  []\n","Printing prob:  0.11712949818596607\n","label:  1\n","idx:  14\n","tok_flaw:  P\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P']\n","token_ids_seq:  [14]\n","Printing prob:  0.06930880200208267\n","label:  1\n","idx:  15\n","tok_flaw:  foonote\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.5433607206947068\n","label:  0\n","idx:  16\n","tok_flaw:  to\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.30606111585490636\n","label:  0\n","idx:  17\n","tok_flaw:  history\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.8963003133607286\n","label:  0\n","idx:  18\n","tok_flaw:  seldom\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.1852158897667341\n","label:  0\n","idx:  19\n","tok_flaw:  brought\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.9439045659515535\n","label:  0\n","idx:  20\n","tok_flaw:  to\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.6328742759404684\n","label:  0\n","idx:  21\n","tok_flaw:  light\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.5466628897599167\n","label:  0\n","idx:  22\n","tok_flaw:  on\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.9138265793161402\n","label:  0\n","idx:  23\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.38807263555262017\n","label:  0\n","idx:  24\n","tok_flaw:  screen\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the', 'screen']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.1743180287845849\n","label:  0\n","idx:  25\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the', 'screen', ',']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.975934254056449\n","label:  0\n","idx:  26\n","tok_flaw:  and\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the', 'screen', ',', 'and']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.7245932155530166\n","label:  0\n","idx:  27\n","tok_flaw:  keeps\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the', 'screen', ',', 'and', 'keeps']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.04139029465159194\n","label:  1\n","idx:  28\n","tok_flaw:  ou\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the', 'screen', ',', 'and', 'keeps', 'ou']\n","token_ids_seq:  [14, 15, 28]\n","Printing prob:  0.738264064689049\n","label:  0\n","idx:  29\n","tok_flaw:  guessing\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the', 'screen', ',', 'and', 'keeps', 'ou', 'guessing']\n","token_ids_seq:  [14, 15, 28]\n","Printing prob:  0.67019583663362\n","label:  0\n","idx:  30\n","tok_flaw:  from\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the', 'screen', ',', 'and', 'keeps', 'ou', 'guessing', 'from']\n","token_ids_seq:  [14, 15, 28]\n","Printing prob:  0.16328982087367694\n","label:  0\n","idx:  31\n","tok_flaw:  first\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the', 'screen', ',', 'and', 'keeps', 'ou', 'guessing', 'from', 'first']\n","token_ids_seq:  [14, 15, 28]\n","Printing prob:  0.17646881307840145\n","label:  0\n","idx:  32\n","tok_flaw:  frame\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the', 'screen', ',', 'and', 'keeps', 'ou', 'guessing', 'from', 'first', 'frame']\n","token_ids_seq:  [14, 15, 28]\n","Printing prob:  0.29325689372086194\n","label:  0\n","idx:  33\n","tok_flaw:  to\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the', 'screen', ',', 'and', 'keeps', 'ou', 'guessing', 'from', 'first', 'frame', 'to']\n","token_ids_seq:  [14, 15, 28]\n","Printing prob:  0.42141851909331796\n","label:  0\n","idx:  34\n","tok_flaw:  last\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the', 'screen', ',', 'and', 'keeps', 'ou', 'guessing', 'from', 'first', 'frame', 'to', 'last']\n","token_ids_seq:  [14, 15, 28]\n","Printing prob:  0.5585858353086421\n","label:  0\n","idx:  35\n","tok_flaw:  .\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the', 'screen', ',', 'and', 'keeps', 'ou', 'guessing', 'from', 'first', 'frame', 'to', 'last', '.']\n","token_ids_seq:  [14, 15, 28]\n","Printing prob:  0.5843653330795059\n","label:  0\n","idx:  36\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the', 'screen', ',', 'and', 'keeps', 'ou', 'guessing', 'from', 'first', 'frame', 'to', 'last', '.', \"''\"]\n","token_ids_seq:  [14, 15, 28]\n","all_flaw_tokens:  [['``', 'visits', 'spy-movie', 'territory', 'like', 'a', 'novel', 'you', 'ca', \"n't\", 'put', 'down', ',', 'examines', 'P', 'foonote', 'to', 'history', 'seldom', 'brought', 'to', 'light', 'on', 'the', 'screen', ',', 'and', 'keeps', 'ou', 'guessing', 'from', 'first', 'frame', 'to', 'last', '.', \"''\"]]\n","all_token_idx:  [[14, 15, 28]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","attacks:  98% 1791/1820 [00:35<00:00, 46.68it/s]emb_dict:  None\n","embeddings: None\n","Printing prob:  0.333233805974381\n","label:  0\n","idx:  0\n","tok_flaw:  i\n","flaw_tokens_seq:  ['i']\n","token_ids_seq:  []\n","Printing prob:  0.04229084297137953\n","label:  1\n","idx:  1\n","tok_flaw:  ory\n","flaw_tokens_seq:  ['i', 'ory']\n","token_ids_seq:  [1]\n","Printing prob:  0.46493248116618024\n","label:  0\n","idx:  2\n","tok_flaw:  for\n","flaw_tokens_seq:  ['i', 'ory', 'for']\n","token_ids_seq:  [1]\n","Printing prob:  0.6575333527589333\n","label:  0\n","idx:  3\n","tok_flaw:  i\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i']\n","token_ids_seq:  [1]\n","Printing prob:  0.730227000095147\n","label:  0\n","idx:  4\n","tok_flaw:  spy\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy']\n","token_ids_seq:  [1]\n","Printing prob:  0.384346567395939\n","label:  0\n","idx:  5\n","tok_flaw:  --\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--']\n","token_ids_seq:  [1]\n","Printing prob:  0.601914747368422\n","label:  0\n","idx:  6\n","tok_flaw:  or\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or']\n","token_ids_seq:  [1]\n","Printing prob:  0.1041415142732639\n","label:  1\n","idx:  7\n","tok_flaw:  Ji\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.7927240855279133\n","label:  0\n","idx:  8\n","tok_flaw:  would\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.36393510185663625\n","label:  0\n","idx:  9\n","tok_flaw:  if\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.4584635823294606\n","label:  0\n","idx:  10\n","tok_flaw:  this\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.8604839373428428\n","label:  0\n","idx:  11\n","tok_flaw:  latest\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.1617284582450087\n","label:  0\n","idx:  12\n","tok_flaw:  and\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.9024168682748014\n","label:  0\n","idx:  13\n","tok_flaw:  laziest\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.2864853284867108\n","label:  0\n","idx:  14\n","tok_flaw:  imaginable\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.08959747664651296\n","label:  1\n","idx:  15\n","tok_flaw:  lof\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof']\n","token_ids_seq:  [1, 7, 15]\n","Printing prob:  0.24509221533660053\n","label:  0\n","idx:  16\n","tok_flaw:  all\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all']\n","token_ids_seq:  [1, 7, 15]\n","Printing prob:  0.6293598851600548\n","label:  0\n","idx:  17\n","tok_flaw:  vintage-tv\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all', 'vintage-tv']\n","token_ids_seq:  [1, 7, 15]\n","Printing prob:  0.8391791989895031\n","label:  0\n","idx:  18\n","tok_flaw:  spinoffs\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all', 'vintage-tv', 'spinoffs']\n","token_ids_seq:  [1, 7, 15]\n","Printing prob:  0.4160324013961124\n","label:  0\n","idx:  19\n","tok_flaw:  were\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all', 'vintage-tv', 'spinoffs', 'were']\n","token_ids_seq:  [1, 7, 15]\n","Printing prob:  0.5099240614052227\n","label:  0\n","idx:  20\n","tok_flaw:  capable\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all', 'vintage-tv', 'spinoffs', 'were', 'capable']\n","token_ids_seq:  [1, 7, 15]\n","Printing prob:  0.7565274451481506\n","label:  0\n","idx:  21\n","tok_flaw:  of\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all', 'vintage-tv', 'spinoffs', 'were', 'capable', 'of']\n","token_ids_seq:  [1, 7, 15]\n","Printing prob:  0.14240664091576571\n","label:  0\n","idx:  22\n","tok_flaw:  engendering\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all', 'vintage-tv', 'spinoffs', 'were', 'capable', 'of', 'engendering']\n","token_ids_seq:  [1, 7, 15]\n","Printing prob:  0.8031767574813814\n","label:  0\n","idx:  23\n","tok_flaw:  an\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all', 'vintage-tv', 'spinoffs', 'were', 'capable', 'of', 'engendering', 'an']\n","token_ids_seq:  [1, 7, 15]\n","Printing prob:  0.9153214771024336\n","label:  0\n","idx:  24\n","tok_flaw:  emotional\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all', 'vintage-tv', 'spinoffs', 'were', 'capable', 'of', 'engendering', 'an', 'emotional']\n","token_ids_seq:  [1, 7, 15]\n","Printing prob:  0.34483707081788173\n","label:  0\n","idx:  25\n","tok_flaw:  response\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all', 'vintage-tv', 'spinoffs', 'were', 'capable', 'of', 'engendering', 'an', 'emotional', 'response']\n","token_ids_seq:  [1, 7, 15]\n","Printing prob:  0.08658484113650489\n","label:  1\n","idx:  26\n","tok_flaw:  f\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all', 'vintage-tv', 'spinoffs', 'were', 'capable', 'of', 'engendering', 'an', 'emotional', 'response', 'f']\n","token_ids_seq:  [1, 7, 15, 26]\n","Printing prob:  0.6752682356370979\n","label:  0\n","idx:  27\n","tok_flaw:  any\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all', 'vintage-tv', 'spinoffs', 'were', 'capable', 'of', 'engendering', 'an', 'emotional', 'response', 'f', 'any']\n","token_ids_seq:  [1, 7, 15, 26]\n","Printing prob:  0.6879118864924034\n","label:  0\n","idx:  28\n","tok_flaw:  kind\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all', 'vintage-tv', 'spinoffs', 'were', 'capable', 'of', 'engendering', 'an', 'emotional', 'response', 'f', 'any', 'kind']\n","token_ids_seq:  [1, 7, 15, 26]\n","Printing prob:  0.8855741600362556\n","label:  0\n","idx:  29\n","tok_flaw:  .\n","flaw_tokens_seq:  ['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all', 'vintage-tv', 'spinoffs', 'were', 'capable', 'of', 'engendering', 'an', 'emotional', 'response', 'f', 'any', 'kind', '.']\n","token_ids_seq:  [1, 7, 15, 26]\n","all_flaw_tokens:  [['i', 'ory', 'for', 'i', 'spy', '--', 'or', 'Ji', 'would', 'if', 'this', 'latest', 'and', 'laziest', 'imaginable', 'lof', 'all', 'vintage-tv', 'spinoffs', 'were', 'capable', 'of', 'engendering', 'an', 'emotional', 'response', 'f', 'any', 'kind', '.']]\n","all_token_idx:  [[1, 7, 15, 26]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.7125144567685447\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.8189741648499214\n","label:  0\n","idx:  1\n","tok_flaw:  ...\n","flaw_tokens_seq:  ['``', '...']\n","token_ids_seq:  []\n","Printing prob:  0.9290908962138258\n","label:  0\n","idx:  2\n","tok_flaw:  just\n","flaw_tokens_seq:  ['``', '...', 'just']\n","token_ids_seq:  []\n","Printing prob:  0.17094339467649133\n","label:  0\n","idx:  3\n","tok_flaw:  a\n","flaw_tokens_seq:  ['``', '...', 'just', 'a']\n","token_ids_seq:  []\n","Printing prob:  0.6166871537320092\n","label:  0\n","idx:  4\n","tok_flaw:  big\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big']\n","token_ids_seq:  []\n","Printing prob:  0.6983735348039458\n","label:  0\n","idx:  5\n","tok_flaw:  mess\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess']\n","token_ids_seq:  []\n","Printing prob:  0.5239653385324244\n","label:  0\n","idx:  6\n","tok_flaw:  of\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of']\n","token_ids_seq:  []\n","Printing prob:  0.15942223862344151\n","label:  0\n","idx:  7\n","tok_flaw:  a\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a']\n","token_ids_seq:  []\n","Printing prob:  0.5209410083859516\n","label:  0\n","idx:  8\n","tok_flaw:  movie\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie']\n","token_ids_seq:  []\n","Printing prob:  0.28717971703811707\n","label:  0\n","idx:  9\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',']\n","token_ids_seq:  []\n","Printing prob:  0.7854324553017664\n","label:  0\n","idx:  10\n","tok_flaw:  full\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',', 'full']\n","token_ids_seq:  []\n","Printing prob:  0.5832473248261074\n","label:  0\n","idx:  11\n","tok_flaw:  of\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',', 'full', 'of']\n","token_ids_seq:  []\n","Printing prob:  0.6364428982222553\n","label:  0\n","idx:  12\n","tok_flaw:  images\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',', 'full', 'of', 'images']\n","token_ids_seq:  []\n","Printing prob:  0.9567252488426973\n","label:  0\n","idx:  13\n","tok_flaw:  and\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',', 'full', 'of', 'images', 'and']\n","token_ids_seq:  []\n","Printing prob:  0.3002738463925523\n","label:  0\n","idx:  14\n","tok_flaw:  events\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',', 'full', 'of', 'images', 'and', 'events']\n","token_ids_seq:  []\n","Printing prob:  0.726386104463038\n","label:  0\n","idx:  15\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',', 'full', 'of', 'images', 'and', 'events', ',']\n","token_ids_seq:  []\n","Printing prob:  0.16646232155647867\n","label:  0\n","idx:  16\n","tok_flaw:  but\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',', 'full', 'of', 'images', 'and', 'events', ',', 'but']\n","token_ids_seq:  []\n","Printing prob:  0.4119266192163431\n","label:  0\n","idx:  17\n","tok_flaw:  no\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',', 'full', 'of', 'images', 'and', 'events', ',', 'but', 'no']\n","token_ids_seq:  []\n","Printing prob:  0.23138375609008577\n","label:  0\n","idx:  18\n","tok_flaw:  tension\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',', 'full', 'of', 'images', 'and', 'events', ',', 'but', 'no', 'tension']\n","token_ids_seq:  []\n","Printing prob:  0.02395690126586536\n","label:  1\n","idx:  19\n","tok_flaw:  o\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',', 'full', 'of', 'images', 'and', 'events', ',', 'but', 'no', 'tension', 'o']\n","token_ids_seq:  [19]\n","Printing prob:  0.29055896624094857\n","label:  0\n","idx:  20\n","tok_flaw:  surprise\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',', 'full', 'of', 'images', 'and', 'events', ',', 'but', 'no', 'tension', 'o', 'surprise']\n","token_ids_seq:  [19]\n","Printing prob:  0.19471102183591416\n","label:  0\n","idx:  21\n","tok_flaw:  .\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',', 'full', 'of', 'images', 'and', 'events', ',', 'but', 'no', 'tension', 'o', 'surprise', '.']\n","token_ids_seq:  [19]\n","Printing prob:  0.29285529108145125\n","label:  0\n","idx:  22\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',', 'full', 'of', 'images', 'and', 'events', ',', 'but', 'no', 'tension', 'o', 'surprise', '.', \"''\"]\n","token_ids_seq:  [19]\n","all_flaw_tokens:  [['``', '...', 'just', 'a', 'big', 'mess', 'of', 'a', 'movie', ',', 'full', 'of', 'images', 'and', 'events', ',', 'but', 'no', 'tension', 'o', 'surprise', '.', \"''\"]]\n","all_token_idx:  [[19]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.12060895916785186\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.16793974820119173\n","label:  0\n","idx:  1\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'the']\n","token_ids_seq:  []\n","Printing prob:  0.8295097421075395\n","label:  0\n","idx:  2\n","tok_flaw:  editing\n","flaw_tokens_seq:  ['``', 'the', 'editing']\n","token_ids_seq:  []\n","Printing prob:  0.7503272767449871\n","label:  0\n","idx:  3\n","tok_flaw:  is\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is']\n","token_ids_seq:  []\n","Printing prob:  0.14232565274607734\n","label:  0\n","idx:  4\n","tok_flaw:  chaotic\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic']\n","token_ids_seq:  []\n","Printing prob:  0.12910177085529417\n","label:  0\n","idx:  5\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',']\n","token_ids_seq:  []\n","Printing prob:  0.5302802535928657\n","label:  0\n","idx:  6\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the']\n","token_ids_seq:  []\n","Printing prob:  0.9034355764160839\n","label:  0\n","idx:  7\n","tok_flaw:  photography\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography']\n","token_ids_seq:  []\n","Printing prob:  0.8678421307522681\n","label:  0\n","idx:  8\n","tok_flaw:  grainy\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy']\n","token_ids_seq:  []\n","Printing prob:  0.8562820207959078\n","label:  0\n","idx:  9\n","tok_flaw:  and\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and']\n","token_ids_seq:  []\n","Printing prob:  0.24860027493267\n","label:  0\n","idx:  10\n","tok_flaw:  badly\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly']\n","token_ids_seq:  []\n","Printing prob:  0.5776460466649014\n","label:  0\n","idx:  11\n","tok_flaw:  focused\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused']\n","token_ids_seq:  []\n","Printing prob:  0.34317211473882225\n","label:  0\n","idx:  12\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',']\n","token_ids_seq:  []\n","Printing prob:  0.151908204854039\n","label:  0\n","idx:  13\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the']\n","token_ids_seq:  []\n","Printing prob:  0.020502394912748634\n","label:  1\n","idx:  14\n","tok_flaw:  writin\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin']\n","token_ids_seq:  [14]\n","Printing prob:  0.06874396033961305\n","label:  1\n","idx:  15\n","tok_flaw:  unntentionally\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin', 'unntentionally']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.8280270518604741\n","label:  0\n","idx:  16\n","tok_flaw:  hilarious\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin', 'unntentionally', 'hilarious']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.3272759199154194\n","label:  0\n","idx:  17\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin', 'unntentionally', 'hilarious', ',']\n","token_ids_seq:  [14, 15]\n","Printing prob:  0.027111694252593188\n","label:  1\n","idx:  18\n","tok_flaw:  he\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin', 'unntentionally', 'hilarious', ',', 'he']\n","token_ids_seq:  [14, 15, 18]\n","Printing prob:  0.2988619459729934\n","label:  0\n","idx:  19\n","tok_flaw:  direction\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin', 'unntentionally', 'hilarious', ',', 'he', 'direction']\n","token_ids_seq:  [14, 15, 18]\n","Printing prob:  0.5814631297757415\n","label:  0\n","idx:  20\n","tok_flaw:  unfocused\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin', 'unntentionally', 'hilarious', ',', 'he', 'direction', 'unfocused']\n","token_ids_seq:  [14, 15, 18]\n","Printing prob:  0.13020024943186148\n","label:  0\n","idx:  21\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin', 'unntentionally', 'hilarious', ',', 'he', 'direction', 'unfocused', ',']\n","token_ids_seq:  [14, 15, 18]\n","Printing prob:  0.8654742200535543\n","label:  0\n","idx:  22\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin', 'unntentionally', 'hilarious', ',', 'he', 'direction', 'unfocused', ',', 'the']\n","token_ids_seq:  [14, 15, 18]\n","Printing prob:  0.6180036777018545\n","label:  0\n","idx:  23\n","tok_flaw:  performances\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin', 'unntentionally', 'hilarious', ',', 'he', 'direction', 'unfocused', ',', 'the', 'performances']\n","token_ids_seq:  [14, 15, 18]\n","Printing prob:  0.5353261956950968\n","label:  0\n","idx:  24\n","tok_flaw:  as\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin', 'unntentionally', 'hilarious', ',', 'he', 'direction', 'unfocused', ',', 'the', 'performances', 'as']\n","token_ids_seq:  [14, 15, 18]\n","Printing prob:  0.977912409651968\n","label:  0\n","idx:  25\n","tok_flaw:  wooden\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin', 'unntentionally', 'hilarious', ',', 'he', 'direction', 'unfocused', ',', 'the', 'performances', 'as', 'wooden']\n","token_ids_seq:  [14, 15, 18]\n","Printing prob:  0.24992877836787641\n","label:  0\n","idx:  26\n","tok_flaw:  .\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin', 'unntentionally', 'hilarious', ',', 'he', 'direction', 'unfocused', ',', 'the', 'performances', 'as', 'wooden', '.']\n","token_ids_seq:  [14, 15, 18]\n","Printing prob:  0.9541684473105322\n","label:  0\n","idx:  27\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin', 'unntentionally', 'hilarious', ',', 'he', 'direction', 'unfocused', ',', 'the', 'performances', 'as', 'wooden', '.', \"''\"]\n","token_ids_seq:  [14, 15, 18]\n","all_flaw_tokens:  [['``', 'the', 'editing', 'is', 'chaotic', ',', 'the', 'photography', 'grainy', 'and', 'badly', 'focused', ',', 'the', 'writin', 'unntentionally', 'hilarious', ',', 'he', 'direction', 'unfocused', ',', 'the', 'performances', 'as', 'wooden', '.', \"''\"]]\n","all_token_idx:  [[14, 15, 18]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.054309137556035836\n","label:  1\n","idx:  0\n","tok_flaw:  chdoose\n","flaw_tokens_seq:  ['chdoose']\n","token_ids_seq:  [0]\n","Printing prob:  0.8483958340290436\n","label:  0\n","idx:  1\n","tok_flaw:  your\n","flaw_tokens_seq:  ['chdoose', 'your']\n","token_ids_seq:  [0]\n","Printing prob:  0.6429141429266858\n","label:  0\n","idx:  2\n","tok_flaw:  reaction\n","flaw_tokens_seq:  ['chdoose', 'your', 'reaction']\n","token_ids_seq:  [0]\n","Printing prob:  0.6784202861750824\n","label:  0\n","idx:  3\n","tok_flaw:  :\n","flaw_tokens_seq:  ['chdoose', 'your', 'reaction', ':']\n","token_ids_seq:  [0]\n","Printing prob:  0.2310865776882428\n","label:  0\n","idx:  4\n","tok_flaw:  a\n","flaw_tokens_seq:  ['chdoose', 'your', 'reaction', ':', 'a']\n","token_ids_seq:  [0]\n","Printing prob:  0.5028287877799328\n","label:  0\n","idx:  5\n","tok_flaw:  .\n","flaw_tokens_seq:  ['chdoose', 'your', 'reaction', ':', 'a', '.']\n","token_ids_seq:  [0]\n","Printing prob:  0.43927971890312656\n","label:  0\n","idx:  6\n","tok_flaw:  -rrb-\n","flaw_tokens_seq:  ['chdoose', 'your', 'reaction', ':', 'a', '.', '-rrb-']\n","token_ids_seq:  [0]\n","Printing prob:  0.4371895396029679\n","label:  0\n","idx:  7\n","tok_flaw:  that\n","flaw_tokens_seq:  ['chdoose', 'your', 'reaction', ':', 'a', '.', '-rrb-', 'that']\n","token_ids_seq:  [0]\n","Printing prob:  0.05738494598469668\n","label:  1\n","idx:  8\n","tok_flaw:  sue\n","flaw_tokens_seq:  ['chdoose', 'your', 'reaction', ':', 'a', '.', '-rrb-', 'that', 'sue']\n","token_ids_seq:  [0, 8]\n","Printing prob:  0.5664704037792053\n","label:  0\n","idx:  9\n","tok_flaw:  is\n","flaw_tokens_seq:  ['chdoose', 'your', 'reaction', ':', 'a', '.', '-rrb-', 'that', 'sue', 'is']\n","token_ids_seq:  [0, 8]\n","Printing prob:  0.8946738589299438\n","label:  0\n","idx:  10\n","tok_flaw:  funny\n","flaw_tokens_seq:  ['chdoose', 'your', 'reaction', ':', 'a', '.', '-rrb-', 'that', 'sue', 'is', 'funny']\n","token_ids_seq:  [0, 8]\n","Printing prob:  0.3013001923648396\n","label:  0\n","idx:  11\n","tok_flaw:  !\n","flaw_tokens_seq:  ['chdoose', 'your', 'reaction', ':', 'a', '.', '-rrb-', 'that', 'sue', 'is', 'funny', '!']\n","token_ids_seq:  [0, 8]\n","all_flaw_tokens:  [['chdoose', 'your', 'reaction', ':', 'a', '.', '-rrb-', 'that', 'sue', 'is', 'funny', '!']]\n","all_token_idx:  [[0, 8]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.4141036656271583\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.8379866410536212\n","label:  0\n","idx:  1\n","tok_flaw:  i\n","flaw_tokens_seq:  ['``', 'i']\n","token_ids_seq:  []\n","Printing prob:  0.5015472957743707\n","label:  0\n","idx:  2\n","tok_flaw:  doubt\n","flaw_tokens_seq:  ['``', 'i', 'doubt']\n","token_ids_seq:  []\n","Printing prob:  0.48968384139272314\n","label:  0\n","idx:  3\n","tok_flaw:  anyone\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone']\n","token_ids_seq:  []\n","Printing prob:  0.217681679522444\n","label:  0\n","idx:  4\n","tok_flaw:  will\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will']\n","token_ids_seq:  []\n","Printing prob:  0.30114300355248413\n","label:  0\n","idx:  5\n","tok_flaw:  remember\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember']\n","token_ids_seq:  []\n","Printing prob:  0.23651844765828678\n","label:  0\n","idx:  6\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the']\n","token_ids_seq:  []\n","Printing prob:  0.209502615610763\n","label:  0\n","idx:  7\n","tok_flaw:  picture\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture']\n","token_ids_seq:  []\n","Printing prob:  0.15768735498118047\n","label:  0\n","idx:  8\n","tok_flaw:  by\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by']\n","token_ids_seq:  []\n","Printing prob:  0.31402006658799453\n","label:  0\n","idx:  9\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the']\n","token_ids_seq:  []\n","Printing prob:  0.28486438547979165\n","label:  0\n","idx:  10\n","tok_flaw:  time\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time']\n","token_ids_seq:  []\n","Printing prob:  0.5039211906681869\n","label:  0\n","idx:  11\n","tok_flaw:  christmas\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas']\n","token_ids_seq:  []\n","Printing prob:  0.10063827663721425\n","label:  1\n","idx:  12\n","tok_flaw:  rally\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally']\n","token_ids_seq:  [12]\n","Printing prob:  0.369610567395515\n","label:  0\n","idx:  13\n","tok_flaw:  rolls\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls']\n","token_ids_seq:  [12]\n","Printing prob:  0.37257850735858977\n","label:  0\n","idx:  14\n","tok_flaw:  around\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls', 'around']\n","token_ids_seq:  [12]\n","Printing prob:  0.6002400018182031\n","label:  0\n","idx:  15\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls', 'around', ',']\n","token_ids_seq:  [12]\n","Printing prob:  0.2787959715683347\n","label:  0\n","idx:  16\n","tok_flaw:  but\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls', 'around', ',', 'but']\n","token_ids_seq:  [12]\n","Printing prob:  0.825896454085303\n","label:  0\n","idx:  17\n","tok_flaw:  maybe\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls', 'around', ',', 'but', 'maybe']\n","token_ids_seq:  [12]\n","Printing prob:  0.5417621188486837\n","label:  0\n","idx:  18\n","tok_flaw:  it\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls', 'around', ',', 'but', 'maybe', 'it']\n","token_ids_seq:  [12]\n","Printing prob:  0.8498506477927766\n","label:  0\n","idx:  19\n","tok_flaw:  'll\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls', 'around', ',', 'but', 'maybe', 'it', \"'ll\"]\n","token_ids_seq:  [12]\n","Printing prob:  0.43951970862045964\n","label:  0\n","idx:  20\n","tok_flaw:  be\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls', 'around', ',', 'but', 'maybe', 'it', \"'ll\", 'be']\n","token_ids_seq:  [12]\n","Printing prob:  0.1394223069546613\n","label:  0\n","idx:  21\n","tok_flaw:  on\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls', 'around', ',', 'but', 'maybe', 'it', \"'ll\", 'be', 'on']\n","token_ids_seq:  [12]\n","Printing prob:  0.38880544519963944\n","label:  0\n","idx:  22\n","tok_flaw:  video\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls', 'around', ',', 'but', 'maybe', 'it', \"'ll\", 'be', 'on', 'video']\n","token_ids_seq:  [12]\n","Printing prob:  0.26333507613403884\n","label:  0\n","idx:  23\n","tok_flaw:  by\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls', 'around', ',', 'but', 'maybe', 'it', \"'ll\", 'be', 'on', 'video', 'by']\n","token_ids_seq:  [12]\n","Printing prob:  0.9659759745788479\n","label:  0\n","idx:  24\n","tok_flaw:  then\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls', 'around', ',', 'but', 'maybe', 'it', \"'ll\", 'be', 'on', 'video', 'by', 'then']\n","token_ids_seq:  [12]\n","Printing prob:  0.04645566504245602\n","label:  1\n","idx:  25\n","tok_flaw:  \n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls', 'around', ',', 'but', 'maybe', 'it', \"'ll\", 'be', 'on', 'video', 'by', 'then', '']\n","token_ids_seq:  [12, 25]\n","Printing prob:  0.5741417519638926\n","label:  0\n","idx:  26\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls', 'around', ',', 'but', 'maybe', 'it', \"'ll\", 'be', 'on', 'video', 'by', 'then', '', \"''\"]\n","token_ids_seq:  [12, 25]\n","all_flaw_tokens:  [['``', 'i', 'doubt', 'anyone', 'will', 'remember', 'the', 'picture', 'by', 'the', 'time', 'christmas', 'rally', 'rolls', 'around', ',', 'but', 'maybe', 'it', \"'ll\", 'be', 'on', 'video', 'by', 'then', '', \"''\"]]\n","all_token_idx:  [[12, 25]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","attacks:  99% 1796/1820 [00:35<00:00, 46.53it/s]emb_dict:  None\n","embeddings: None\n","Printing prob:  0.6249883407255488\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.5775831285388746\n","label:  0\n","idx:  1\n","tok_flaw:  a\n","flaw_tokens_seq:  ['``', 'a']\n","token_ids_seq:  []\n","Printing prob:  0.6556108407613619\n","label:  0\n","idx:  2\n","tok_flaw:  strong\n","flaw_tokens_seq:  ['``', 'a', 'strong']\n","token_ids_seq:  []\n","Printing prob:  0.2340266571380053\n","label:  0\n","idx:  3\n","tok_flaw:  first\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first']\n","token_ids_seq:  []\n","Printing prob:  0.3556437958359556\n","label:  0\n","idx:  4\n","tok_flaw:  quarter\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first', 'quarter']\n","token_ids_seq:  []\n","Printing prob:  0.7705658213787946\n","label:  0\n","idx:  5\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first', 'quarter', ',']\n","token_ids_seq:  []\n","Printing prob:  0.8316239782328518\n","label:  0\n","idx:  6\n","tok_flaw:  slightly\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first', 'quarter', ',', 'slightly']\n","token_ids_seq:  []\n","Printing prob:  0.6193858578446706\n","label:  0\n","idx:  7\n","tok_flaw:  less\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first', 'quarter', ',', 'slightly', 'less']\n","token_ids_seq:  []\n","Printing prob:  0.5485393335662485\n","label:  0\n","idx:  8\n","tok_flaw:  so\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first', 'quarter', ',', 'slightly', 'less', 'so']\n","token_ids_seq:  []\n","Printing prob:  0.3107596082056545\n","label:  0\n","idx:  9\n","tok_flaw:  second\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first', 'quarter', ',', 'slightly', 'less', 'so', 'second']\n","token_ids_seq:  []\n","Printing prob:  0.20723669088190533\n","label:  0\n","idx:  10\n","tok_flaw:  quarter\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first', 'quarter', ',', 'slightly', 'less', 'so', 'second', 'quarter']\n","token_ids_seq:  []\n","Printing prob:  0.1887936475543055\n","label:  0\n","idx:  11\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first', 'quarter', ',', 'slightly', 'less', 'so', 'second', 'quarter', ',']\n","token_ids_seq:  []\n","Printing prob:  0.4961666231512044\n","label:  0\n","idx:  12\n","tok_flaw:  and\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first', 'quarter', ',', 'slightly', 'less', 'so', 'second', 'quarter', ',', 'and']\n","token_ids_seq:  []\n","Printing prob:  0.632616409132926\n","label:  0\n","idx:  13\n","tok_flaw:  average\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first', 'quarter', ',', 'slightly', 'less', 'so', 'second', 'quarter', ',', 'and', 'average']\n","token_ids_seq:  []\n","Printing prob:  0.6998436705082837\n","label:  0\n","idx:  14\n","tok_flaw:  second\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first', 'quarter', ',', 'slightly', 'less', 'so', 'second', 'quarter', ',', 'and', 'average', 'second']\n","token_ids_seq:  []\n","Printing prob:  0.9705498144654375\n","label:  0\n","idx:  15\n","tok_flaw:  half\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first', 'quarter', ',', 'slightly', 'less', 'so', 'second', 'quarter', ',', 'and', 'average', 'second', 'half']\n","token_ids_seq:  []\n","Printing prob:  0.5040247622548326\n","label:  0\n","idx:  16\n","tok_flaw:  .\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first', 'quarter', ',', 'slightly', 'less', 'so', 'second', 'quarter', ',', 'and', 'average', 'second', 'half', '.']\n","token_ids_seq:  []\n","Printing prob:  0.7763379235301514\n","label:  0\n","idx:  17\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', 'a', 'strong', 'first', 'quarter', ',', 'slightly', 'less', 'so', 'second', 'quarter', ',', 'and', 'average', 'second', 'half', '.', \"''\"]\n","token_ids_seq:  []\n","all_flaw_tokens:  [['``', 'a', 'strong', 'first', 'quarter', ',', 'slightly', 'less', 'so', 'second', 'quarter', ',', 'and', 'average', 'second', 'half', '.', \"''\"]]\n","all_token_idx:  [[]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.9517666699906878\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.9171976259606127\n","label:  0\n","idx:  1\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'the']\n","token_ids_seq:  []\n","Printing prob:  0.2758203774602267\n","label:  0\n","idx:  2\n","tok_flaw:  film\n","flaw_tokens_seq:  ['``', 'the', 'film']\n","token_ids_seq:  []\n","Printing prob:  0.10277210545814197\n","label:  1\n","idx:  3\n","tok_flaw:  ics\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics']\n","token_ids_seq:  [3]\n","Printing prob:  0.9944640772442678\n","label:  0\n","idx:  4\n","tok_flaw:  faithful\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful']\n","token_ids_seq:  [3]\n","Printing prob:  0.1462901175113661\n","label:  0\n","idx:  5\n","tok_flaw:  to\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to']\n","token_ids_seq:  [3]\n","Printing prob:  0.5350339739853273\n","label:  0\n","idx:  6\n","tok_flaw:  what\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what']\n","token_ids_seq:  [3]\n","Printing prob:  0.8562392608129049\n","label:  0\n","idx:  7\n","tok_flaw:  one\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one']\n","token_ids_seq:  [3]\n","Printing prob:  0.8772054631573979\n","label:  0\n","idx:  8\n","tok_flaw:  presumes\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes']\n","token_ids_seq:  [3]\n","Printing prob:  0.38462156659404223\n","label:  0\n","idx:  9\n","tok_flaw:  are\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are']\n","token_ids_seq:  [3]\n","Printing prob:  0.7647035800454196\n","label:  0\n","idx:  10\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the']\n","token_ids_seq:  [3]\n","Printing prob:  0.7172565376942445\n","label:  0\n","idx:  11\n","tok_flaw:  book\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book']\n","token_ids_seq:  [3]\n","Printing prob:  0.7539423883235574\n","label:  0\n","idx:  12\n","tok_flaw:  's\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\"]\n","token_ids_seq:  [3]\n","Printing prob:  0.0013015611154580942\n","label:  1\n","idx:  13\n","tok_flaw:  Fwin\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.1392379482139613\n","label:  0\n","idx:  14\n","tok_flaw:  premises\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.14506658807745043\n","label:  0\n","idx:  15\n","tok_flaw:  --\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.888302192875029\n","label:  0\n","idx:  16\n","tok_flaw:  that\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.44881957136491857\n","label:  0\n","idx:  17\n","tok_flaw:  we\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.4662908772741533\n","label:  0\n","idx:  18\n","tok_flaw:  become\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.8880013220163276\n","label:  0\n","idx:  19\n","tok_flaw:  who\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.2750474020102217\n","label:  0\n","idx:  20\n","tok_flaw:  we\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.990059410156008\n","label:  0\n","idx:  21\n","tok_flaw:  are\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.13390206328435805\n","label:  0\n","idx:  22\n","tok_flaw:  on\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.41357611133106\n","label:  0\n","idx:  23\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.1913004304208067\n","label:  0\n","idx:  24\n","tok_flaw:  backs\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.7493770970620537\n","label:  0\n","idx:  25\n","tok_flaw:  of\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.9011005252377807\n","label:  0\n","idx:  26\n","tok_flaw:  our\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.6987605131614133\n","label:  0\n","idx:  27\n","tok_flaw:  parents\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.657561532323289\n","label:  0\n","idx:  28\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.7549152163273434\n","label:  0\n","idx:  29\n","tok_flaw:  but\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.635928135143003\n","label:  0\n","idx:  30\n","tok_flaw:  we\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.8407510330314113\n","label:  0\n","idx:  31\n","tok_flaw:  have\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have']\n","token_ids_seq:  [3, 13]\n","Printing prob:  0.07859462331395795\n","label:  1\n","idx:  32\n","tok_flaw:  Dno\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno']\n","token_ids_seq:  [3, 13, 32]\n","Printing prob:  0.8444343915811499\n","label:  0\n","idx:  33\n","tok_flaw:  idea\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea']\n","token_ids_seq:  [3, 13, 32]\n","Printing prob:  0.41096930806774346\n","label:  0\n","idx:  34\n","tok_flaw:  who\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who']\n","token_ids_seq:  [3, 13, 32]\n","Printing prob:  0.08803551796821396\n","label:  1\n","idx:  35\n","tok_flaw:  thvey\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey']\n","token_ids_seq:  [3, 13, 32, 35]\n","Printing prob:  0.4586477776561684\n","label:  0\n","idx:  36\n","tok_flaw:  were\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were']\n","token_ids_seq:  [3, 13, 32, 35]\n","Printing prob:  0.904669997853557\n","label:  0\n","idx:  37\n","tok_flaw:  at\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at']\n","token_ids_seq:  [3, 13, 32, 35]\n","Printing prob:  0.6893596567787574\n","label:  0\n","idx:  38\n","tok_flaw:  our\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our']\n","token_ids_seq:  [3, 13, 32, 35]\n","Printing prob:  0.45935414513473405\n","label:  0\n","idx:  39\n","tok_flaw:  age\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age']\n","token_ids_seq:  [3, 13, 32, 35]\n","Printing prob:  0.2770957686583293\n","label:  0\n","idx:  40\n","tok_flaw:  ;\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';']\n","token_ids_seq:  [3, 13, 32, 35]\n","Printing prob:  0.36090362116080044\n","label:  0\n","idx:  41\n","tok_flaw:  and\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and']\n","token_ids_seq:  [3, 13, 32, 35]\n","Printing prob:  0.1889244493101091\n","label:  0\n","idx:  42\n","tok_flaw:  that\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that']\n","token_ids_seq:  [3, 13, 32, 35]\n","Printing prob:  0.7094243759587107\n","label:  0\n","idx:  43\n","tok_flaw:  time\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time']\n","token_ids_seq:  [3, 13, 32, 35]\n","Printing prob:  0.715962057377183\n","label:  0\n","idx:  44\n","tok_flaw:  is\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is']\n","token_ids_seq:  [3, 13, 32, 35]\n","Printing prob:  0.10015529212964325\n","label:  1\n","idx:  45\n","tok_flaw:  \n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is', '']\n","token_ids_seq:  [3, 13, 32, 35, 45]\n","Printing prob:  0.6833942959044025\n","label:  0\n","idx:  46\n","tok_flaw:  fleeting\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is', '', 'fleeting']\n","token_ids_seq:  [3, 13, 32, 35, 45]\n","Printing prob:  0.228270620472678\n","label:  0\n","idx:  47\n","tok_flaw:  and\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is', '', 'fleeting', 'and']\n","token_ids_seq:  [3, 13, 32, 35, 45]\n","Printing prob:  0.03721179828289456\n","label:  1\n","idx:  48\n","tok_flaw:  pjecious\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is', '', 'fleeting', 'and', 'pjecious']\n","token_ids_seq:  [3, 13, 32, 35, 45, 48]\n","Printing prob:  0.9121433590501408\n","label:  0\n","idx:  49\n","tok_flaw:  commodity\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is', '', 'fleeting', 'and', 'pjecious', 'commodity']\n","token_ids_seq:  [3, 13, 32, 35, 45, 48]\n","Printing prob:  0.8010621459865673\n","label:  0\n","idx:  50\n","tok_flaw:  no\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is', '', 'fleeting', 'and', 'pjecious', 'commodity', 'no']\n","token_ids_seq:  [3, 13, 32, 35, 45, 48]\n","Printing prob:  0.19309334425053848\n","label:  0\n","idx:  51\n","tok_flaw:  matter\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is', '', 'fleeting', 'and', 'pjecious', 'commodity', 'no', 'matter']\n","token_ids_seq:  [3, 13, 32, 35, 45, 48]\n","Printing prob:  0.557001173006251\n","label:  0\n","idx:  52\n","tok_flaw:  how\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is', '', 'fleeting', 'and', 'pjecious', 'commodity', 'no', 'matter', 'how']\n","token_ids_seq:  [3, 13, 32, 35, 45, 48]\n","Printing prob:  0.484088087393313\n","label:  0\n","idx:  53\n","tok_flaw:  old\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is', '', 'fleeting', 'and', 'pjecious', 'commodity', 'no', 'matter', 'how', 'old']\n","token_ids_seq:  [3, 13, 32, 35, 45, 48]\n","Printing prob:  0.39462985941069384\n","label:  0\n","idx:  54\n","tok_flaw:  you\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is', '', 'fleeting', 'and', 'pjecious', 'commodity', 'no', 'matter', 'how', 'old', 'you']\n","token_ids_seq:  [3, 13, 32, 35, 45, 48]\n","Printing prob:  0.526273083679816\n","label:  0\n","idx:  55\n","tok_flaw:  are\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is', '', 'fleeting', 'and', 'pjecious', 'commodity', 'no', 'matter', 'how', 'old', 'you', 'are']\n","token_ids_seq:  [3, 13, 32, 35, 45, 48]\n","Printing prob:  0.1824222736104697\n","label:  0\n","idx:  56\n","tok_flaw:  .\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is', '', 'fleeting', 'and', 'pjecious', 'commodity', 'no', 'matter', 'how', 'old', 'you', 'are', '.']\n","token_ids_seq:  [3, 13, 32, 35, 45, 48]\n","Printing prob:  0.22977559924947277\n","label:  0\n","idx:  57\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is', '', 'fleeting', 'and', 'pjecious', 'commodity', 'no', 'matter', 'how', 'old', 'you', 'are', '.', \"''\"]\n","token_ids_seq:  [3, 13, 32, 35, 45, 48]\n","all_flaw_tokens:  [['``', 'the', 'film', 'ics', 'faithful', 'to', 'what', 'one', 'presumes', 'are', 'the', 'book', \"'s\", 'Fwin', 'premises', '--', 'that', 'we', 'become', 'who', 'we', 'are', 'on', 'the', 'backs', 'of', 'our', 'parents', ',', 'but', 'we', 'have', 'Dno', 'idea', 'who', 'thvey', 'were', 'at', 'our', 'age', ';', 'and', 'that', 'time', 'is', '', 'fleeting', 'and', 'pjecious', 'commodity', 'no', 'matter', 'how', 'old', 'you', 'are', '.', \"''\"]]\n","all_token_idx:  [[3, 13, 32, 35, 45, 48]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.21273100662010447\n","label:  0\n","idx:  0\n","tok_flaw:  mark\n","flaw_tokens_seq:  ['mark']\n","token_ids_seq:  []\n","Printing prob:  0.7597991981757352\n","label:  0\n","idx:  1\n","tok_flaw:  me\n","flaw_tokens_seq:  ['mark', 'me']\n","token_ids_seq:  []\n","Printing prob:  0.8657551944541163\n","label:  0\n","idx:  2\n","tok_flaw:  down\n","flaw_tokens_seq:  ['mark', 'me', 'down']\n","token_ids_seq:  []\n","Printing prob:  0.29535274482725127\n","label:  0\n","idx:  3\n","tok_flaw:  as\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as']\n","token_ids_seq:  []\n","Printing prob:  0.05924762396542538\n","label:  1\n","idx:  4\n","tok_flaw:  k\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k']\n","token_ids_seq:  [4]\n","Printing prob:  0.9122586696900279\n","label:  0\n","idx:  5\n","tok_flaw:  non-believer\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer']\n","token_ids_seq:  [4]\n","Printing prob:  0.8981234733947785\n","label:  0\n","idx:  6\n","tok_flaw:  in\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in']\n","token_ids_seq:  [4]\n","Printing prob:  0.8101604994113301\n","label:  0\n","idx:  7\n","tok_flaw:  werewolf\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf']\n","token_ids_seq:  [4]\n","Printing prob:  0.8161467157075223\n","label:  0\n","idx:  8\n","tok_flaw:  films\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films']\n","token_ids_seq:  [4]\n","Printing prob:  0.5989097816054275\n","label:  0\n","idx:  9\n","tok_flaw:  that\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that']\n","token_ids_seq:  [4]\n","Printing prob:  0.8236596254953699\n","label:  0\n","idx:  10\n","tok_flaw:  are\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that', 'are']\n","token_ids_seq:  [4]\n","Printing prob:  0.9160427173853901\n","label:  0\n","idx:  11\n","tok_flaw:  not\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that', 'are', 'not']\n","token_ids_seq:  [4]\n","Printing prob:  0.8939627232337978\n","label:  0\n","idx:  12\n","tok_flaw:  serious\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that', 'are', 'not', 'serious']\n","token_ids_seq:  [4]\n","Printing prob:  0.415450599565959\n","label:  0\n","idx:  13\n","tok_flaw:  and\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that', 'are', 'not', 'serious', 'and']\n","token_ids_seq:  [4]\n","Printing prob:  0.6622752566664445\n","label:  0\n","idx:  14\n","tok_flaw:  rely\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that', 'are', 'not', 'serious', 'and', 'rely']\n","token_ids_seq:  [4]\n","Printing prob:  0.8587429905741077\n","label:  0\n","idx:  15\n","tok_flaw:  on\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that', 'are', 'not', 'serious', 'and', 'rely', 'on']\n","token_ids_seq:  [4]\n","Printing prob:  0.9954804442242539\n","label:  0\n","idx:  16\n","tok_flaw:  stupidity\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that', 'are', 'not', 'serious', 'and', 'rely', 'on', 'stupidity']\n","token_ids_seq:  [4]\n","Printing prob:  0.8146377312867613\n","label:  0\n","idx:  17\n","tok_flaw:  as\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that', 'are', 'not', 'serious', 'and', 'rely', 'on', 'stupidity', 'as']\n","token_ids_seq:  [4]\n","Printing prob:  0.8215063279817798\n","label:  0\n","idx:  18\n","tok_flaw:  a\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that', 'are', 'not', 'serious', 'and', 'rely', 'on', 'stupidity', 'as', 'a']\n","token_ids_seq:  [4]\n","Printing prob:  0.6068355387214169\n","label:  0\n","idx:  19\n","tok_flaw:  substitute\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that', 'are', 'not', 'serious', 'and', 'rely', 'on', 'stupidity', 'as', 'a', 'substitute']\n","token_ids_seq:  [4]\n","Printing prob:  0.10622657840744232\n","label:  1\n","idx:  20\n","tok_flaw:  fnr\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that', 'are', 'not', 'serious', 'and', 'rely', 'on', 'stupidity', 'as', 'a', 'substitute', 'fnr']\n","token_ids_seq:  [4, 20]\n","Printing prob:  0.869984818156342\n","label:  0\n","idx:  21\n","tok_flaw:  humor\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that', 'are', 'not', 'serious', 'and', 'rely', 'on', 'stupidity', 'as', 'a', 'substitute', 'fnr', 'humor']\n","token_ids_seq:  [4, 20]\n","Printing prob:  0.9647108240613572\n","label:  0\n","idx:  22\n","tok_flaw:  .\n","flaw_tokens_seq:  ['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that', 'are', 'not', 'serious', 'and', 'rely', 'on', 'stupidity', 'as', 'a', 'substitute', 'fnr', 'humor', '.']\n","token_ids_seq:  [4, 20]\n","all_flaw_tokens:  [['mark', 'me', 'down', 'as', 'k', 'non-believer', 'in', 'werewolf', 'films', 'that', 'are', 'not', 'serious', 'and', 'rely', 'on', 'stupidity', 'as', 'a', 'substitute', 'fnr', 'humor', '.']]\n","all_token_idx:  [[4, 20]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.3547986457667168\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.5364863563724939\n","label:  0\n","idx:  1\n","tok_flaw:  theology\n","flaw_tokens_seq:  ['``', 'theology']\n","token_ids_seq:  []\n","Printing prob:  0.22214958551710218\n","label:  0\n","idx:  2\n","tok_flaw:  aside\n","flaw_tokens_seq:  ['``', 'theology', 'aside']\n","token_ids_seq:  []\n","Printing prob:  0.0069440459457541515\n","label:  1\n","idx:  3\n","tok_flaw:  L,\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,']\n","token_ids_seq:  [3]\n","Printing prob:  0.9538512772885656\n","label:  0\n","idx:  4\n","tok_flaw:  why\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why']\n","token_ids_seq:  [3]\n","Printing prob:  0.5808525699348965\n","label:  0\n","idx:  5\n","tok_flaw:  put\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put']\n","token_ids_seq:  [3]\n","Printing prob:  0.19600704856712003\n","label:  0\n","idx:  6\n","tok_flaw:  someone\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone']\n","token_ids_seq:  [3]\n","Printing prob:  0.7288421289554698\n","label:  0\n","idx:  7\n","tok_flaw:  who\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who']\n","token_ids_seq:  [3]\n","Printing prob:  0.297438939857291\n","label:  0\n","idx:  8\n","tok_flaw:  ultimately\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately']\n","token_ids_seq:  [3]\n","Printing prob:  0.5408921158585692\n","label:  0\n","idx:  9\n","tok_flaw:  does\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately', 'does']\n","token_ids_seq:  [3]\n","Printing prob:  0.26367733144018946\n","label:  0\n","idx:  10\n","tok_flaw:  n't\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately', 'does', \"n't\"]\n","token_ids_seq:  [3]\n","Printing prob:  0.7687767479409194\n","label:  0\n","idx:  11\n","tok_flaw:  learn\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately', 'does', \"n't\", 'learn']\n","token_ids_seq:  [3]\n","Printing prob:  0.5865901918676011\n","label:  0\n","idx:  12\n","tok_flaw:  at\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately', 'does', \"n't\", 'learn', 'at']\n","token_ids_seq:  [3]\n","Printing prob:  0.9887432614206477\n","label:  0\n","idx:  13\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately', 'does', \"n't\", 'learn', 'at', 'the']\n","token_ids_seq:  [3]\n","Printing prob:  0.15593445924560523\n","label:  0\n","idx:  14\n","tok_flaw:  center\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately', 'does', \"n't\", 'learn', 'at', 'the', 'center']\n","token_ids_seq:  [3]\n","Printing prob:  0.2540257393871941\n","label:  0\n","idx:  15\n","tok_flaw:  of\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately', 'does', \"n't\", 'learn', 'at', 'the', 'center', 'of']\n","token_ids_seq:  [3]\n","Printing prob:  0.05820681887528001\n","label:  1\n","idx:  16\n","tok_flaw:  Ea\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately', 'does', \"n't\", 'learn', 'at', 'the', 'center', 'of', 'Ea']\n","token_ids_seq:  [3, 16]\n","Printing prob:  0.8105311739478281\n","label:  0\n","idx:  17\n","tok_flaw:  kids\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately', 'does', \"n't\", 'learn', 'at', 'the', 'center', 'of', 'Ea', 'kids']\n","token_ids_seq:  [3, 16]\n","Printing prob:  0.6608580973181224\n","label:  0\n","idx:  18\n","tok_flaw:  '\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately', 'does', \"n't\", 'learn', 'at', 'the', 'center', 'of', 'Ea', 'kids', \"'\"]\n","token_ids_seq:  [3, 16]\n","Printing prob:  0.6087241301740987\n","label:  0\n","idx:  19\n","tok_flaw:  story\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately', 'does', \"n't\", 'learn', 'at', 'the', 'center', 'of', 'Ea', 'kids', \"'\", 'story']\n","token_ids_seq:  [3, 16]\n","Printing prob:  0.6526244502168402\n","label:  0\n","idx:  20\n","tok_flaw:  ?\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately', 'does', \"n't\", 'learn', 'at', 'the', 'center', 'of', 'Ea', 'kids', \"'\", 'story', '?']\n","token_ids_seq:  [3, 16]\n","Printing prob:  0.4418512563383381\n","label:  0\n","idx:  21\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately', 'does', \"n't\", 'learn', 'at', 'the', 'center', 'of', 'Ea', 'kids', \"'\", 'story', '?', \"''\"]\n","token_ids_seq:  [3, 16]\n","all_flaw_tokens:  [['``', 'theology', 'aside', 'L,', 'why', 'put', 'someone', 'who', 'ultimately', 'does', \"n't\", 'learn', 'at', 'the', 'center', 'of', 'Ea', 'kids', \"'\", 'story', '?', \"''\"]]\n","all_token_idx:  [[3, 16]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.12369723007962152\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.7604733740542904\n","label:  0\n","idx:  1\n","tok_flaw:  this\n","flaw_tokens_seq:  ['``', 'this']\n","token_ids_seq:  []\n","Printing prob:  0.9216084844109628\n","label:  0\n","idx:  2\n","tok_flaw:  film\n","flaw_tokens_seq:  ['``', 'this', 'film']\n","token_ids_seq:  []\n","Printing prob:  0.034492854658561445\n","label:  1\n","idx:  3\n","tok_flaw:  waRs\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs']\n","token_ids_seq:  [3]\n","Printing prob:  0.34242290201955183\n","label:  0\n","idx:  4\n","tok_flaw:  made\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made']\n","token_ids_seq:  [3]\n","Printing prob:  0.7733259411671376\n","label:  0\n","idx:  5\n","tok_flaw:  to\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to']\n","token_ids_seq:  [3]\n","Printing prob:  0.5138994365441211\n","label:  0\n","idx:  6\n","tok_flaw:  get\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get']\n","token_ids_seq:  [3]\n","Printing prob:  0.8727651550281811\n","label:  0\n","idx:  7\n","tok_flaw:  laughs\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs']\n","token_ids_seq:  [3]\n","Printing prob:  0.37268772275290696\n","label:  0\n","idx:  8\n","tok_flaw:  from\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from']\n","token_ids_seq:  [3]\n","Printing prob:  0.3121449888797998\n","label:  0\n","idx:  9\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the']\n","token_ids_seq:  [3]\n","Printing prob:  0.5296150780033001\n","label:  0\n","idx:  10\n","tok_flaw:  slowest\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest']\n","token_ids_seq:  [3]\n","Printing prob:  0.304694623932395\n","label:  0\n","idx:  11\n","tok_flaw:  person\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person']\n","token_ids_seq:  [3]\n","Printing prob:  0.33273428624149026\n","label:  0\n","idx:  12\n","tok_flaw:  in\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in']\n","token_ids_seq:  [3]\n","Printing prob:  0.8701871257162588\n","label:  0\n","idx:  13\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the']\n","token_ids_seq:  [3]\n","Printing prob:  0.8366805844266626\n","label:  0\n","idx:  14\n","tok_flaw:  audience\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience']\n","token_ids_seq:  [3]\n","Printing prob:  0.5183639702845232\n","label:  0\n","idx:  15\n","tok_flaw:  --\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--']\n","token_ids_seq:  [3]\n","Printing prob:  0.941769138273435\n","label:  0\n","idx:  16\n","tok_flaw:  just\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just']\n","token_ids_seq:  [3]\n","Printing prob:  0.007597002906448047\n","label:  1\n","idx:  17\n","tok_flaw:  pule\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule']\n","token_ids_seq:  [3, 17]\n","Printing prob:  0.8727732918899713\n","label:  0\n","idx:  18\n","tok_flaw:  slapstick\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick']\n","token_ids_seq:  [3, 17]\n","Printing prob:  0.05153398928372299\n","label:  1\n","idx:  19\n","tok_flaw:  wih\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick', 'wih']\n","token_ids_seq:  [3, 17, 19]\n","Printing prob:  0.6763263961556466\n","label:  0\n","idx:  20\n","tok_flaw:  lots\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick', 'wih', 'lots']\n","token_ids_seq:  [3, 17, 19]\n","Printing prob:  0.4597150206657945\n","label:  0\n","idx:  21\n","tok_flaw:  of\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick', 'wih', 'lots', 'of']\n","token_ids_seq:  [3, 17, 19]\n","Printing prob:  0.6584716303731962\n","label:  0\n","idx:  22\n","tok_flaw:  inane\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick', 'wih', 'lots', 'of', 'inane']\n","token_ids_seq:  [3, 17, 19]\n","Printing prob:  0.021406151558508224\n","label:  1\n","idx:  23\n","tok_flaw:  i,\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick', 'wih', 'lots', 'of', 'inane', 'i,']\n","token_ids_seq:  [3, 17, 19, 23]\n","Printing prob:  0.8816472141533118\n","label:  0\n","idx:  24\n","tok_flaw:  inoffensive\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick', 'wih', 'lots', 'of', 'inane', 'i,', 'inoffensive']\n","token_ids_seq:  [3, 17, 19, 23]\n","Printing prob:  0.41881027140417426\n","label:  0\n","idx:  25\n","tok_flaw:  screaming\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick', 'wih', 'lots', 'of', 'inane', 'i,', 'inoffensive', 'screaming']\n","token_ids_seq:  [3, 17, 19, 23]\n","Printing prob:  0.47095479260077744\n","label:  0\n","idx:  26\n","tok_flaw:  and\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick', 'wih', 'lots', 'of', 'inane', 'i,', 'inoffensive', 'screaming', 'and']\n","token_ids_seq:  [3, 17, 19, 23]\n","Printing prob:  0.33440637432564213\n","label:  0\n","idx:  27\n","tok_flaw:  exaggerated\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick', 'wih', 'lots', 'of', 'inane', 'i,', 'inoffensive', 'screaming', 'and', 'exaggerated']\n","token_ids_seq:  [3, 17, 19, 23]\n","Printing prob:  0.4886351185521244\n","label:  0\n","idx:  28\n","tok_flaw:  facial\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick', 'wih', 'lots', 'of', 'inane', 'i,', 'inoffensive', 'screaming', 'and', 'exaggerated', 'facial']\n","token_ids_seq:  [3, 17, 19, 23]\n","Printing prob:  0.9062268598760973\n","label:  0\n","idx:  29\n","tok_flaw:  expressions\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick', 'wih', 'lots', 'of', 'inane', 'i,', 'inoffensive', 'screaming', 'and', 'exaggerated', 'facial', 'expressions']\n","token_ids_seq:  [3, 17, 19, 23]\n","Printing prob:  0.6325711628342803\n","label:  0\n","idx:  30\n","tok_flaw:  .\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick', 'wih', 'lots', 'of', 'inane', 'i,', 'inoffensive', 'screaming', 'and', 'exaggerated', 'facial', 'expressions', '.']\n","token_ids_seq:  [3, 17, 19, 23]\n","Printing prob:  0.40259713499385485\n","label:  0\n","idx:  31\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick', 'wih', 'lots', 'of', 'inane', 'i,', 'inoffensive', 'screaming', 'and', 'exaggerated', 'facial', 'expressions', '.', \"''\"]\n","token_ids_seq:  [3, 17, 19, 23]\n","all_flaw_tokens:  [['``', 'this', 'film', 'waRs', 'made', 'to', 'get', 'laughs', 'from', 'the', 'slowest', 'person', 'in', 'the', 'audience', '--', 'just', 'pule', 'slapstick', 'wih', 'lots', 'of', 'inane', 'i,', 'inoffensive', 'screaming', 'and', 'exaggerated', 'facial', 'expressions', '.', \"''\"]]\n","all_token_idx:  [[3, 17, 19, 23]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","attacks:  99% 1801/1820 [00:35<00:00, 36.70it/s]emb_dict:  None\n","embeddings: None\n","Printing prob:  0.9249260151611254\n","label:  0\n","idx:  0\n","tok_flaw:  ...\n","flaw_tokens_seq:  ['...']\n","token_ids_seq:  []\n","Printing prob:  0.8679163255211668\n","label:  0\n","idx:  1\n","tok_flaw:  surprisingly\n","flaw_tokens_seq:  ['...', 'surprisingly']\n","token_ids_seq:  []\n","Printing prob:  0.3258666087363028\n","label:  0\n","idx:  2\n","tok_flaw:  inert\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert']\n","token_ids_seq:  []\n","Printing prob:  0.8770334912667972\n","label:  0\n","idx:  3\n","tok_flaw:  for\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for']\n","token_ids_seq:  []\n","Printing prob:  0.1105733738037965\n","label:  1\n","idx:  4\n","tok_flaw:  q\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for', 'q']\n","token_ids_seq:  [4]\n","Printing prob:  0.21827187249413083\n","label:  0\n","idx:  5\n","tok_flaw:  movie\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for', 'q', 'movie']\n","token_ids_seq:  [4]\n","Printing prob:  0.723455206602015\n","label:  0\n","idx:  6\n","tok_flaw:  in\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for', 'q', 'movie', 'in']\n","token_ids_seq:  [4]\n","Printing prob:  0.09583973190821138\n","label:  1\n","idx:  7\n","tok_flaw:  Khich\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for', 'q', 'movie', 'in', 'Khich']\n","token_ids_seq:  [4, 7]\n","Printing prob:  0.16631360825330288\n","label:  0\n","idx:  8\n","tok_flaw:  the\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for', 'q', 'movie', 'in', 'Khich', 'the']\n","token_ids_seq:  [4, 7]\n","Printing prob:  0.24450081026316872\n","label:  0\n","idx:  9\n","tok_flaw:  main\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for', 'q', 'movie', 'in', 'Khich', 'the', 'main']\n","token_ids_seq:  [4, 7]\n","Printing prob:  0.32708571853770096\n","label:  0\n","idx:  10\n","tok_flaw:  character\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for', 'q', 'movie', 'in', 'Khich', 'the', 'main', 'character']\n","token_ids_seq:  [4, 7]\n","Printing prob:  0.06036637754428209\n","label:  1\n","idx:  11\n","tok_flaw:  Ctravels\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for', 'q', 'movie', 'in', 'Khich', 'the', 'main', 'character', 'Ctravels']\n","token_ids_seq:  [4, 7, 11]\n","Printing prob:  0.15650824351313097\n","label:  0\n","idx:  12\n","tok_flaw:  back\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for', 'q', 'movie', 'in', 'Khich', 'the', 'main', 'character', 'Ctravels', 'back']\n","token_ids_seq:  [4, 7, 11]\n","Printing prob:  0.9959983379034414\n","label:  0\n","idx:  13\n","tok_flaw:  and\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for', 'q', 'movie', 'in', 'Khich', 'the', 'main', 'character', 'Ctravels', 'back', 'and']\n","token_ids_seq:  [4, 7, 11]\n","Printing prob:  0.5243615248888335\n","label:  0\n","idx:  14\n","tok_flaw:  forth\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for', 'q', 'movie', 'in', 'Khich', 'the', 'main', 'character', 'Ctravels', 'back', 'and', 'forth']\n","token_ids_seq:  [4, 7, 11]\n","Printing prob:  0.4243859294107106\n","label:  0\n","idx:  15\n","tok_flaw:  between\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for', 'q', 'movie', 'in', 'Khich', 'the', 'main', 'character', 'Ctravels', 'back', 'and', 'forth', 'between']\n","token_ids_seq:  [4, 7, 11]\n","Printing prob:  0.5098551691655482\n","label:  0\n","idx:  16\n","tok_flaw:  epochs\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for', 'q', 'movie', 'in', 'Khich', 'the', 'main', 'character', 'Ctravels', 'back', 'and', 'forth', 'between', 'epochs']\n","token_ids_seq:  [4, 7, 11]\n","Printing prob:  0.9619064903332472\n","label:  0\n","idx:  17\n","tok_flaw:  .\n","flaw_tokens_seq:  ['...', 'surprisingly', 'inert', 'for', 'q', 'movie', 'in', 'Khich', 'the', 'main', 'character', 'Ctravels', 'back', 'and', 'forth', 'between', 'epochs', '.']\n","token_ids_seq:  [4, 7, 11]\n","all_flaw_tokens:  [['...', 'surprisingly', 'inert', 'for', 'q', 'movie', 'in', 'Khich', 'the', 'main', 'character', 'Ctravels', 'back', 'and', 'forth', 'between', 'epochs', '.']]\n","all_token_idx:  [[4, 7, 11]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.5360055645493758\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.2087222376606157\n","label:  0\n","idx:  1\n","tok_flaw:  it\n","flaw_tokens_seq:  ['``', 'it']\n","token_ids_seq:  []\n","Printing prob:  0.038157913925742526\n","label:  1\n","idx:  2\n","tok_flaw:  herlps\n","flaw_tokens_seq:  ['``', 'it', 'herlps']\n","token_ids_seq:  [2]\n","Printing prob:  0.6168802537941012\n","label:  0\n","idx:  3\n","tok_flaw:  that\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that']\n","token_ids_seq:  [2]\n","Printing prob:  0.6177570797784996\n","label:  0\n","idx:  4\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the']\n","token_ids_seq:  [2]\n","Printing prob:  0.21624011138834554\n","label:  0\n","idx:  5\n","tok_flaw:  central\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central']\n","token_ids_seq:  [2]\n","Printing prob:  0.7048522601856763\n","label:  0\n","idx:  6\n","tok_flaw:  performers\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers']\n","token_ids_seq:  [2]\n","Printing prob:  0.6288874617269571\n","label:  0\n","idx:  7\n","tok_flaw:  are\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are']\n","token_ids_seq:  [2]\n","Printing prob:  0.1767009282069405\n","label:  0\n","idx:  8\n","tok_flaw:  experienced\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are', 'experienced']\n","token_ids_seq:  [2]\n","Printing prob:  0.35754560366216726\n","label:  0\n","idx:  9\n","tok_flaw:  actors\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are', 'experienced', 'actors']\n","token_ids_seq:  [2]\n","Printing prob:  0.9567117131869988\n","label:  0\n","idx:  10\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are', 'experienced', 'actors', ',']\n","token_ids_seq:  [2]\n","Printing prob:  0.11183321404989666\n","label:  1\n","idx:  11\n","tok_flaw:  anid\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are', 'experienced', 'actors', ',', 'anid']\n","token_ids_seq:  [2, 11]\n","Printing prob:  0.3601748920312984\n","label:  0\n","idx:  12\n","tok_flaw:  that\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are', 'experienced', 'actors', ',', 'anid', 'that']\n","token_ids_seq:  [2, 11]\n","Printing prob:  0.042394741741056285\n","label:  1\n","idx:  13\n","tok_flaw:  tzey\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are', 'experienced', 'actors', ',', 'anid', 'that', 'tzey']\n","token_ids_seq:  [2, 11, 13]\n","Printing prob:  0.6545640428895284\n","label:  0\n","idx:  14\n","tok_flaw:  know\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are', 'experienced', 'actors', ',', 'anid', 'that', 'tzey', 'know']\n","token_ids_seq:  [2, 11, 13]\n","Printing prob:  0.06525784426530323\n","label:  1\n","idx:  15\n","tok_flaw:  theeir\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are', 'experienced', 'actors', ',', 'anid', 'that', 'tzey', 'know', 'theeir']\n","token_ids_seq:  [2, 11, 13, 15]\n","Printing prob:  0.3470458292119407\n","label:  0\n","idx:  16\n","tok_flaw:  roles\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are', 'experienced', 'actors', ',', 'anid', 'that', 'tzey', 'know', 'theeir', 'roles']\n","token_ids_seq:  [2, 11, 13, 15]\n","Printing prob:  0.13668038486297474\n","label:  0\n","idx:  17\n","tok_flaw:  so\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are', 'experienced', 'actors', ',', 'anid', 'that', 'tzey', 'know', 'theeir', 'roles', 'so']\n","token_ids_seq:  [2, 11, 13, 15]\n","Printing prob:  0.0333076909141693\n","label:  1\n","idx:  18\n","tok_flaw:  wel\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are', 'experienced', 'actors', ',', 'anid', 'that', 'tzey', 'know', 'theeir', 'roles', 'so', 'wel']\n","token_ids_seq:  [2, 11, 13, 15, 18]\n","Printing prob:  0.31619033513533257\n","label:  0\n","idx:  19\n","tok_flaw:  .\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are', 'experienced', 'actors', ',', 'anid', 'that', 'tzey', 'know', 'theeir', 'roles', 'so', 'wel', '.']\n","token_ids_seq:  [2, 11, 13, 15, 18]\n","Printing prob:  0.3103914330079457\n","label:  0\n","idx:  20\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are', 'experienced', 'actors', ',', 'anid', 'that', 'tzey', 'know', 'theeir', 'roles', 'so', 'wel', '.', \"''\"]\n","token_ids_seq:  [2, 11, 13, 15, 18]\n","all_flaw_tokens:  [['``', 'it', 'herlps', 'that', 'the', 'central', 'performers', 'are', 'experienced', 'actors', ',', 'anid', 'that', 'tzey', 'know', 'theeir', 'roles', 'so', 'wel', '.', \"''\"]]\n","all_token_idx:  [[2, 11, 13, 15, 18]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.6854614718407825\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.9486579339367598\n","label:  0\n","idx:  1\n","tok_flaw:  an\n","flaw_tokens_seq:  ['``', 'an']\n","token_ids_seq:  []\n","Printing prob:  0.6584578847103579\n","label:  0\n","idx:  2\n","tok_flaw:  impressive\n","flaw_tokens_seq:  ['``', 'an', 'impressive']\n","token_ids_seq:  []\n","Printing prob:  0.6726836133641957\n","label:  0\n","idx:  3\n","tok_flaw:  debut\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut']\n","token_ids_seq:  []\n","Printing prob:  0.706328249217406\n","label:  0\n","idx:  4\n","tok_flaw:  for\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for']\n","token_ids_seq:  []\n","Printing prob:  0.04106176235382086\n","label:  1\n","idx:  5\n","tok_flaw:  first-tme\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme']\n","token_ids_seq:  [5]\n","Printing prob:  0.30426497150761833\n","label:  0\n","idx:  6\n","tok_flaw:  writer-director\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director']\n","token_ids_seq:  [5]\n","Printing prob:  0.5235775446324185\n","label:  0\n","idx:  7\n","tok_flaw:  mark\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director', 'mark']\n","token_ids_seq:  [5]\n","Printing prob:  0.7520428279627135\n","label:  0\n","idx:  8\n","tok_flaw:  romanek\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director', 'mark', 'romanek']\n","token_ids_seq:  [5]\n","Printing prob:  0.22684580165376922\n","label:  0\n","idx:  9\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director', 'mark', 'romanek', ',']\n","token_ids_seq:  [5]\n","Printing prob:  0.6166846578196169\n","label:  0\n","idx:  10\n","tok_flaw:  especially\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director', 'mark', 'romanek', ',', 'especially']\n","token_ids_seq:  [5]\n","Printing prob:  0.22390279018556347\n","label:  0\n","idx:  11\n","tok_flaw:  considering\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director', 'mark', 'romanek', ',', 'especially', 'considering']\n","token_ids_seq:  [5]\n","Printing prob:  0.7907290786936789\n","label:  0\n","idx:  12\n","tok_flaw:  his\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director', 'mark', 'romanek', ',', 'especially', 'considering', 'his']\n","token_ids_seq:  [5]\n","Printing prob:  0.8012119212723628\n","label:  0\n","idx:  13\n","tok_flaw:  background\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director', 'mark', 'romanek', ',', 'especially', 'considering', 'his', 'background']\n","token_ids_seq:  [5]\n","Printing prob:  0.34696492414960334\n","label:  0\n","idx:  14\n","tok_flaw:  is\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director', 'mark', 'romanek', ',', 'especially', 'considering', 'his', 'background', 'is']\n","token_ids_seq:  [5]\n","Printing prob:  0.1379065472118276\n","label:  0\n","idx:  15\n","tok_flaw:  in\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director', 'mark', 'romanek', ',', 'especially', 'considering', 'his', 'background', 'is', 'in']\n","token_ids_seq:  [5]\n","Printing prob:  0.3398598977617482\n","label:  0\n","idx:  16\n","tok_flaw:  music\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director', 'mark', 'romanek', ',', 'especially', 'considering', 'his', 'background', 'is', 'in', 'music']\n","token_ids_seq:  [5]\n","Printing prob:  0.4156278143596104\n","label:  0\n","idx:  17\n","tok_flaw:  video\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director', 'mark', 'romanek', ',', 'especially', 'considering', 'his', 'background', 'is', 'in', 'music', 'video']\n","token_ids_seq:  [5]\n","Printing prob:  0.11559442733702752\n","label:  1\n","idx:  18\n","tok_flaw:  p\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director', 'mark', 'romanek', ',', 'especially', 'considering', 'his', 'background', 'is', 'in', 'music', 'video', 'p']\n","token_ids_seq:  [5, 18]\n","Printing prob:  0.6056286939276274\n","label:  0\n","idx:  19\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director', 'mark', 'romanek', ',', 'especially', 'considering', 'his', 'background', 'is', 'in', 'music', 'video', 'p', \"''\"]\n","token_ids_seq:  [5, 18]\n","all_flaw_tokens:  [['``', 'an', 'impressive', 'debut', 'for', 'first-tme', 'writer-director', 'mark', 'romanek', ',', 'especially', 'considering', 'his', 'background', 'is', 'in', 'music', 'video', 'p', \"''\"]]\n","all_token_idx:  [[5, 18]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.2402785599091215\n","label:  0\n","idx:  0\n","tok_flaw:  for\n","flaw_tokens_seq:  ['for']\n","token_ids_seq:  []\n","Printing prob:  0.19806759532219687\n","label:  0\n","idx:  1\n","tok_flaw:  caine\n","flaw_tokens_seq:  ['for', 'caine']\n","token_ids_seq:  []\n","Printing prob:  0.7914281199797979\n","label:  0\n","idx:  2\n","tok_flaw:  lovers\n","flaw_tokens_seq:  ['for', 'caine', 'lovers']\n","token_ids_seq:  []\n","Printing prob:  0.13209151490158177\n","label:  0\n","idx:  3\n","tok_flaw:  only\n","flaw_tokens_seq:  ['for', 'caine', 'lovers', 'only']\n","token_ids_seq:  []\n","Printing prob:  0.4434722343373698\n","label:  0\n","idx:  4\n","tok_flaw:  .\n","flaw_tokens_seq:  ['for', 'caine', 'lovers', 'only', '.']\n","token_ids_seq:  []\n","all_flaw_tokens:  [['for', 'caine', 'lovers', 'only', '.']]\n","all_token_idx:  [[]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.14154843133058514\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.11540098038969304\n","label:  1\n","idx:  1\n","tok_flaw:  thQis\n","flaw_tokens_seq:  ['``', 'thQis']\n","token_ids_seq:  [1]\n","Printing prob:  0.6742490923400994\n","label:  0\n","idx:  2\n","tok_flaw:  film\n","flaw_tokens_seq:  ['``', 'thQis', 'film']\n","token_ids_seq:  [1]\n","Printing prob:  0.24205389693956736\n","label:  0\n","idx:  3\n","tok_flaw:  is\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is']\n","token_ids_seq:  [1]\n","Printing prob:  0.5630120359499976\n","label:  0\n","idx:  4\n","tok_flaw:  so\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so']\n","token_ids_seq:  [1]\n","Printing prob:  0.8034625775501908\n","label:  0\n","idx:  5\n","tok_flaw:  slick\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick']\n","token_ids_seq:  [1]\n","Printing prob:  0.1529545880094434\n","label:  0\n","idx:  6\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',']\n","token_ids_seq:  [1]\n","Printing prob:  0.04921320557551878\n","label:  1\n","idx:  7\n","tok_flaw:  supSerficial\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.8826828320606155\n","label:  0\n","idx:  8\n","tok_flaw:  and\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.8733967821532069\n","label:  0\n","idx:  9\n","tok_flaw:  trend-hoppy\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.8488975059220468\n","label:  0\n","idx:  10\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.5869802292651004\n","label:  0\n","idx:  11\n","tok_flaw:  that\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.8383807230562716\n","label:  0\n","idx:  12\n","tok_flaw:  it\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.5642255859888047\n","label:  0\n","idx:  13\n","tok_flaw:  's\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\"]\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.7554689700238947\n","label:  0\n","idx:  14\n","tok_flaw:  easy\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.21443687450083393\n","label:  0\n","idx:  15\n","tok_flaw:  to\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy', 'to']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.45391749368007694\n","label:  0\n","idx:  16\n","tok_flaw:  imagine\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy', 'to', 'imagine']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.5275580826241556\n","label:  0\n","idx:  17\n","tok_flaw:  that\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy', 'to', 'imagine', 'that']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.7865713222383613\n","label:  0\n","idx:  18\n","tok_flaw:  a\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy', 'to', 'imagine', 'that', 'a']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.4140567171163263\n","label:  0\n","idx:  19\n","tok_flaw:  new\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy', 'to', 'imagine', 'that', 'a', 'new']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.5934081287697592\n","label:  0\n","idx:  20\n","tok_flaw:  software\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy', 'to', 'imagine', 'that', 'a', 'new', 'software']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.28209972199527134\n","label:  0\n","idx:  21\n","tok_flaw:  program\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy', 'to', 'imagine', 'that', 'a', 'new', 'software', 'program']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.355347206572697\n","label:  0\n","idx:  22\n","tok_flaw:  spit\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy', 'to', 'imagine', 'that', 'a', 'new', 'software', 'program', 'spit']\n","token_ids_seq:  [1, 7]\n","Printing prob:  0.11831205309517634\n","label:  1\n","idx:  23\n","tok_flaw:  zout\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy', 'to', 'imagine', 'that', 'a', 'new', 'software', 'program', 'spit', 'zout']\n","token_ids_seq:  [1, 7, 23]\n","Printing prob:  0.627041526641214\n","label:  0\n","idx:  24\n","tok_flaw:  the\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy', 'to', 'imagine', 'that', 'a', 'new', 'software', 'program', 'spit', 'zout', 'the']\n","token_ids_seq:  [1, 7, 23]\n","Printing prob:  0.7260441238479408\n","label:  0\n","idx:  25\n","tok_flaw:  screenplay\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy', 'to', 'imagine', 'that', 'a', 'new', 'software', 'program', 'spit', 'zout', 'the', 'screenplay']\n","token_ids_seq:  [1, 7, 23]\n","Printing prob:  0.27805441724351765\n","label:  0\n","idx:  26\n","tok_flaw:  .\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy', 'to', 'imagine', 'that', 'a', 'new', 'software', 'program', 'spit', 'zout', 'the', 'screenplay', '.']\n","token_ids_seq:  [1, 7, 23]\n","Printing prob:  0.3838054224730095\n","label:  0\n","idx:  27\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy', 'to', 'imagine', 'that', 'a', 'new', 'software', 'program', 'spit', 'zout', 'the', 'screenplay', '.', \"''\"]\n","token_ids_seq:  [1, 7, 23]\n","all_flaw_tokens:  [['``', 'thQis', 'film', 'is', 'so', 'slick', ',', 'supSerficial', 'and', 'trend-hoppy', ',', 'that', 'it', \"'s\", 'easy', 'to', 'imagine', 'that', 'a', 'new', 'software', 'program', 'spit', 'zout', 'the', 'screenplay', '.', \"''\"]]\n","all_token_idx:  [[1, 7, 23]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.4440647677628321\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.9783271611929848\n","label:  0\n","idx:  1\n","tok_flaw:  almost\n","flaw_tokens_seq:  ['``', 'almost']\n","token_ids_seq:  []\n","Printing prob:  0.37935723955852363\n","label:  0\n","idx:  2\n","tok_flaw:  every\n","flaw_tokens_seq:  ['``', 'almost', 'every']\n","token_ids_seq:  []\n","Printing prob:  0.6279682950798485\n","label:  0\n","idx:  3\n","tok_flaw:  scene\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene']\n","token_ids_seq:  []\n","Printing prob:  0.03232884772614997\n","label:  1\n","idx:  4\n","tok_flaw:  lin\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin']\n","token_ids_seq:  [4]\n","Printing prob:  0.19550985288829326\n","label:  0\n","idx:  5\n","tok_flaw:  this\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this']\n","token_ids_seq:  [4]\n","Printing prob:  0.9186633123068523\n","label:  0\n","idx:  6\n","tok_flaw:  film\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film']\n","token_ids_seq:  [4]\n","Printing prob:  0.0651616718245367\n","label:  1\n","idx:  7\n","tok_flaw:  us\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us']\n","token_ids_seq:  [4, 7]\n","Printing prob:  0.02162760005173081\n","label:  1\n","idx:  8\n","tok_flaw:  \n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '']\n","token_ids_seq:  [4, 7, 8]\n","Printing prob:  0.9607304245790804\n","label:  0\n","idx:  9\n","tok_flaw:  gem\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem']\n","token_ids_seq:  [4, 7, 8]\n","Printing prob:  0.5373992178017847\n","label:  0\n","idx:  10\n","tok_flaw:  that\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that']\n","token_ids_seq:  [4, 7, 8]\n","Printing prob:  0.7371008335795539\n","label:  0\n","idx:  11\n","tok_flaw:  could\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could']\n","token_ids_seq:  [4, 7, 8]\n","Printing prob:  0.6067769244491736\n","label:  0\n","idx:  12\n","tok_flaw:  stand\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand']\n","token_ids_seq:  [4, 7, 8]\n","Printing prob:  0.8491708348666791\n","label:  0\n","idx:  13\n","tok_flaw:  alone\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone']\n","token_ids_seq:  [4, 7, 8]\n","Printing prob:  0.4303000805943673\n","label:  0\n","idx:  14\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone', ',']\n","token_ids_seq:  [4, 7, 8]\n","Printing prob:  0.5597893596079212\n","label:  0\n","idx:  15\n","tok_flaw:  a\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone', ',', 'a']\n","token_ids_seq:  [4, 7, 8]\n","Printing prob:  0.7205315399734885\n","label:  0\n","idx:  16\n","tok_flaw:  perfectly\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone', ',', 'a', 'perfectly']\n","token_ids_seq:  [4, 7, 8]\n","Printing prob:  0.6041291779433551\n","label:  0\n","idx:  17\n","tok_flaw:  realized\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone', ',', 'a', 'perfectly', 'realized']\n","token_ids_seq:  [4, 7, 8]\n","Printing prob:  0.8727924170012497\n","label:  0\n","idx:  18\n","tok_flaw:  observation\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone', ',', 'a', 'perfectly', 'realized', 'observation']\n","token_ids_seq:  [4, 7, 8]\n","Printing prob:  0.7570782570215021\n","label:  0\n","idx:  19\n","tok_flaw:  of\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone', ',', 'a', 'perfectly', 'realized', 'observation', 'of']\n","token_ids_seq:  [4, 7, 8]\n","Printing prob:  0.37212330146480976\n","label:  0\n","idx:  20\n","tok_flaw:  mood\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone', ',', 'a', 'perfectly', 'realized', 'observation', 'of', 'mood']\n","token_ids_seq:  [4, 7, 8]\n","Printing prob:  0.018020046272777424\n","label:  1\n","idx:  21\n","tok_flaw:  \n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone', ',', 'a', 'perfectly', 'realized', 'observation', 'of', 'mood', '']\n","token_ids_seq:  [4, 7, 8, 21]\n","Printing prob:  0.6657960950062211\n","label:  0\n","idx:  22\n","tok_flaw:  behavior\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone', ',', 'a', 'perfectly', 'realized', 'observation', 'of', 'mood', '', 'behavior']\n","token_ids_seq:  [4, 7, 8, 21]\n","Printing prob:  0.47792629688525445\n","label:  0\n","idx:  23\n","tok_flaw:  and\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone', ',', 'a', 'perfectly', 'realized', 'observation', 'of', 'mood', '', 'behavior', 'and']\n","token_ids_seq:  [4, 7, 8, 21]\n","Printing prob:  0.12333848498373101\n","label:  0\n","idx:  24\n","tok_flaw:  intent\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone', ',', 'a', 'perfectly', 'realized', 'observation', 'of', 'mood', '', 'behavior', 'and', 'intent']\n","token_ids_seq:  [4, 7, 8, 21]\n","Printing prob:  0.5099085169425603\n","label:  0\n","idx:  25\n","tok_flaw:  .\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone', ',', 'a', 'perfectly', 'realized', 'observation', 'of', 'mood', '', 'behavior', 'and', 'intent', '.']\n","token_ids_seq:  [4, 7, 8, 21]\n","Printing prob:  0.9122693494884809\n","label:  0\n","idx:  26\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone', ',', 'a', 'perfectly', 'realized', 'observation', 'of', 'mood', '', 'behavior', 'and', 'intent', '.', \"''\"]\n","token_ids_seq:  [4, 7, 8, 21]\n","all_flaw_tokens:  [['``', 'almost', 'every', 'scene', 'lin', 'this', 'film', 'us', '', 'gem', 'that', 'could', 'stand', 'alone', ',', 'a', 'perfectly', 'realized', 'observation', 'of', 'mood', '', 'behavior', 'and', 'intent', '.', \"''\"]]\n","all_token_idx:  [[4, 7, 8, 21]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","attacks:  99% 1807/1820 [00:35<00:00, 41.05it/s]emb_dict:  None\n","embeddings: None\n","Printing prob:  0.6934000760411054\n","label:  0\n","idx:  0\n","tok_flaw:  a\n","flaw_tokens_seq:  ['a']\n","token_ids_seq:  []\n","Printing prob:  0.049105868968112976\n","label:  1\n","idx:  1\n","tok_flaw:  monxter\n","flaw_tokens_seq:  ['a', 'monxter']\n","token_ids_seq:  [1]\n","Printing prob:  0.8290844486837562\n","label:  0\n","idx:  2\n","tok_flaw:  combat\n","flaw_tokens_seq:  ['a', 'monxter', 'combat']\n","token_ids_seq:  [1]\n","Printing prob:  0.05969143565777579\n","label:  1\n","idx:  3\n","tok_flaw:  thtiller\n","flaw_tokens_seq:  ['a', 'monxter', 'combat', 'thtiller']\n","token_ids_seq:  [1, 3]\n","Printing prob:  0.057995964652187815\n","label:  1\n","idx:  4\n","tok_flaw:  a\n","flaw_tokens_seq:  ['a', 'monxter', 'combat', 'thtiller', 'a']\n","token_ids_seq:  [1, 3, 4]\n","Printing prob:  0.3906135728746192\n","label:  0\n","idx:  5\n","tok_flaw:  impersonal\n","flaw_tokens_seq:  ['a', 'monxter', 'combat', 'thtiller', 'a', 'impersonal']\n","token_ids_seq:  [1, 3, 4]\n","Printing prob:  0.11650526966429786\n","label:  1\n","idx:  6\n","tok_flaw:  iY\n","flaw_tokens_seq:  ['a', 'monxter', 'combat', 'thtiller', 'a', 'impersonal', 'iY']\n","token_ids_seq:  [1, 3, 4, 6]\n","Printing prob:  0.9546704309769528\n","label:  0\n","idx:  7\n","tok_flaw:  its\n","flaw_tokens_seq:  ['a', 'monxter', 'combat', 'thtiller', 'a', 'impersonal', 'iY', 'its']\n","token_ids_seq:  [1, 3, 4, 6]\n","Printing prob:  0.8755886280871278\n","label:  0\n","idx:  8\n","tok_flaw:  relentlessness\n","flaw_tokens_seq:  ['a', 'monxter', 'combat', 'thtiller', 'a', 'impersonal', 'iY', 'its', 'relentlessness']\n","token_ids_seq:  [1, 3, 4, 6]\n","Printing prob:  0.8750326326530316\n","label:  0\n","idx:  9\n","tok_flaw:  as\n","flaw_tokens_seq:  ['a', 'monxter', 'combat', 'thtiller', 'a', 'impersonal', 'iY', 'its', 'relentlessness', 'as']\n","token_ids_seq:  [1, 3, 4, 6]\n","Printing prob:  0.6139278268806402\n","label:  0\n","idx:  10\n","tok_flaw:  the\n","flaw_tokens_seq:  ['a', 'monxter', 'combat', 'thtiller', 'a', 'impersonal', 'iY', 'its', 'relentlessness', 'as', 'the']\n","token_ids_seq:  [1, 3, 4, 6]\n","Printing prob:  0.20166275243342147\n","label:  0\n","idx:  11\n","tok_flaw:  videogame\n","flaw_tokens_seq:  ['a', 'monxter', 'combat', 'thtiller', 'a', 'impersonal', 'iY', 'its', 'relentlessness', 'as', 'the', 'videogame']\n","token_ids_seq:  [1, 3, 4, 6]\n","Printing prob:  0.25623271208336673\n","label:  0\n","idx:  12\n","tok_flaw:  series\n","flaw_tokens_seq:  ['a', 'monxter', 'combat', 'thtiller', 'a', 'impersonal', 'iY', 'its', 'relentlessness', 'as', 'the', 'videogame', 'series']\n","token_ids_seq:  [1, 3, 4, 6]\n","Printing prob:  0.9837632824764714\n","label:  0\n","idx:  13\n","tok_flaw:  that\n","flaw_tokens_seq:  ['a', 'monxter', 'combat', 'thtiller', 'a', 'impersonal', 'iY', 'its', 'relentlessness', 'as', 'the', 'videogame', 'series', 'that']\n","token_ids_seq:  [1, 3, 4, 6]\n","Printing prob:  0.5899449150819501\n","label:  0\n","idx:  14\n","tok_flaw:  inspired\n","flaw_tokens_seq:  ['a', 'monxter', 'combat', 'thtiller', 'a', 'impersonal', 'iY', 'its', 'relentlessness', 'as', 'the', 'videogame', 'series', 'that', 'inspired']\n","token_ids_seq:  [1, 3, 4, 6]\n","Printing prob:  0.7484345942217425\n","label:  0\n","idx:  15\n","tok_flaw:  it\n","flaw_tokens_seq:  ['a', 'monxter', 'combat', 'thtiller', 'a', 'impersonal', 'iY', 'its', 'relentlessness', 'as', 'the', 'videogame', 'series', 'that', 'inspired', 'it']\n","token_ids_seq:  [1, 3, 4, 6]\n","Printing prob:  0.9460997529680774\n","label:  0\n","idx:  16\n","tok_flaw:  .\n","flaw_tokens_seq:  ['a', 'monxter', 'combat', 'thtiller', 'a', 'impersonal', 'iY', 'its', 'relentlessness', 'as', 'the', 'videogame', 'series', 'that', 'inspired', 'it', '.']\n","token_ids_seq:  [1, 3, 4, 6]\n","all_flaw_tokens:  [['a', 'monxter', 'combat', 'thtiller', 'a', 'impersonal', 'iY', 'its', 'relentlessness', 'as', 'the', 'videogame', 'series', 'that', 'inspired', 'it', '.']]\n","all_token_idx:  [[1, 3, 4, 6]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.6983634426280082\n","label:  0\n","idx:  0\n","tok_flaw:  rates\n","flaw_tokens_seq:  ['rates']\n","token_ids_seq:  []\n","Printing prob:  0.7863795940483206\n","label:  0\n","idx:  1\n","tok_flaw:  an\n","flaw_tokens_seq:  ['rates', 'an']\n","token_ids_seq:  []\n","Printing prob:  0.4813879962288877\n","label:  0\n","idx:  2\n","tok_flaw:  `\n","flaw_tokens_seq:  ['rates', 'an', '`']\n","token_ids_seq:  []\n","Printing prob:  0.49451416535719395\n","label:  0\n","idx:  3\n","tok_flaw:  e\n","flaw_tokens_seq:  ['rates', 'an', '`', 'e']\n","token_ids_seq:  []\n","Printing prob:  0.6549119607978823\n","label:  0\n","idx:  4\n","tok_flaw:  '\n","flaw_tokens_seq:  ['rates', 'an', '`', 'e', \"'\"]\n","token_ids_seq:  []\n","Printing prob:  0.633982652868543\n","label:  0\n","idx:  5\n","tok_flaw:  for\n","flaw_tokens_seq:  ['rates', 'an', '`', 'e', \"'\", 'for']\n","token_ids_seq:  []\n","Printing prob:  0.08056100526110777\n","label:  1\n","idx:  6\n","tok_flaw:  enffort\n","flaw_tokens_seq:  ['rates', 'an', '`', 'e', \"'\", 'for', 'enffort']\n","token_ids_seq:  [6]\n","Printing prob:  0.7647841187513088\n","label:  0\n","idx:  7\n","tok_flaw:  --\n","flaw_tokens_seq:  ['rates', 'an', '`', 'e', \"'\", 'for', 'enffort', '--']\n","token_ids_seq:  [6]\n","Printing prob:  0.5840121361933888\n","label:  0\n","idx:  8\n","tok_flaw:  and\n","flaw_tokens_seq:  ['rates', 'an', '`', 'e', \"'\", 'for', 'enffort', '--', 'and']\n","token_ids_seq:  [6]\n","Printing prob:  0.25567045584676606\n","label:  0\n","idx:  9\n","tok_flaw:  a\n","flaw_tokens_seq:  ['rates', 'an', '`', 'e', \"'\", 'for', 'enffort', '--', 'and', 'a']\n","token_ids_seq:  [6]\n","Printing prob:  0.5415229203990832\n","label:  0\n","idx:  10\n","tok_flaw:  `\n","flaw_tokens_seq:  ['rates', 'an', '`', 'e', \"'\", 'for', 'enffort', '--', 'and', 'a', '`']\n","token_ids_seq:  [6]\n","Printing prob:  0.8308050790464193\n","label:  0\n","idx:  11\n","tok_flaw:  b\n","flaw_tokens_seq:  ['rates', 'an', '`', 'e', \"'\", 'for', 'enffort', '--', 'and', 'a', '`', 'b']\n","token_ids_seq:  [6]\n","Printing prob:  0.6167429745114716\n","label:  0\n","idx:  12\n","tok_flaw:  '\n","flaw_tokens_seq:  ['rates', 'an', '`', 'e', \"'\", 'for', 'enffort', '--', 'and', 'a', '`', 'b', \"'\"]\n","token_ids_seq:  [6]\n","Printing prob:  0.2580906930764396\n","label:  0\n","idx:  13\n","tok_flaw:  for\n","flaw_tokens_seq:  ['rates', 'an', '`', 'e', \"'\", 'for', 'enffort', '--', 'and', 'a', '`', 'b', \"'\", 'for']\n","token_ids_seq:  [6]\n","Printing prob:  0.0975043872892084\n","label:  1\n","idx:  14\n","tok_flaw:  bobring\n","flaw_tokens_seq:  ['rates', 'an', '`', 'e', \"'\", 'for', 'enffort', '--', 'and', 'a', '`', 'b', \"'\", 'for', 'bobring']\n","token_ids_seq:  [6, 14]\n","Printing prob:  0.27478355359650464\n","label:  0\n","idx:  15\n","tok_flaw:  .\n","flaw_tokens_seq:  ['rates', 'an', '`', 'e', \"'\", 'for', 'enffort', '--', 'and', 'a', '`', 'b', \"'\", 'for', 'bobring', '.']\n","token_ids_seq:  [6, 14]\n","all_flaw_tokens:  [['rates', 'an', '`', 'e', \"'\", 'for', 'enffort', '--', 'and', 'a', '`', 'b', \"'\", 'for', 'bobring', '.']]\n","all_token_idx:  [[6, 14]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.5884804823741867\n","label:  0\n","idx:  0\n","tok_flaw:  the\n","flaw_tokens_seq:  ['the']\n","token_ids_seq:  []\n","Printing prob:  0.4283438498734278\n","label:  0\n","idx:  1\n","tok_flaw:  cast\n","flaw_tokens_seq:  ['the', 'cast']\n","token_ids_seq:  []\n","Printing prob:  0.4056448084289731\n","label:  0\n","idx:  2\n","tok_flaw:  is\n","flaw_tokens_seq:  ['the', 'cast', 'is']\n","token_ids_seq:  []\n","Printing prob:  0.3438448518667132\n","label:  0\n","idx:  3\n","tok_flaw:  uniformly\n","flaw_tokens_seq:  ['the', 'cast', 'is', 'uniformly']\n","token_ids_seq:  []\n","Printing prob:  0.7582746973089637\n","label:  0\n","idx:  4\n","tok_flaw:  excellent\n","flaw_tokens_seq:  ['the', 'cast', 'is', 'uniformly', 'excellent']\n","token_ids_seq:  []\n","Printing prob:  0.20336139063095848\n","label:  0\n","idx:  5\n","tok_flaw:  and\n","flaw_tokens_seq:  ['the', 'cast', 'is', 'uniformly', 'excellent', 'and']\n","token_ids_seq:  []\n","Printing prob:  0.310423753448124\n","label:  0\n","idx:  6\n","tok_flaw:  relaxed\n","flaw_tokens_seq:  ['the', 'cast', 'is', 'uniformly', 'excellent', 'and', 'relaxed']\n","token_ids_seq:  []\n","Printing prob:  0.9396347214787742\n","label:  0\n","idx:  7\n","tok_flaw:  .\n","flaw_tokens_seq:  ['the', 'cast', 'is', 'uniformly', 'excellent', 'and', 'relaxed', '.']\n","token_ids_seq:  []\n","all_flaw_tokens:  [['the', 'cast', 'is', 'uniformly', 'excellent', 'and', 'relaxed', '.']]\n","all_token_idx:  [[]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.2642446261079776\n","label:  0\n","idx:  0\n","tok_flaw:  the\n","flaw_tokens_seq:  ['the']\n","token_ids_seq:  []\n","Printing prob:  0.01886070970059095\n","label:  1\n","idx:  1\n","tok_flaw:  impacS\n","flaw_tokens_seq:  ['the', 'impacS']\n","token_ids_seq:  [1]\n","Printing prob:  0.1976955166131017\n","label:  0\n","idx:  2\n","tok_flaw:  of\n","flaw_tokens_seq:  ['the', 'impacS', 'of']\n","token_ids_seq:  [1]\n","Printing prob:  0.6061774837955344\n","label:  0\n","idx:  3\n","tok_flaw:  the\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the']\n","token_ids_seq:  [1]\n","Printing prob:  0.06252602737531088\n","label:  1\n","idx:  4\n","tok_flaw:  armeniban\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the', 'armeniban']\n","token_ids_seq:  [1, 4]\n","Printing prob:  0.8824125562747815\n","label:  0\n","idx:  5\n","tok_flaw:  genocide\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the', 'armeniban', 'genocide']\n","token_ids_seq:  [1, 4]\n","Printing prob:  0.3916213270223837\n","label:  0\n","idx:  6\n","tok_flaw:  is\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the', 'armeniban', 'genocide', 'is']\n","token_ids_seq:  [1, 4]\n","Printing prob:  0.614459168219024\n","label:  0\n","idx:  7\n","tok_flaw:  diluted\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the', 'armeniban', 'genocide', 'is', 'diluted']\n","token_ids_seq:  [1, 4]\n","Printing prob:  0.7006632958629031\n","label:  0\n","idx:  8\n","tok_flaw:  by\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the', 'armeniban', 'genocide', 'is', 'diluted', 'by']\n","token_ids_seq:  [1, 4]\n","Printing prob:  0.2033774334521149\n","label:  0\n","idx:  9\n","tok_flaw:  too\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the', 'armeniban', 'genocide', 'is', 'diluted', 'by', 'too']\n","token_ids_seq:  [1, 4]\n","Printing prob:  0.8289335660507836\n","label:  0\n","idx:  10\n","tok_flaw:  much\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the', 'armeniban', 'genocide', 'is', 'diluted', 'by', 'too', 'much']\n","token_ids_seq:  [1, 4]\n","Printing prob:  0.3828937286290137\n","label:  0\n","idx:  11\n","tok_flaw:  stage\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the', 'armeniban', 'genocide', 'is', 'diluted', 'by', 'too', 'much', 'stage']\n","token_ids_seq:  [1, 4]\n","Printing prob:  0.48528861179836336\n","label:  0\n","idx:  12\n","tok_flaw:  business\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the', 'armeniban', 'genocide', 'is', 'diluted', 'by', 'too', 'much', 'stage', 'business']\n","token_ids_seq:  [1, 4]\n","Printing prob:  0.6217861290013991\n","label:  0\n","idx:  13\n","tok_flaw:  in\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the', 'armeniban', 'genocide', 'is', 'diluted', 'by', 'too', 'much', 'stage', 'business', 'in']\n","token_ids_seq:  [1, 4]\n","Printing prob:  0.03470668511444597\n","label:  1\n","idx:  14\n","tok_flaw:  tfhe\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the', 'armeniban', 'genocide', 'is', 'diluted', 'by', 'too', 'much', 'stage', 'business', 'in', 'tfhe']\n","token_ids_seq:  [1, 4, 14]\n","Printing prob:  0.9169276104189015\n","label:  0\n","idx:  15\n","tok_flaw:  modern\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the', 'armeniban', 'genocide', 'is', 'diluted', 'by', 'too', 'much', 'stage', 'business', 'in', 'tfhe', 'modern']\n","token_ids_seq:  [1, 4, 14]\n","Printing prob:  0.2361840410314211\n","label:  0\n","idx:  16\n","tok_flaw:  day\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the', 'armeniban', 'genocide', 'is', 'diluted', 'by', 'too', 'much', 'stage', 'business', 'in', 'tfhe', 'modern', 'day']\n","token_ids_seq:  [1, 4, 14]\n","Printing prob:  0.6084465490583586\n","label:  0\n","idx:  17\n","tok_flaw:  .\n","flaw_tokens_seq:  ['the', 'impacS', 'of', 'the', 'armeniban', 'genocide', 'is', 'diluted', 'by', 'too', 'much', 'stage', 'business', 'in', 'tfhe', 'modern', 'day', '.']\n","token_ids_seq:  [1, 4, 14]\n","all_flaw_tokens:  [['the', 'impacS', 'of', 'the', 'armeniban', 'genocide', 'is', 'diluted', 'by', 'too', 'much', 'stage', 'business', 'in', 'tfhe', 'modern', 'day', '.']]\n","all_token_idx:  [[1, 4, 14]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.24997047730570732\n","label:  0\n","idx:  0\n","tok_flaw:  the\n","flaw_tokens_seq:  ['the']\n","token_ids_seq:  []\n","Printing prob:  0.49650653848860793\n","label:  0\n","idx:  1\n","tok_flaw:  tenderness\n","flaw_tokens_seq:  ['the', 'tenderness']\n","token_ids_seq:  []\n","Printing prob:  0.27080363326056267\n","label:  0\n","idx:  2\n","tok_flaw:  of\n","flaw_tokens_seq:  ['the', 'tenderness', 'of']\n","token_ids_seq:  []\n","Printing prob:  0.6561634778085232\n","label:  0\n","idx:  3\n","tok_flaw:  the\n","flaw_tokens_seq:  ['the', 'tenderness', 'of', 'the']\n","token_ids_seq:  []\n","Printing prob:  0.16933132253342387\n","label:  0\n","idx:  4\n","tok_flaw:  piece\n","flaw_tokens_seq:  ['the', 'tenderness', 'of', 'the', 'piece']\n","token_ids_seq:  []\n","Printing prob:  0.38484038335063964\n","label:  0\n","idx:  5\n","tok_flaw:  is\n","flaw_tokens_seq:  ['the', 'tenderness', 'of', 'the', 'piece', 'is']\n","token_ids_seq:  []\n","Printing prob:  0.8115525690981134\n","label:  0\n","idx:  6\n","tok_flaw:  still\n","flaw_tokens_seq:  ['the', 'tenderness', 'of', 'the', 'piece', 'is', 'still']\n","token_ids_seq:  []\n","Printing prob:  0.021478743905459452\n","label:  1\n","idx:  7\n","tok_flaw:  inact\n","flaw_tokens_seq:  ['the', 'tenderness', 'of', 'the', 'piece', 'is', 'still', 'inact']\n","token_ids_seq:  [7]\n","Printing prob:  0.6459933156874802\n","label:  0\n","idx:  8\n","tok_flaw:  .\n","flaw_tokens_seq:  ['the', 'tenderness', 'of', 'the', 'piece', 'is', 'still', 'inact', '.']\n","token_ids_seq:  [7]\n","all_flaw_tokens:  [['the', 'tenderness', 'of', 'the', 'piece', 'is', 'still', 'inact', '.']]\n","all_token_idx:  [[7]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.10391299207147253\n","label:  1\n","idx:  0\n","tok_flaw:  q``\n","flaw_tokens_seq:  ['q``']\n","token_ids_seq:  [0]\n","Printing prob:  0.04057864724082172\n","label:  1\n","idx:  1\n","tok_flaw:  Ahile\n","flaw_tokens_seq:  ['q``', 'Ahile']\n","token_ids_seq:  [0, 1]\n","Printing prob:  0.9048182889081633\n","label:  0\n","idx:  2\n","tok_flaw:  super\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super']\n","token_ids_seq:  [0, 1]\n","Printing prob:  0.7104917353285549\n","label:  0\n","idx:  3\n","tok_flaw:  troopers\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers']\n","token_ids_seq:  [0, 1]\n","Printing prob:  0.3219713357655143\n","label:  0\n","idx:  4\n","tok_flaw:  is\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is']\n","token_ids_seq:  [0, 1]\n","Printing prob:  0.1049503044021084\n","label:  1\n","idx:  5\n","tok_flaw:  aboSve\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve']\n","token_ids_seq:  [0, 1, 5]\n","Printing prob:  0.10443657098836368\n","label:  1\n","idx:  6\n","tok_flaw:  acadmy\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy']\n","token_ids_seq:  [0, 1, 5, 6]\n","Printing prob:  0.9222177762091883\n","label:  0\n","idx:  7\n","tok_flaw:  standards\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards']\n","token_ids_seq:  [0, 1, 5, 6]\n","Printing prob:  0.4437146486866336\n","label:  0\n","idx:  8\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards', ',']\n","token_ids_seq:  [0, 1, 5, 6]\n","Printing prob:  0.15556067681510233\n","label:  0\n","idx:  9\n","tok_flaw:  its\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards', ',', 'its']\n","token_ids_seq:  [0, 1, 5, 6]\n","Printing prob:  0.7937899421170539\n","label:  0\n","idx:  10\n","tok_flaw:  quintet\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards', ',', 'its', 'quintet']\n","token_ids_seq:  [0, 1, 5, 6]\n","Printing prob:  0.8476927039533403\n","label:  0\n","idx:  11\n","tok_flaw:  of\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards', ',', 'its', 'quintet', 'of']\n","token_ids_seq:  [0, 1, 5, 6]\n","Printing prob:  0.7452219088076613\n","label:  0\n","idx:  12\n","tok_flaw:  writers\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards', ',', 'its', 'quintet', 'of', 'writers']\n","token_ids_seq:  [0, 1, 5, 6]\n","Printing prob:  0.10339242782664093\n","label:  1\n","idx:  13\n","tok_flaw:  culd\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards', ',', 'its', 'quintet', 'of', 'writers', 'culd']\n","token_ids_seq:  [0, 1, 5, 6, 13]\n","Printing prob:  0.9885903818233682\n","label:  0\n","idx:  14\n","tok_flaw:  still\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards', ',', 'its', 'quintet', 'of', 'writers', 'culd', 'still']\n","token_ids_seq:  [0, 1, 5, 6, 13]\n","Printing prob:  0.12136382196547846\n","label:  0\n","idx:  15\n","tok_flaw:  use\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards', ',', 'its', 'quintet', 'of', 'writers', 'culd', 'still', 'use']\n","token_ids_seq:  [0, 1, 5, 6, 13]\n","Printing prob:  0.6316122055751207\n","label:  0\n","idx:  16\n","tok_flaw:  some\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards', ',', 'its', 'quintet', 'of', 'writers', 'culd', 'still', 'use', 'some']\n","token_ids_seq:  [0, 1, 5, 6, 13]\n","Printing prob:  0.7988225888032596\n","label:  0\n","idx:  17\n","tok_flaw:  more\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards', ',', 'its', 'quintet', 'of', 'writers', 'culd', 'still', 'use', 'some', 'more']\n","token_ids_seq:  [0, 1, 5, 6, 13]\n","Printing prob:  0.6472767184721678\n","label:  0\n","idx:  18\n","tok_flaw:  schooling\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards', ',', 'its', 'quintet', 'of', 'writers', 'culd', 'still', 'use', 'some', 'more', 'schooling']\n","token_ids_seq:  [0, 1, 5, 6, 13]\n","Printing prob:  0.06733836902358203\n","label:  1\n","idx:  19\n","tok_flaw:  f\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards', ',', 'its', 'quintet', 'of', 'writers', 'culd', 'still', 'use', 'some', 'more', 'schooling', 'f']\n","token_ids_seq:  [0, 1, 5, 6, 13, 19]\n","Printing prob:  0.32662870861745785\n","label:  0\n","idx:  20\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards', ',', 'its', 'quintet', 'of', 'writers', 'culd', 'still', 'use', 'some', 'more', 'schooling', 'f', \"''\"]\n","token_ids_seq:  [0, 1, 5, 6, 13, 19]\n","all_flaw_tokens:  [['q``', 'Ahile', 'super', 'troopers', 'is', 'aboSve', 'acadmy', 'standards', ',', 'its', 'quintet', 'of', 'writers', 'culd', 'still', 'use', 'some', 'more', 'schooling', 'f', \"''\"]]\n","all_token_idx:  [[0, 1, 5, 6, 13, 19]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.38515050694313113\n","label:  0\n","idx:  0\n","tok_flaw:  full\n","flaw_tokens_seq:  ['full']\n","token_ids_seq:  []\n","Printing prob:  0.29256523780943955\n","label:  0\n","idx:  1\n","tok_flaw:  frontal\n","flaw_tokens_seq:  ['full', 'frontal']\n","token_ids_seq:  []\n","Printing prob:  0.37191902682064815\n","label:  0\n","idx:  2\n","tok_flaw:  is\n","flaw_tokens_seq:  ['full', 'frontal', 'is']\n","token_ids_seq:  []\n","Printing prob:  0.6378517045939502\n","label:  0\n","idx:  3\n","tok_flaw:  the\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the']\n","token_ids_seq:  []\n","Printing prob:  0.8819722557975396\n","label:  0\n","idx:  4\n","tok_flaw:  antidote\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote']\n","token_ids_seq:  []\n","Printing prob:  0.9419894825626233\n","label:  0\n","idx:  5\n","tok_flaw:  for\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for']\n","token_ids_seq:  []\n","Printing prob:  0.5481254652780743\n","label:  0\n","idx:  6\n","tok_flaw:  soderbergh\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh']\n","token_ids_seq:  []\n","Printing prob:  0.10120450605485287\n","label:  1\n","idx:  7\n","tok_flaw:  fais\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais']\n","token_ids_seq:  [7]\n","Printing prob:  0.49253569153026144\n","label:  0\n","idx:  8\n","tok_flaw:  who\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who']\n","token_ids_seq:  [7]\n","Printing prob:  0.8206527174523036\n","label:  0\n","idx:  9\n","tok_flaw:  think\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think']\n","token_ids_seq:  [7]\n","Printing prob:  0.8010843548483889\n","label:  0\n","idx:  10\n","tok_flaw:  he\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think', 'he']\n","token_ids_seq:  [7]\n","Printing prob:  0.049384996444879925\n","label:  1\n","idx:  11\n","tok_flaw:  'cs\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think', 'he', \"'cs\"]\n","token_ids_seq:  [7, 11]\n","Printing prob:  0.5983474913815002\n","label:  0\n","idx:  12\n","tok_flaw:  gone\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think', 'he', \"'cs\", 'gone']\n","token_ids_seq:  [7, 11]\n","Printing prob:  0.8940121472825268\n","label:  0\n","idx:  13\n","tok_flaw:  too\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think', 'he', \"'cs\", 'gone', 'too']\n","token_ids_seq:  [7, 11]\n","Printing prob:  0.7285803646882029\n","label:  0\n","idx:  14\n","tok_flaw:  commercial\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think', 'he', \"'cs\", 'gone', 'too', 'commercial']\n","token_ids_seq:  [7, 11]\n","Printing prob:  0.620446781289983\n","label:  0\n","idx:  15\n","tok_flaw:  since\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think', 'he', \"'cs\", 'gone', 'too', 'commercial', 'since']\n","token_ids_seq:  [7, 11]\n","Printing prob:  0.5119269436956542\n","label:  0\n","idx:  16\n","tok_flaw:  his\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think', 'he', \"'cs\", 'gone', 'too', 'commercial', 'since', 'his']\n","token_ids_seq:  [7, 11]\n","Printing prob:  0.4948308718887341\n","label:  0\n","idx:  17\n","tok_flaw:  two\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think', 'he', \"'cs\", 'gone', 'too', 'commercial', 'since', 'his', 'two']\n","token_ids_seq:  [7, 11]\n","Printing prob:  0.6877748366743414\n","label:  0\n","idx:  18\n","tok_flaw:  oscar\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think', 'he', \"'cs\", 'gone', 'too', 'commercial', 'since', 'his', 'two', 'oscar']\n","token_ids_seq:  [7, 11]\n","Printing prob:  0.030564723763080393\n","label:  1\n","idx:  19\n","tok_flaw:  nominatd\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think', 'he', \"'cs\", 'gone', 'too', 'commercial', 'since', 'his', 'two', 'oscar', 'nominatd']\n","token_ids_seq:  [7, 11, 19]\n","Printing prob:  0.9263842471829254\n","label:  0\n","idx:  20\n","tok_flaw:  films\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think', 'he', \"'cs\", 'gone', 'too', 'commercial', 'since', 'his', 'two', 'oscar', 'nominatd', 'films']\n","token_ids_seq:  [7, 11, 19]\n","Printing prob:  0.04826926742857607\n","label:  1\n","idx:  21\n","tok_flaw:  ian\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think', 'he', \"'cs\", 'gone', 'too', 'commercial', 'since', 'his', 'two', 'oscar', 'nominatd', 'films', 'ian']\n","token_ids_seq:  [7, 11, 19, 21]\n","Printing prob:  0.5033922415244582\n","label:  0\n","idx:  22\n","tok_flaw:  2000\n","flaw_tokens_seq:  ['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think', 'he', \"'cs\", 'gone', 'too', 'commercial', 'since', 'his', 'two', 'oscar', 'nominatd', 'films', 'ian', '2000']\n","token_ids_seq:  [7, 11, 19, 21]\n","all_flaw_tokens:  [['full', 'frontal', 'is', 'the', 'antidote', 'for', 'soderbergh', 'fais', 'who', 'think', 'he', \"'cs\", 'gone', 'too', 'commercial', 'since', 'his', 'two', 'oscar', 'nominatd', 'films', 'ian', '2000']]\n","all_token_idx:  [[7, 11, 19, 21]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","attacks: 100% 1814/1820 [00:35<00:00, 46.58it/s]emb_dict:  None\n","embeddings: None\n","Printing prob:  0.9221104801481952\n","label:  0\n","idx:  0\n","tok_flaw:  ``\n","flaw_tokens_seq:  ['``']\n","token_ids_seq:  []\n","Printing prob:  0.9714203262731216\n","label:  0\n","idx:  1\n","tok_flaw:  thoughtful\n","flaw_tokens_seq:  ['``', 'thoughtful']\n","token_ids_seq:  []\n","Printing prob:  0.4245142598177315\n","label:  0\n","idx:  2\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['``', 'thoughtful', ',']\n","token_ids_seq:  []\n","Printing prob:  0.3660521886449155\n","label:  0\n","idx:  3\n","tok_flaw:  provocative\n","flaw_tokens_seq:  ['``', 'thoughtful', ',', 'provocative']\n","token_ids_seq:  []\n","Printing prob:  0.6606205117764503\n","label:  0\n","idx:  4\n","tok_flaw:  and\n","flaw_tokens_seq:  ['``', 'thoughtful', ',', 'provocative', 'and']\n","token_ids_seq:  []\n","Printing prob:  0.9716124574231403\n","label:  0\n","idx:  5\n","tok_flaw:  entertaining\n","flaw_tokens_seq:  ['``', 'thoughtful', ',', 'provocative', 'and', 'entertaining']\n","token_ids_seq:  []\n","Printing prob:  0.2838261832632204\n","label:  0\n","idx:  6\n","tok_flaw:  .\n","flaw_tokens_seq:  ['``', 'thoughtful', ',', 'provocative', 'and', 'entertaining', '.']\n","token_ids_seq:  []\n","Printing prob:  0.13933211228317588\n","label:  0\n","idx:  7\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['``', 'thoughtful', ',', 'provocative', 'and', 'entertaining', '.', \"''\"]\n","token_ids_seq:  []\n","all_flaw_tokens:  [['``', 'thoughtful', ',', 'provocative', 'and', 'entertaining', '.', \"''\"]]\n","all_token_idx:  [[]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.7243329306289227\n","label:  0\n","idx:  0\n","tok_flaw:  an\n","flaw_tokens_seq:  ['an']\n","token_ids_seq:  []\n","Printing prob:  0.01216400825638786\n","label:  1\n","idx:  1\n","tok_flaw:  unZeven\n","flaw_tokens_seq:  ['an', 'unZeven']\n","token_ids_seq:  [1]\n","Printing prob:  0.8899925302275015\n","label:  0\n","idx:  2\n","tok_flaw:  but\n","flaw_tokens_seq:  ['an', 'unZeven', 'but']\n","token_ids_seq:  [1]\n","Printing prob:  0.5562897322830138\n","label:  0\n","idx:  3\n","tok_flaw:  intriguing\n","flaw_tokens_seq:  ['an', 'unZeven', 'but', 'intriguing']\n","token_ids_seq:  [1]\n","Printing prob:  0.3686612135479771\n","label:  0\n","idx:  4\n","tok_flaw:  drama\n","flaw_tokens_seq:  ['an', 'unZeven', 'but', 'intriguing', 'drama']\n","token_ids_seq:  [1]\n","Printing prob:  0.6879917487909106\n","label:  0\n","idx:  5\n","tok_flaw:  that\n","flaw_tokens_seq:  ['an', 'unZeven', 'but', 'intriguing', 'drama', 'that']\n","token_ids_seq:  [1]\n","Printing prob:  0.4430534026087123\n","label:  0\n","idx:  6\n","tok_flaw:  is\n","flaw_tokens_seq:  ['an', 'unZeven', 'but', 'intriguing', 'drama', 'that', 'is']\n","token_ids_seq:  [1]\n","Printing prob:  0.35376979676129916\n","label:  0\n","idx:  7\n","tok_flaw:  part\n","flaw_tokens_seq:  ['an', 'unZeven', 'but', 'intriguing', 'drama', 'that', 'is', 'part']\n","token_ids_seq:  [1]\n","Printing prob:  0.26237418226023956\n","label:  0\n","idx:  8\n","tok_flaw:  homage\n","flaw_tokens_seq:  ['an', 'unZeven', 'but', 'intriguing', 'drama', 'that', 'is', 'part', 'homage']\n","token_ids_seq:  [1]\n","Printing prob:  0.1415486180558535\n","label:  0\n","idx:  9\n","tok_flaw:  and\n","flaw_tokens_seq:  ['an', 'unZeven', 'but', 'intriguing', 'drama', 'that', 'is', 'part', 'homage', 'and']\n","token_ids_seq:  [1]\n","Printing prob:  0.2778935902412829\n","label:  0\n","idx:  10\n","tok_flaw:  part\n","flaw_tokens_seq:  ['an', 'unZeven', 'but', 'intriguing', 'drama', 'that', 'is', 'part', 'homage', 'and', 'part']\n","token_ids_seq:  [1]\n","Printing prob:  0.16743197489978612\n","label:  0\n","idx:  11\n","tok_flaw:  remake\n","flaw_tokens_seq:  ['an', 'unZeven', 'but', 'intriguing', 'drama', 'that', 'is', 'part', 'homage', 'and', 'part', 'remake']\n","token_ids_seq:  [1]\n","Printing prob:  0.23138123211261885\n","label:  0\n","idx:  12\n","tok_flaw:  of\n","flaw_tokens_seq:  ['an', 'unZeven', 'but', 'intriguing', 'drama', 'that', 'is', 'part', 'homage', 'and', 'part', 'remake', 'of']\n","token_ids_seq:  [1]\n","Printing prob:  0.4647146739980642\n","label:  0\n","idx:  13\n","tok_flaw:  the\n","flaw_tokens_seq:  ['an', 'unZeven', 'but', 'intriguing', 'drama', 'that', 'is', 'part', 'homage', 'and', 'part', 'remake', 'of', 'the']\n","token_ids_seq:  [1]\n","Printing prob:  0.8485942442636691\n","label:  0\n","idx:  14\n","tok_flaw:  italian\n","flaw_tokens_seq:  ['an', 'unZeven', 'but', 'intriguing', 'drama', 'that', 'is', 'part', 'homage', 'and', 'part', 'remake', 'of', 'the', 'italian']\n","token_ids_seq:  [1]\n","Printing prob:  0.48885410435599097\n","label:  0\n","idx:  15\n","tok_flaw:  masterpiece\n","flaw_tokens_seq:  ['an', 'unZeven', 'but', 'intriguing', 'drama', 'that', 'is', 'part', 'homage', 'and', 'part', 'remake', 'of', 'the', 'italian', 'masterpiece']\n","token_ids_seq:  [1]\n","Printing prob:  0.42825849577593045\n","label:  0\n","idx:  16\n","tok_flaw:  .\n","flaw_tokens_seq:  ['an', 'unZeven', 'but', 'intriguing', 'drama', 'that', 'is', 'part', 'homage', 'and', 'part', 'remake', 'of', 'the', 'italian', 'masterpiece', '.']\n","token_ids_seq:  [1]\n","all_flaw_tokens:  [['an', 'unZeven', 'but', 'intriguing', 'drama', 'that', 'is', 'part', 'homage', 'and', 'part', 'remake', 'of', 'the', 'italian', 'masterpiece', '.']]\n","all_token_idx:  [[1]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.5752036867254916\n","label:  0\n","idx:  0\n","tok_flaw:  a\n","flaw_tokens_seq:  ['a']\n","token_ids_seq:  []\n","Printing prob:  0.018010124257254123\n","label:  1\n","idx:  1\n","tok_flaw:  hysterica\n","flaw_tokens_seq:  ['a', 'hysterica']\n","token_ids_seq:  [1]\n","Printing prob:  0.19797565271728979\n","label:  0\n","idx:  2\n","tok_flaw:  yet\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet']\n","token_ids_seq:  [1]\n","Printing prob:  0.8756861919840848\n","label:  0\n","idx:  3\n","tok_flaw:  humorless\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet', 'humorless']\n","token_ids_seq:  [1]\n","Printing prob:  0.7253946453485559\n","label:  0\n","idx:  4\n","tok_flaw:  disquisition\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet', 'humorless', 'disquisition']\n","token_ids_seq:  [1]\n","Printing prob:  0.5064723384631776\n","label:  0\n","idx:  5\n","tok_flaw:  on\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet', 'humorless', 'disquisition', 'on']\n","token_ids_seq:  [1]\n","Printing prob:  0.41170718218045943\n","label:  0\n","idx:  6\n","tok_flaw:  the\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet', 'humorless', 'disquisition', 'on', 'the']\n","token_ids_seq:  [1]\n","Printing prob:  0.9784181622847964\n","label:  0\n","idx:  7\n","tok_flaw:  thin\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet', 'humorless', 'disquisition', 'on', 'the', 'thin']\n","token_ids_seq:  [1]\n","Printing prob:  0.4831988112375909\n","label:  0\n","idx:  8\n","tok_flaw:  line\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet', 'humorless', 'disquisition', 'on', 'the', 'thin', 'line']\n","token_ids_seq:  [1]\n","Printing prob:  0.06451743385798026\n","label:  1\n","idx:  9\n","tok_flaw:  betwnen\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet', 'humorless', 'disquisition', 'on', 'the', 'thin', 'line', 'betwnen']\n","token_ids_seq:  [1, 9]\n","Printing prob:  0.38038047583535484\n","label:  0\n","idx:  10\n","tok_flaw:  sucking\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet', 'humorless', 'disquisition', 'on', 'the', 'thin', 'line', 'betwnen', 'sucking']\n","token_ids_seq:  [1, 9]\n","Printing prob:  0.8956239111529424\n","label:  0\n","idx:  11\n","tok_flaw:  face\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet', 'humorless', 'disquisition', 'on', 'the', 'thin', 'line', 'betwnen', 'sucking', 'face']\n","token_ids_seq:  [1, 9]\n","Printing prob:  0.8605606372708084\n","label:  0\n","idx:  12\n","tok_flaw:  and\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet', 'humorless', 'disquisition', 'on', 'the', 'thin', 'line', 'betwnen', 'sucking', 'face', 'and']\n","token_ids_seq:  [1, 9]\n","Printing prob:  0.6719371737087395\n","label:  0\n","idx:  13\n","tok_flaw:  literally\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet', 'humorless', 'disquisition', 'on', 'the', 'thin', 'line', 'betwnen', 'sucking', 'face', 'and', 'literally']\n","token_ids_seq:  [1, 9]\n","Printing prob:  0.7215944577988803\n","label:  0\n","idx:  14\n","tok_flaw:  sucking\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet', 'humorless', 'disquisition', 'on', 'the', 'thin', 'line', 'betwnen', 'sucking', 'face', 'and', 'literally', 'sucking']\n","token_ids_seq:  [1, 9]\n","Printing prob:  0.08514310325561014\n","label:  1\n","idx:  15\n","tok_flaw:  Face\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet', 'humorless', 'disquisition', 'on', 'the', 'thin', 'line', 'betwnen', 'sucking', 'face', 'and', 'literally', 'sucking', 'Face']\n","token_ids_seq:  [1, 9, 15]\n","Printing prob:  0.21275781005885197\n","label:  0\n","idx:  16\n","tok_flaw:  .\n","flaw_tokens_seq:  ['a', 'hysterica', 'yet', 'humorless', 'disquisition', 'on', 'the', 'thin', 'line', 'betwnen', 'sucking', 'face', 'and', 'literally', 'sucking', 'Face', '.']\n","token_ids_seq:  [1, 9, 15]\n","all_flaw_tokens:  [['a', 'hysterica', 'yet', 'humorless', 'disquisition', 'on', 'the', 'thin', 'line', 'betwnen', 'sucking', 'face', 'and', 'literally', 'sucking', 'Face', '.']]\n","all_token_idx:  [[1, 9, 15]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.2864343866458938\n","label:  0\n","idx:  0\n","tok_flaw:  i\n","flaw_tokens_seq:  ['i']\n","token_ids_seq:  []\n","Printing prob:  0.38549397854819334\n","label:  0\n","idx:  1\n","tok_flaw:  hated\n","flaw_tokens_seq:  ['i', 'hated']\n","token_ids_seq:  []\n","Printing prob:  0.5800358977939518\n","label:  0\n","idx:  2\n","tok_flaw:  every\n","flaw_tokens_seq:  ['i', 'hated', 'every']\n","token_ids_seq:  []\n","Printing prob:  0.3491792844284892\n","label:  0\n","idx:  3\n","tok_flaw:  minute\n","flaw_tokens_seq:  ['i', 'hated', 'every', 'minute']\n","token_ids_seq:  []\n","Printing prob:  0.3415742313199681\n","label:  0\n","idx:  4\n","tok_flaw:  of\n","flaw_tokens_seq:  ['i', 'hated', 'every', 'minute', 'of']\n","token_ids_seq:  []\n","Printing prob:  0.5537224867077652\n","label:  0\n","idx:  5\n","tok_flaw:  it\n","flaw_tokens_seq:  ['i', 'hated', 'every', 'minute', 'of', 'it']\n","token_ids_seq:  []\n","Printing prob:  0.17967838765060506\n","label:  0\n","idx:  6\n","tok_flaw:  .\n","flaw_tokens_seq:  ['i', 'hated', 'every', 'minute', 'of', 'it', '.']\n","token_ids_seq:  []\n","all_flaw_tokens:  [['i', 'hated', 'every', 'minute', 'of', 'it', '.']]\n","all_token_idx:  [[]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.7518984471428023\n","label:  0\n","idx:  0\n","tok_flaw:  ...\n","flaw_tokens_seq:  ['...']\n","token_ids_seq:  []\n","Printing prob:  0.9153199097953828\n","label:  0\n","idx:  1\n","tok_flaw:  too\n","flaw_tokens_seq:  ['...', 'too']\n","token_ids_seq:  []\n","Printing prob:  0.5997635322945319\n","label:  0\n","idx:  2\n","tok_flaw:  dull\n","flaw_tokens_seq:  ['...', 'too', 'dull']\n","token_ids_seq:  []\n","Printing prob:  0.9483853997263799\n","label:  0\n","idx:  3\n","tok_flaw:  to\n","flaw_tokens_seq:  ['...', 'too', 'dull', 'to']\n","token_ids_seq:  []\n","Printing prob:  0.4731325541444561\n","label:  0\n","idx:  4\n","tok_flaw:  enjoy\n","flaw_tokens_seq:  ['...', 'too', 'dull', 'to', 'enjoy']\n","token_ids_seq:  []\n","Printing prob:  0.8233318370207501\n","label:  0\n","idx:  5\n","tok_flaw:  .\n","flaw_tokens_seq:  ['...', 'too', 'dull', 'to', 'enjoy', '.']\n","token_ids_seq:  []\n","all_flaw_tokens:  [['...', 'too', 'dull', 'to', 'enjoy', '.']]\n","all_token_idx:  [[]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","emb_dict:  None\n","embeddings: None\n","Printing prob:  0.021835616745112918\n","label:  1\n","idx:  0\n","tok_flaw:  `\n","flaw_tokens_seq:  ['`']\n","token_ids_seq:  [0]\n","Printing prob:  0.8715476252327595\n","label:  0\n","idx:  1\n","tok_flaw:  a\n","flaw_tokens_seq:  ['`', 'a']\n","token_ids_seq:  [0]\n","Printing prob:  0.4682826814578841\n","label:  0\n","idx:  2\n","tok_flaw:  gentle\n","flaw_tokens_seq:  ['`', 'a', 'gentle']\n","token_ids_seq:  [0]\n","Printing prob:  0.5646789916754171\n","label:  0\n","idx:  3\n","tok_flaw:  ,\n","flaw_tokens_seq:  ['`', 'a', 'gentle', ',']\n","token_ids_seq:  [0]\n","Printing prob:  0.11602229536436459\n","label:  1\n","idx:  4\n","tok_flaw:  compassiqnate\n","flaw_tokens_seq:  ['`', 'a', 'gentle', ',', 'compassiqnate']\n","token_ids_seq:  [0, 4]\n","Printing prob:  0.15749348428067556\n","label:  0\n","idx:  5\n","tok_flaw:  drama\n","flaw_tokens_seq:  ['`', 'a', 'gentle', ',', 'compassiqnate', 'drama']\n","token_ids_seq:  [0, 4]\n","Printing prob:  0.2898475262312066\n","label:  0\n","idx:  6\n","tok_flaw:  about\n","flaw_tokens_seq:  ['`', 'a', 'gentle', ',', 'compassiqnate', 'drama', 'about']\n","token_ids_seq:  [0, 4]\n","Printing prob:  0.6181506457184668\n","label:  0\n","idx:  7\n","tok_flaw:  grief\n","flaw_tokens_seq:  ['`', 'a', 'gentle', ',', 'compassiqnate', 'drama', 'about', 'grief']\n","token_ids_seq:  [0, 4]\n","Printing prob:  0.9119156038724561\n","label:  0\n","idx:  8\n","tok_flaw:  and\n","flaw_tokens_seq:  ['`', 'a', 'gentle', ',', 'compassiqnate', 'drama', 'about', 'grief', 'and']\n","token_ids_seq:  [0, 4]\n","Printing prob:  0.09138870097826146\n","label:  1\n","idx:  9\n","tok_flaw:  healineg\n","flaw_tokens_seq:  ['`', 'a', 'gentle', ',', 'compassiqnate', 'drama', 'about', 'grief', 'and', 'healineg']\n","token_ids_seq:  [0, 4, 9]\n","Printing prob:  0.3358613796589037\n","label:  0\n","idx:  10\n","tok_flaw:  .\n","flaw_tokens_seq:  ['`', 'a', 'gentle', ',', 'compassiqnate', 'drama', 'about', 'grief', 'and', 'healineg', '.']\n","token_ids_seq:  [0, 4, 9]\n","Printing prob:  0.34968193969692996\n","label:  0\n","idx:  11\n","tok_flaw:  ''\n","flaw_tokens_seq:  ['`', 'a', 'gentle', ',', 'compassiqnate', 'drama', 'about', 'grief', 'and', 'healineg', '.', \"''\"]\n","token_ids_seq:  [0, 4, 9]\n","all_flaw_tokens:  [['`', 'a', 'gentle', ',', 'compassiqnate', 'drama', 'about', 'grief', 'and', 'healineg', '.', \"''\"]]\n","all_token_idx:  [[0, 4, 9]]\n","all_flaw_tokens type:  <class 'list'>\n","all_flaw_tokens len:  1\n","all_token_idx type:  <class 'list'>\n","all_token_idx len:  1\n","attacks: 100% 1820/1820 [00:35<00:00, 50.58it/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y0j2CNHrg1YP"},"source":["Testing"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"id":"VZzl84JKg1YP"},"source":["Inference\n","We first attack the test data using 5 differernt methods to drop the model performance as much as possible. The codes related to attacking the test sets would be availble soon!\n","\n","During inference phase, we use the pre-trained discriminator to identify the words that have been attacked."]},{"cell_type":"code","metadata":{"tags":[],"id":"jo6eI6vYg1YP"},"source":["# Modified - Run this : \n","# Discriminator do_eval or Testing \n","!python bert_discriminator.py \\\n","--task_name sst-2\\\n","--do_eval\\\n","--eval_batch_size 32\\\n","--do_lower_case\\\n","--data_dir data/sst-2/add_1/\\\n","--data_file data/sst-2/add_1/test.tsv\\\n","--bert_model bert-base-uncased\\\n","--max_seq_length 128\\\n","--train_batch_size 16\\\n","--learning_rate 2e-5\\\n","--num_train_epochs 5\\\n","--output_dir models/\\\n","--single\n","#--no_cuda"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nyBeF4qU_L5_"},"source":["!python bert_discriminator.py  --task_name sst-2  --do_eval  --eval_batch_size 32  --do_lower_case  --data_dir ./data/sst-2/add_1/  --data_file ./data/sst-2/add_1/test.tsv  --bert_model bert-base-uncased  --max_seq_length 128  --train_batch_size 16  --learning_rate 2e-5  --num_train_epochs 5  --output_dir ./models/  --single"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"id":"354rtMeLg1YP"},"source":["Then, we recover the words with a pre-trained embedding estimator. Note that we use small-world-graph to conduct a KNN-based search for closest word in the embedding space."]},{"cell_type":"code","metadata":{"tags":[],"id":"TrYnZ21og1YQ","outputId":"2e2fd4e4-8895-40fa-b08f-61aabbd31e7d"},"source":["!python bert_generator.py \\\n","--task_name sst-2\\\n","--do_eval\\\n","--do_lower_case\\\n","--data_dir data/sst-2/add_1/\\\n","--bert_model bert-base-uncased\\\n","--max_seq_length 64\\\n","--train_batch_size 8\\\n","--learning_rate 2e-5\\\n","--output_dir ./tmp/sst2-gnrt/\\\n","--num_eval_epochs 2\\\n","--no_cuda"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n","03/28/2021 20:43:49 - INFO - bert_utils -   device: cpu n_gpu: 2, distributed training: False, 16-bits training: False\n","03/28/2021 20:43:49 - INFO - tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","03/28/2021 20:43:49 - INFO - bert_utils -   loading embeddings ... \n","03/28/2021 20:43:49 - INFO - bert_utils -   loading p index ...\n","line : ['sentence', 'label', 'ids']\n","line : ['that loves its charcatres and communicates something rather handsome about human ntaure', '1', '-1']\n","line : ['remains utterly satisfied to remain the smea throughout', '0', '-1']\n","line : ['on the bad revenge-of-the-nerds clichés the filmmakers could dredge up', '0', '-1']\n","line : [\"that 's far too tragic to merit such superficial treatment\", '0', '-1']\n","line : ['`` demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop . ``', '1', '-1']\n","03/28/2021 20:43:50 - INFO - bert_utils -   *** Example ***\n","03/28/2021 20:43:50 - INFO - bert_utils -   tokens: that loves its charcatres and communicates something rather handsome about human ntaure\n","03/28/2021 20:43:50 - INFO - bert_utils -   token_ids: 1 2 3 4 5 6 7 8 9 10 11 12 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/28/2021 20:43:50 - INFO - bert_utils -   flaw_labels: -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/28/2021 20:43:50 - INFO - bert_utils -   ngram_labels: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/28/2021 20:43:50 - INFO - bert_utils -   label: 1 (id = 1)\n","03/28/2021 20:43:50 - INFO - bert_utils -   *** Example ***\n","03/28/2021 20:43:50 - INFO - bert_utils -   tokens: remains utterly satisfied to remain the smea throughout\n","03/28/2021 20:43:50 - INFO - bert_utils -   token_ids: 13 14 15 16 17 18 19 20 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/28/2021 20:43:50 - INFO - bert_utils -   flaw_labels: -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/28/2021 20:43:50 - INFO - bert_utils -   ngram_labels: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/28/2021 20:43:50 - INFO - bert_utils -   label: 0 (id = 0)\n","03/28/2021 20:43:50 - INFO - bert_utils -   *** Example ***\n","03/28/2021 20:43:50 - INFO - bert_utils -   tokens: on the bad revenge-of-the-nerds clichés the filmmakers could dredge up\n","03/28/2021 20:43:50 - INFO - bert_utils -   token_ids: 21 18 22 23 24 18 25 26 27 28 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/28/2021 20:43:50 - INFO - bert_utils -   flaw_labels: -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/28/2021 20:43:50 - INFO - bert_utils -   ngram_labels: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/28/2021 20:43:50 - INFO - bert_utils -   label: 0 (id = 0)\n","03/28/2021 20:43:50 - INFO - bert_utils -   ***** Running evaluation *****\n","03/28/2021 20:43:50 - INFO - bert_utils -     Num examples = 5\n","03/28/2021 20:43:50 - INFO - bert_utils -     Num token vocab = 60\n","03/28/2021 20:43:50 - INFO - bert_utils -     Batch size = 8\n","Epoch:   0%|                                              | 0/2 [00:00<?, ?it/s]\n","Evaluating:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n","Evaluating: 100%|█████████████████████████████████| 1/1 [00:08<00:00,  8.43s/it]\u001b[A\n","Epoch:  50%|███████████████████                   | 1/2 [00:10<00:10, 10.57s/it]\n","Evaluating:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n","Evaluating: 100%|█████████████████████████████████| 1/1 [00:08<00:00,  8.37s/it]\u001b[A\n","Epoch: 100%|██████████████████████████████████████| 2/2 [00:21<00:00, 10.64s/it]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"tags":[],"id":"6fO-Mmtbg1YQ"},"source":["Classification"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"id":"okvXv7spg1YQ"},"source":["After recovering the test instances, we can run a model to check the recovering effectiveness. The model in our settings is a sentiment classification model based on bert contextualized embeddings."]},{"cell_type":"code","metadata":{"tags":[],"id":"2r6oueIUg1YQ"},"source":["python bert_classifier.py \n","--task_name sst-2 \n","--do_eval  \n","--do_lower_case   \n","--data_dir data/SST-2/add_1/  \n","--bert_model bert-base-uncased   \n","--max_seq_length 64   \n","--train_batch_size 8  \n","--learning_rate 2e-5   \n","--output_dir ./tmp/sst2-gnrt/ \n","--num_eval_epochs 2"],"execution_count":null,"outputs":[]}]}